[2021-12-11 15:39:08,300 DEBUG] Assigning machine gpu3 to PID 6562
[2021-12-11 15:39:08,316 DEBUG] Assigning machine gpu2 to PID 6561
[2021-12-11 15:39:08,319 DEBUG] Starting producer with PID 6559
[2021-12-11 15:39:08,335 DEBUG] gpu3 now training {'batch-size': 64, 'lr': 0.5, 'gamma': 0.5}...
[2021-12-11 15:39:08,335 DEBUG] Attempting to establish SSH connection with gpu3...
[2021-12-11 15:39:08,339 DEBUG] gpu2 now training {'batch-size': 64, 'lr': 0.5, 'gamma': 0.7}...
[2021-12-11 15:39:08,339 DEBUG] Attempting to establish SSH connection with gpu2...
[2021-12-11 15:39:08,340 DEBUG] Assigning machine gpu1 to PID 6560
[2021-12-11 15:39:08,341 DEBUG] gpu1 now training {'batch-size': 64, 'lr': 0.5, 'gamma': 0.9}...
[2021-12-11 15:39:08,341 DEBUG] Attempting to establish SSH connection with gpu1...
[2021-12-11 15:39:08,472 DEBUG] SSH connection with gpu1 established successfully!
[2021-12-11 15:39:08,472 DEBUG] Running cmd on gpu1: source /u5/p3basta/CS848/CS848-Project/venv/bin/activate && python /u5/p3basta/CS848/CS848-Project/models/MNIST/train.py --arch "alexnet" --parallelism "dp" --epochs "1" --batch-size "64" --lr "0.5" --gamma "0.9"
[2021-12-11 15:39:08,472 INFO] Training {'batch-size': 64, 'lr': 0.5, 'gamma': 0.9} on gpu1...
[2021-12-11 15:39:08,474 DEBUG] SSH connection with gpu2 established successfully!
[2021-12-11 15:39:08,474 DEBUG] Running cmd on gpu2: source /u5/p3basta/CS848/CS848-Project/venv/bin/activate && python /u5/p3basta/CS848/CS848-Project/models/MNIST/train.py --arch "alexnet" --parallelism "dp" --epochs "1" --batch-size "64" --lr "0.5" --gamma "0.7"
[2021-12-11 15:39:08,474 INFO] Training {'batch-size': 64, 'lr': 0.5, 'gamma': 0.7} on gpu2...
[2021-12-11 15:39:08,477 DEBUG] SSH connection with gpu3 established successfully!
[2021-12-11 15:39:08,478 DEBUG] Running cmd on gpu3: source /u5/p3basta/CS848/CS848-Project/venv/bin/activate && python /u5/p3basta/CS848/CS848-Project/models/MNIST/train.py --arch "alexnet" --parallelism "dp" --epochs "1" --batch-size "64" --lr "0.5" --gamma "0.5"
[2021-12-11 15:39:08,478 INFO] Training {'batch-size': 64, 'lr': 0.5, 'gamma': 0.5} on gpu3...
[2021-12-11 15:40:48,884 DEBUG] Received output from gpu3: ['Train Epoch: 1 [0/60000 (0%)]\tLoss: -0.003959\n', 'Train Epoch: 1 [640/60000 (1%)]\tLoss: -710013593059328.000000\n', 'Train Epoch: 1 [1280/60000 (2%)]\tLoss: -19887335634616871408369664.000000\n', 'Train Epoch: 1 [1920/60000 (3%)]\tLoss: -1043242403219886915603922944.000000\n', 'Train Epoch: 1 [2560/60000 (4%)]\tLoss: -3303356155235783773662478336.000000\n', 'Train Epoch: 1 [3200/60000 (5%)]\tLoss: -5429092829159312326857326592.000000\n', 'Train Epoch: 1 [3840/60000 (6%)]\tLoss: -7598488961808591467464097792.000000\n', 'Train Epoch: 1 [4480/60000 (7%)]\tLoss: -9493595882033353005123764224.000000\n', 'Train Epoch: 1 [5120/60000 (9%)]\tLoss: -11448335075316361346425028608.000000\n', 'Train Epoch: 1 [5760/60000 (10%)]\tLoss: -14193718247881251113746300928.000000\n', 'Train Epoch: 1 [6400/60000 (11%)]\tLoss: -15978253318092861343549882368.000000\n', 'Train Epoch: 1 [7040/60000 (12%)]\tLoss: -17662192537486382391011311616.000000\n', 'Train Epoch: 1 [7680/60000 (13%)]\tLoss: -19065408320122475943921975296.000000\n', 'Train Epoch: 1 [8320/60000 (14%)]\tLoss: -21414496400403048671966396416.000000\n', 'Train Epoch: 1 [8960/60000 (15%)]\tLoss: -22726964827521077687628070912.000000\n', 'Train Epoch: 1 [9600/60000 (16%)]\tLoss: -25752969905964013252128014336.000000\n', 'Train Epoch: 1 [10240/60000 (17%)]\tLoss: -28493987250715490032449224704.000000\n', 'Train Epoch: 1 [10880/60000 (18%)]\tLoss: -29929640968722415178332766208.000000\n', 'Train Epoch: 1 [11520/60000 (19%)]\tLoss: -30692218153109171226730823680.000000\n', 'Train Epoch: 1 [12160/60000 (20%)]\tLoss: -32527369908467419748757405696.000000\n', 'Train Epoch: 1 [12800/60000 (21%)]\tLoss: -35808108879729309715374538752.000000\n', 'Train Epoch: 1 [13440/60000 (22%)]\tLoss: -36865434929327616104608038912.000000\n', 'Train Epoch: 1 [14080/60000 (23%)]\tLoss: -40845594155634363484535259136.000000\n', 'Train Epoch: 1 [14720/60000 (25%)]\tLoss: -39871275502888698284045500416.000000\n', 'Train Epoch: 1 [15360/60000 (26%)]\tLoss: -44828489993317933823863816192.000000\n', 'Train Epoch: 1 [16000/60000 (27%)]\tLoss: -47630440032797877636377346048.000000\n', 'Train Epoch: 1 [16640/60000 (28%)]\tLoss: -47731640346525774133306851328.000000\n', 'Train Epoch: 1 [17280/60000 (29%)]\tLoss: -47344212677904665570330017792.000000\n', 'Train Epoch: 1 [17920/60000 (30%)]\tLoss: -50068106721789257017106366464.000000\n', 'Train Epoch: 1 [18560/60000 (31%)]\tLoss: -52389499303239419993383763968.000000\n', 'Train Epoch: 1 [19200/60000 (32%)]\tLoss: -56496064474376380601568591872.000000\n', 'Train Epoch: 1 [19840/60000 (33%)]\tLoss: -54382144341984612618109714432.000000\n', 'Train Epoch: 1 [20480/60000 (34%)]\tLoss: -56672997379390057598790139904.000000\n', 'Train Epoch: 1 [21120/60000 (35%)]\tLoss: -59306576164289767080854552576.000000\n', 'Train Epoch: 1 [21760/60000 (36%)]\tLoss: -60836226225954971079894106112.000000\n', 'Train Epoch: 1 [22400/60000 (37%)]\tLoss: -65947347362427411226871988224.000000\n', 'Train Epoch: 1 [23040/60000 (38%)]\tLoss: -66388765847047168443577008128.000000\n', 'Train Epoch: 1 [23680/60000 (39%)]\tLoss: -66620832380748348548668456960.000000\n', 'Train Epoch: 1 [24320/60000 (41%)]\tLoss: -69275756262150628827098775552.000000\n', 'Train Epoch: 1 [24960/60000 (42%)]\tLoss: -69920774855312827927547084800.000000\n', 'Train Epoch: 1 [25600/60000 (43%)]\tLoss: -72640815448147397743829057536.000000\n', 'Train Epoch: 1 [26240/60000 (44%)]\tLoss: -77818422782332159625770565632.000000\n', 'Train Epoch: 1 [26880/60000 (45%)]\tLoss: -74001834525075809581932740608.000000\n', 'Train Epoch: 1 [27520/60000 (46%)]\tLoss: -75881180547163993678691696640.000000\n', 'Train Epoch: 1 [28160/60000 (47%)]\tLoss: -81979460450849021591495376896.000000\n', 'Train Epoch: 1 [28800/60000 (48%)]\tLoss: -85844065730503190187866062848.000000\n', 'Train Epoch: 1 [29440/60000 (49%)]\tLoss: -82076505082071992800636829696.000000\n', 'Train Epoch: 1 [30080/60000 (50%)]\tLoss: -83256293900487316264374501376.000000\n', 'Train Epoch: 1 [30720/60000 (51%)]\tLoss: -90762599317071240463738994688.000000\n', 'Train Epoch: 1 [31360/60000 (52%)]\tLoss: -88608633516904737888867975168.000000\n', 'Train Epoch: 1 [32000/60000 (53%)]\tLoss: -86900440223255198343589003264.000000\n', 'Train Epoch: 1 [32640/60000 (54%)]\tLoss: -86983525539154806881478770688.000000\n', 'Train Epoch: 1 [33280/60000 (55%)]\tLoss: -95008148456165537600208109568.000000\n', 'Train Epoch: 1 [33920/60000 (57%)]\tLoss: -91795730321994564225720123392.000000\n', 'Train Epoch: 1 [34560/60000 (58%)]\tLoss: -94267860841577926277218697216.000000\n', 'Train Epoch: 1 [35200/60000 (59%)]\tLoss: -91663211273752276241733386240.000000\n', 'Train Epoch: 1 [35840/60000 (60%)]\tLoss: -100931006612111406802258624512.000000\n', 'Train Epoch: 1 [36480/60000 (61%)]\tLoss: -95150216129436188006816940032.000000\n', 'Train Epoch: 1 [37120/60000 (62%)]\tLoss: -105656291517467465456696688640.000000\n', 'Train Epoch: 1 [37760/60000 (63%)]\tLoss: -103891061481437826336526696448.000000\n', 'Train Epoch: 1 [38400/60000 (64%)]\tLoss: -110726158060345556383087722496.000000\n', 'Train Epoch: 1 [39040/60000 (65%)]\tLoss: -104237890965405704559601385472.000000\n', 'Train Epoch: 1 [39680/60000 (66%)]\tLoss: -109187053820981647354330349568.000000\n', 'Train Epoch: 1 [40320/60000 (67%)]\tLoss: -110472387530289107388594126848.000000\n', 'Train Epoch: 1 [40960/60000 (68%)]\tLoss: -111496886049281745439124619264.000000\n', 'Train Epoch: 1 [41600/60000 (69%)]\tLoss: -117178147935964003592042446848.000000\n', 'Train Epoch: 1 [42240/60000 (70%)]\tLoss: -114583443671951277029377179648.000000\n', 'Train Epoch: 1 [42880/60000 (71%)]\tLoss: -121416481299072475910625034240.000000\n', 'Train Epoch: 1 [43520/60000 (72%)]\tLoss: -118232454032196514843161788416.000000\n', 'Train Epoch: 1 [44160/60000 (74%)]\tLoss: -123107088499939808897128202240.000000\n', 'Train Epoch: 1 [44800/60000 (75%)]\tLoss: -116910852548300615933656825856.000000\n', 'Train Epoch: 1 [45440/60000 (76%)]\tLoss: -115834681895252418225198071808.000000\n', 'Train Epoch: 1 [46080/60000 (77%)]\tLoss: -124587144268801915882133520384.000000\n', 'Train Epoch: 1 [46720/60000 (78%)]\tLoss: -119506255722552807203813720064.000000\n', 'Train Epoch: 1 [47360/60000 (79%)]\tLoss: -120172638301683508579208790016.000000\n', 'Train Epoch: 1 [48000/60000 (80%)]\tLoss: -129217925176102787196555100160.000000\n', 'Train Epoch: 1 [48640/60000 (81%)]\tLoss: -129371402086796050666000220160.000000\n', 'Train Epoch: 1 [49280/60000 (82%)]\tLoss: -130856057440612472685443678208.000000\n', 'Train Epoch: 1 [49920/60000 (83%)]\tLoss: -134740241651704618830870347776.000000\n', 'Train Epoch: 1 [50560/60000 (84%)]\tLoss: -134218618494739803559855915008.000000\n', 'Train Epoch: 1 [51200/60000 (85%)]\tLoss: -136314404739837352105694199808.000000\n', 'Train Epoch: 1 [51840/60000 (86%)]\tLoss: -141059504694955531791448932352.000000\n', 'Train Epoch: 1 [52480/60000 (87%)]\tLoss: -135521217175908635017020964864.000000\n', 'Train Epoch: 1 [53120/60000 (88%)]\tLoss: -138690520104091008530707906560.000000\n', 'Train Epoch: 1 [53760/60000 (90%)]\tLoss: -144139677678140223621372575744.000000\n', 'Train Epoch: 1 [54400/60000 (91%)]\tLoss: -133780647337652541184156893184.000000\n', 'Train Epoch: 1 [55040/60000 (92%)]\tLoss: -143820700711688310565768265728.000000\n', 'Train Epoch: 1 [55680/60000 (93%)]\tLoss: -136096061403135391189593751552.000000\n', 'Train Epoch: 1 [56320/60000 (94%)]\tLoss: -143089659490674158008107270144.000000\n', 'Train Epoch: 1 [56960/60000 (95%)]\tLoss: -149358260986296845414833324032.000000\n', 'Train Epoch: 1 [57600/60000 (96%)]\tLoss: -151003410687400075196509454336.000000\n', 'Train Epoch: 1 [58240/60000 (97%)]\tLoss: -151659271834006943002368409600.000000\n', 'Train Epoch: 1 [58880/60000 (98%)]\tLoss: -144455226206525573314551742464.000000\n', 'Train Epoch: 1 [59520/60000 (99%)]\tLoss: -151013610999003073630171037696.000000\n', 'Train Epoch: 1 [0/60000 (0%)]\tLoss: -0.004582\n', 'Train Epoch: 1 [640/60000 (1%)]\tLoss: -697744683433984.000000\n', 'Train Epoch: 1 [1280/60000 (2%)]\tLoss: -19800633631627427302080512.000000\n', 'Train Epoch: 1 [1920/60000 (3%)]\tLoss: -1069983172364017755817508864.000000\n', 'Train Epoch: 1 [2560/60000 (4%)]\tLoss: -3270378984642189503076761600.000000\n', 'Train Epoch: 1 [3200/60000 (5%)]\tLoss: -5538172411363876826825883648.000000\n', 'Train Epoch: 1 [3840/60000 (6%)]\tLoss: -7443337972197150708790722560.000000\n', 'Train Epoch: 1 [4480/60000 (7%)]\tLoss: -9504989771764896741613109248.000000\n', 'Train Epoch: 1 [5120/60000 (9%)]\tLoss: -11207078816439516911747727360.000000\n', 'Train Epoch: 1 [5760/60000 (10%)]\tLoss: -13731920390704669943121575936.000000\n', 'Train Epoch: 1 [6400/60000 (11%)]\tLoss: -15785374162058154271852986368.000000\n', 'Train Epoch: 1 [7040/60000 (12%)]\tLoss: -17575348217866409615531442176.000000\n', 'Train Epoch: 1 [7680/60000 (13%)]\tLoss: -20174601301393760363948802048.000000\n', 'Train Epoch: 1 [8320/60000 (14%)]\tLoss: -21970706169488401224525938688.000000\n', 'Train Epoch: 1 [8960/60000 (15%)]\tLoss: -24848386439070884102508904448.000000\n', 'Train Epoch: 1 [9600/60000 (16%)]\tLoss: -26017120197549809726801313792.000000\n', 'Train Epoch: 1 [10240/60000 (17%)]\tLoss: -28021323228261825808187785216.000000\n', 'Train Epoch: 1 [10880/60000 (18%)]\tLoss: -30582824533533495895355555840.000000\n', 'Train Epoch: 1 [11520/60000 (19%)]\tLoss: -30614426610036859561125609472.000000\n', 'Train Epoch: 1 [12160/60000 (20%)]\tLoss: -33432647563233530736222928896.000000\n', 'Train Epoch: 1 [12800/60000 (21%)]\tLoss: -34389642214536788643246243840.000000\n', 'Train Epoch: 1 [13440/60000 (22%)]\tLoss: -36011347727235812071258980352.000000\n', 'Train Epoch: 1 [14080/60000 (23%)]\tLoss: -38156532286927418540855132160.000000\n', 'Train Epoch: 1 [14720/60000 (25%)]\tLoss: -39813662631797688612438409216.000000\n', 'Train Epoch: 1 [15360/60000 (26%)]\tLoss: -41642554890382893419734237184.000000\n', 'Train Epoch: 1 [16000/60000 (27%)]\tLoss: -45399197427505696187229405184.000000\n', 'Train Epoch: 1 [16640/60000 (28%)]\tLoss: -49436669654631791016292646912.000000\n', 'Train Epoch: 1 [17280/60000 (29%)]\tLoss: -48383463869789788392508096512.000000\n', 'Train Epoch: 1 [17920/60000 (30%)]\tLoss: -52243578178918747956280557568.000000\n', 'Train Epoch: 1 [18560/60000 (31%)]\tLoss: -50600766049224538648985206784.000000\n', 'Train Epoch: 1 [19200/60000 (32%)]\tLoss: -52853736262704403335761362944.000000\n', 'Train Epoch: 1 [19840/60000 (33%)]\tLoss: -56533555341883882714920124416.000000\n', 'Train Epoch: 1 [20480/60000 (34%)]\tLoss: -55479721482299658428322152448.000000\n', 'Train Epoch: 1 [21120/60000 (35%)]\tLoss: -59619664339737541688877383680.000000\n', 'Train Epoch: 1 [21760/60000 (36%)]\tLoss: -60953392860761449847291117568.000000\n', 'Train Epoch: 1 [22400/60000 (37%)]\tLoss: -66101523183360139403808735232.000000\n', 'Train Epoch: 1 [23040/60000 (38%)]\tLoss: -65849589653865526701303267328.000000\n', 'Train Epoch: 1 [23680/60000 (39%)]\tLoss: -68098843364923372977296244736.000000\n', 'Train Epoch: 1 [24320/60000 (41%)]\tLoss: -69963583107480041261409239040.000000\n', 'Train Epoch: 1 [24960/60000 (42%)]\tLoss: -69632039923817212079891283968.000000\n', 'Train Epoch: 1 [25600/60000 (43%)]\tLoss: -70015769979482233710665793536.000000\n', 'Train Epoch: 1 [26240/60000 (44%)]\tLoss: -77225439945444701145931972608.000000\n', 'Train Epoch: 1 [26880/60000 (45%)]\tLoss: -73691022530272778142902910976.000000\n', 'Train Epoch: 1 [27520/60000 (46%)]\tLoss: -76636839464653345696851689472.000000\n', 'Train Epoch: 1 [28160/60000 (47%)]\tLoss: -76577092083912078945608007680.000000\n', 'Train Epoch: 1 [28800/60000 (48%)]\tLoss: -79793514784860525779237208064.000000\n', 'Train Epoch: 1 [29440/60000 (49%)]\tLoss: -83538880310822235833962070016.000000\n', 'Train Epoch: 1 [30080/60000 (50%)]\tLoss: -84679067363912214452937687040.000000\n', 'Train Epoch: 1 [30720/60000 (51%)]\tLoss: -90088028154459243123543375872.000000\n', 'Train Epoch: 1 [31360/60000 (52%)]\tLoss: -89868627007665119406915059712.000000\n', 'Train Epoch: 1 [32000/60000 (53%)]\tLoss: -90670229828666310203359100928.000000\n', 'Train Epoch: 1 [32640/60000 (54%)]\tLoss: -86006930705764398511996010496.000000\n', 'Train Epoch: 1 [33280/60000 (55%)]\tLoss: -89774141899075863545479430144.000000\n', 'Train Epoch: 1 [33920/60000 (57%)]\tLoss: -94327041538341248671036735488.000000\n', 'Train Epoch: 1 [34560/60000 (58%)]\tLoss: -93229403007261925555436519424.000000\n', 'Train Epoch: 1 [35200/60000 (59%)]\tLoss: -96297713405841648836583358464.000000\n', 'Train Epoch: 1 [35840/60000 (60%)]\tLoss: -96135670122348459830720593920.000000\n', 'Train Epoch: 1 [36480/60000 (61%)]\tLoss: -101195742477141079112938422272.000000\n', 'Train Epoch: 1 [37120/60000 (62%)]\tLoss: -102932430530148254097436835840.000000\n', 'Train Epoch: 1 [37760/60000 (63%)]\tLoss: -103585618817325817684104839168.000000\n', 'Train Epoch: 1 [38400/60000 (64%)]\tLoss: -106710200934915415657618079744.000000\n', 'Train Epoch: 1 [39040/60000 (65%)]\tLoss: -99799669273810325898413473792.000000\n', 'Train Epoch: 1 [39680/60000 (66%)]\tLoss: -108706241355161791557252677632.000000\n', 'Train Epoch: 1 [40320/60000 (67%)]\tLoss: -111795027934811237620046102528.000000\n', 'Train Epoch: 1 [40960/60000 (68%)]\tLoss: -110175067336527634525939826688.000000\n', 'Train Epoch: 1 [41600/60000 (69%)]\tLoss: -116453104120383095483802845184.000000\n', 'Train Epoch: 1 [42240/60000 (70%)]\tLoss: -113294067616934480578810478592.000000\n', 'Train Epoch: 1 [42880/60000 (71%)]\tLoss: -120493948117177959239548665856.000000\n', 'Train Epoch: 1 [43520/60000 (72%)]\tLoss: -119335863295117904665213140992.000000\n', 'Train Epoch: 1 [44160/60000 (74%)]\tLoss: -116109211948367562180051075072.000000\n', 'Train Epoch: 1 [44800/60000 (75%)]\tLoss: -124021829777137590653601972224.000000\n', 'Train Epoch: 1 [45440/60000 (76%)]\tLoss: -123108731883475847533662568448.000000\n', 'Train Epoch: 1 [46080/60000 (77%)]\tLoss: -123737684985863324101093883904.000000\n', 'Train Epoch: 1 [46720/60000 (78%)]\tLoss: -122611853926881269203567902720.000000\n', 'Train Epoch: 1 [47360/60000 (79%)]\tLoss: -126566212503908858276870094848.000000\n', 'Train Epoch: 1 [48000/60000 (80%)]\tLoss: -131987697010368457246582505472.000000\n', 'Train Epoch: 1 [48640/60000 (81%)]\tLoss: -135161741194499631884063997952.000000\n', 'Train Epoch: 1 [49280/60000 (82%)]\tLoss: -135859036384627197957027921920.000000\n', 'Train Epoch: 1 [49920/60000 (83%)]\tLoss: -130560824532836428205973831680.000000\n', 'Train Epoch: 1 [50560/60000 (84%)]\tLoss: -135349086917608036448981745664.000000\n', 'Train Epoch: 1 [51200/60000 (85%)]\tLoss: -133320112713510127643626831872.000000\n', 'Train Epoch: 1 [51840/60000 (86%)]\tLoss: -134321839981322368264936882176.000000\n', 'Train Epoch: 1 [52480/60000 (87%)]\tLoss: -130314222555100975332914626560.000000\n', 'Train Epoch: 1 [53120/60000 (88%)]\tLoss: -148603201809350817841615470592.000000\n', 'Train Epoch: 1 [53760/60000 (90%)]\tLoss: -140494917447729568488280293376.000000\n', 'Train Epoch: 1 [54400/60000 (91%)]\tLoss: -147583812890892644747206197248.000000\n', 'Train Epoch: 1 [55040/60000 (92%)]\tLoss: -150062224157898223426838986752.000000\n', 'Train Epoch: 1 [55680/60000 (93%)]\tLoss: -151875395658461955185218420736.000000\n', 'Train Epoch: 1 [56320/60000 (94%)]\tLoss: -145741872733715271110184927232.000000\n', 'Train Epoch: 1 [56960/60000 (95%)]\tLoss: -146950260203550853145336741888.000000\n', 'Train Epoch: 1 [57600/60000 (96%)]\tLoss: -150000096704449590374407602176.000000\n', 'Train Epoch: 1 [58240/60000 (97%)]\tLoss: -146903622112166032529206280192.000000\n', 'Train Epoch: 1 [58880/60000 (98%)]\tLoss: -154747520063877341925607473152.000000\n', 'Train Epoch: 1 [59520/60000 (99%)]\tLoss: -153478072395418255377842569216.000000\n', '\n', 'Test set: Average loss: -156168928090923702472019017728.0000, Accuracy: 1010/10000 (10%)\n', '\n', '\n', 'Test set: Average loss: -156168935828048946063468396544.0000, Accuracy: 1010/10000 (10%)\n', '\n', '{"accuracy": 10.1, "runtime": 98.86405460909009, "mem_params": 244341408, "mem_bufs": 0, "mem_peak": 3344906752}\n']
[2021-12-11 15:40:48,884 DEBUG] Received error from gpu3: []
[2021-12-11 15:40:48,885 DEBUG] SSH connection with gpu3 has been closed
[2021-12-11 15:40:48,885 INFO] {'batch-size': 64, 'lr': 0.5, 'gamma': 0.5} => {"accuracy": 10.1, "runtime": 98.86405460909009, "mem_params": 244341408, "mem_bufs": 0, "mem_peak": 3344906752}
[2021-12-11 15:40:48,887 DEBUG] gpu3 finished training {'batch-size': 64, 'lr': 0.5, 'gamma': 0.5}
[2021-12-11 15:40:48,888 DEBUG] gpu3 now training {'batch-size': 64, 'lr': 0.9, 'gamma': 0.5}...
[2021-12-11 15:40:48,888 DEBUG] Attempting to establish SSH connection with gpu3...
[2021-12-11 15:40:48,979 DEBUG] SSH connection with gpu3 established successfully!
[2021-12-11 15:40:48,979 DEBUG] Running cmd on gpu3: source /u5/p3basta/CS848/CS848-Project/venv/bin/activate && python /u5/p3basta/CS848/CS848-Project/models/MNIST/train.py --arch "alexnet" --parallelism "dp" --epochs "1" --batch-size "64" --lr "0.9" --gamma "0.5"
[2021-12-11 15:40:48,979 INFO] Training {'batch-size': 64, 'lr': 0.9, 'gamma': 0.5} on gpu3...
[2021-12-11 15:40:49,671 DEBUG] Received output from gpu2: ['Train Epoch: 1 [0/60000 (0%)]\tLoss: 0.000976\n', 'Train Epoch: 1 [640/60000 (1%)]\tLoss: -204824809308160.000000\n', 'Train Epoch: 1 [1280/60000 (2%)]\tLoss: -15834747370633527876911104.000000\n', 'Train Epoch: 1 [1920/60000 (3%)]\tLoss: -991267521200589536514539520.000000\n', 'Train Epoch: 1 [2560/60000 (4%)]\tLoss: -3144910724706731078746898432.000000\n', 'Train Epoch: 1 [3200/60000 (5%)]\tLoss: -5317175104698543170115338240.000000\n', 'Train Epoch: 1 [3840/60000 (6%)]\tLoss: -7090026449935723538954584064.000000\n', 'Train Epoch: 1 [4480/60000 (7%)]\tLoss: -9652380142357551597083426816.000000\n', 'Train Epoch: 1 [5120/60000 (9%)]\tLoss: -11323513484441150884136615936.000000\n', 'Train Epoch: 1 [5760/60000 (10%)]\tLoss: -13164832650426027162812284928.000000\n', 'Train Epoch: 1 [6400/60000 (11%)]\tLoss: -15232147747998354617657196544.000000\n', 'Train Epoch: 1 [7040/60000 (12%)]\tLoss: -16270226612404105050410975232.000000\n', 'Train Epoch: 1 [7680/60000 (13%)]\tLoss: -20434019781763721454117978112.000000\n', 'Train Epoch: 1 [8320/60000 (14%)]\tLoss: -20313793053476343156622491648.000000\n', 'Train Epoch: 1 [8960/60000 (15%)]\tLoss: -22992430298172353358493384704.000000\n', 'Train Epoch: 1 [9600/60000 (16%)]\tLoss: -25344610347907584986741473280.000000\n', 'Train Epoch: 1 [10240/60000 (17%)]\tLoss: -26083927516182966597639471104.000000\n', 'Train Epoch: 1 [10880/60000 (18%)]\tLoss: -29743513616166590981880152064.000000\n', 'Train Epoch: 1 [11520/60000 (19%)]\tLoss: -30124814014276176180192215040.000000\n', 'Train Epoch: 1 [12160/60000 (20%)]\tLoss: -33105963694681574419629867008.000000\n', 'Train Epoch: 1 [12800/60000 (21%)]\tLoss: -35086857124434145932241534976.000000\n', 'Train Epoch: 1 [13440/60000 (22%)]\tLoss: -37890889727533035258294304768.000000\n', 'Train Epoch: 1 [14080/60000 (23%)]\tLoss: -39299548037540636077313753088.000000\n', 'Train Epoch: 1 [14720/60000 (25%)]\tLoss: -39189549955055153431351132160.000000\n', 'Train Epoch: 1 [15360/60000 (26%)]\tLoss: -40823635151489019634291572736.000000\n', 'Train Epoch: 1 [16000/60000 (27%)]\tLoss: -44465023612230905840701276160.000000\n', 'Train Epoch: 1 [16640/60000 (28%)]\tLoss: -46769958746488268103408943104.000000\n', 'Train Epoch: 1 [17280/60000 (29%)]\tLoss: -47294207539217558897162190848.000000\n', 'Train Epoch: 1 [17920/60000 (30%)]\tLoss: -50024320939760089666684977152.000000\n', 'Train Epoch: 1 [18560/60000 (31%)]\tLoss: -51749269189690850713182142464.000000\n', 'Train Epoch: 1 [19200/60000 (32%)]\tLoss: -50474674141765436252134309888.000000\n', 'Train Epoch: 1 [19840/60000 (33%)]\tLoss: -52869225624768215772062285824.000000\n', 'Train Epoch: 1 [20480/60000 (34%)]\tLoss: -55486672805762442546076712960.000000\n', 'Train Epoch: 1 [21120/60000 (35%)]\tLoss: -56314668933036391789620101120.000000\n', 'Train Epoch: 1 [21760/60000 (36%)]\tLoss: -56806418399630573685012692992.000000\n', 'Train Epoch: 1 [22400/60000 (37%)]\tLoss: -61853763976751859273379610624.000000\n', 'Train Epoch: 1 [23040/60000 (38%)]\tLoss: -65163920930018785694855462912.000000\n', 'Train Epoch: 1 [23680/60000 (39%)]\tLoss: -64301050126268844121408929792.000000\n', 'Train Epoch: 1 [24320/60000 (41%)]\tLoss: -65877286333287557170481594368.000000\n', 'Train Epoch: 1 [24960/60000 (42%)]\tLoss: -67767385183857235449392136192.000000\n', 'Train Epoch: 1 [25600/60000 (43%)]\tLoss: -68833671923856786990418624512.000000\n', 'Train Epoch: 1 [26240/60000 (44%)]\tLoss: -71880811953493805652072464384.000000\n', 'Train Epoch: 1 [26880/60000 (45%)]\tLoss: -71093966527751582496921223168.000000\n', 'Train Epoch: 1 [27520/60000 (46%)]\tLoss: -75898521076889091015916388352.000000\n', 'Train Epoch: 1 [28160/60000 (47%)]\tLoss: -76109299182485494760384495616.000000\n', 'Train Epoch: 1 [28800/60000 (48%)]\tLoss: -77493028119830026722320842752.000000\n', 'Train Epoch: 1 [29440/60000 (49%)]\tLoss: -78960149326895553749085847552.000000\n', 'Train Epoch: 1 [30080/60000 (50%)]\tLoss: -83436386068678033054244012032.000000\n', 'Train Epoch: 1 [30720/60000 (51%)]\tLoss: -82805440127634785496532516864.000000\n', 'Train Epoch: 1 [31360/60000 (52%)]\tLoss: -85796369829026206771207733248.000000\n', 'Train Epoch: 1 [32000/60000 (53%)]\tLoss: -86864191338132690946928672768.000000\n', 'Train Epoch: 1 [32640/60000 (54%)]\tLoss: -88950882305384232556085379072.000000\n', 'Train Epoch: 1 [33280/60000 (55%)]\tLoss: -88245625205366548261291163648.000000\n', 'Train Epoch: 1 [33920/60000 (57%)]\tLoss: -91251628700571289443488497664.000000\n', 'Train Epoch: 1 [34560/60000 (58%)]\tLoss: -90386387268846947308144689152.000000\n', 'Train Epoch: 1 [35200/60000 (59%)]\tLoss: -91462151798377618227115065344.000000\n', 'Train Epoch: 1 [35840/60000 (60%)]\tLoss: -97174042954067768898888925184.000000\n', 'Train Epoch: 1 [36480/60000 (61%)]\tLoss: -98902410197332127568520806400.000000\n', 'Train Epoch: 1 [37120/60000 (62%)]\tLoss: -96632906978795736253851500544.000000\n', 'Train Epoch: 1 [37760/60000 (63%)]\tLoss: -99712097709751991197570695168.000000\n', 'Train Epoch: 1 [38400/60000 (64%)]\tLoss: -107433233022374621296996646912.000000\n', 'Train Epoch: 1 [39040/60000 (65%)]\tLoss: -107271614751864890559203115008.000000\n', 'Train Epoch: 1 [39680/60000 (66%)]\tLoss: -105335822283206965593204850688.000000\n', 'Train Epoch: 1 [40320/60000 (67%)]\tLoss: -103277984975165757516303826944.000000\n', 'Train Epoch: 1 [40960/60000 (68%)]\tLoss: -104872898141624220012196659200.000000\n', 'Train Epoch: 1 [41600/60000 (69%)]\tLoss: -112651816330531243090457395200.000000\n', 'Train Epoch: 1 [42240/60000 (70%)]\tLoss: -111226813910126430429353345024.000000\n', 'Train Epoch: 1 [42880/60000 (71%)]\tLoss: -112620960387932172828631105536.000000\n', 'Train Epoch: 1 [43520/60000 (72%)]\tLoss: -120260644323458267287411228672.000000\n', 'Train Epoch: 1 [44160/60000 (74%)]\tLoss: -115652492996343307312853680128.000000\n', 'Train Epoch: 1 [44800/60000 (75%)]\tLoss: -118260948791554150282381230080.000000\n', 'Train Epoch: 1 [45440/60000 (76%)]\tLoss: -118954645538421769685692317696.000000\n', 'Train Epoch: 1 [46080/60000 (77%)]\tLoss: -121908438549791904070407028736.000000\n', 'Train Epoch: 1 [46720/60000 (78%)]\tLoss: -121058176464551224449681063936.000000\n', 'Train Epoch: 1 [47360/60000 (79%)]\tLoss: -121932314834729292996607475712.000000\n', 'Train Epoch: 1 [48000/60000 (80%)]\tLoss: -126860746501445438048848314368.000000\n', 'Train Epoch: 1 [48640/60000 (81%)]\tLoss: -123632574552687611537927438336.000000\n', 'Train Epoch: 1 [49280/60000 (82%)]\tLoss: -127568175890045242380440829952.000000\n', 'Train Epoch: 1 [49920/60000 (83%)]\tLoss: -127206414283258530339200434176.000000\n', 'Train Epoch: 1 [50560/60000 (84%)]\tLoss: -136927934593291776411857584128.000000\n', 'Train Epoch: 1 [51200/60000 (85%)]\tLoss: -135214962264761572785622351872.000000\n', 'Train Epoch: 1 [51840/60000 (86%)]\tLoss: -131927203495722897091395059712.000000\n', 'Train Epoch: 1 [52480/60000 (87%)]\tLoss: -133102638292241014742245703680.000000\n', 'Train Epoch: 1 [53120/60000 (88%)]\tLoss: -139677938601460154127020457984.000000\n', 'Train Epoch: 1 [53760/60000 (90%)]\tLoss: -140937903758021638427196260352.000000\n', 'Train Epoch: 1 [54400/60000 (91%)]\tLoss: -137944820657514028594303598592.000000\n', 'Train Epoch: 1 [55040/60000 (92%)]\tLoss: -147116751956270905356990808064.000000\n', 'Train Epoch: 1 [55680/60000 (93%)]\tLoss: -143156282637014482962782093312.000000\n', 'Train Epoch: 1 [56320/60000 (94%)]\tLoss: -132420275224932282487447486464.000000\n', 'Train Epoch: 1 [56960/60000 (95%)]\tLoss: -145247204844634675774050271232.000000\n', 'Train Epoch: 1 [57600/60000 (96%)]\tLoss: -143477734123503419712478380032.000000\n', 'Train Epoch: 1 [58240/60000 (97%)]\tLoss: -142873497887287282868095549440.000000\n', 'Train Epoch: 1 [58880/60000 (98%)]\tLoss: -148966512352343911126485958656.000000\n', 'Train Epoch: 1 [59520/60000 (99%)]\tLoss: -143164811230882545542038028288.000000\n', 'Train Epoch: 1 [0/60000 (0%)]\tLoss: 0.001863\n', 'Train Epoch: 1 [640/60000 (1%)]\tLoss: -214531083075584.000000\n', 'Train Epoch: 1 [1280/60000 (2%)]\tLoss: -15717993315705001697345536.000000\n', 'Train Epoch: 1 [1920/60000 (3%)]\tLoss: -984269121646929311984254976.000000\n', 'Train Epoch: 1 [2560/60000 (4%)]\tLoss: -3148552259560833933912309760.000000\n', 'Train Epoch: 1 [3200/60000 (5%)]\tLoss: -5081805865938406106902560768.000000\n', 'Train Epoch: 1 [3840/60000 (6%)]\tLoss: -7065811925498999074415706112.000000\n', 'Train Epoch: 1 [4480/60000 (7%)]\tLoss: -9293816167975552664358354944.000000\n', 'Train Epoch: 1 [5120/60000 (9%)]\tLoss: -11140090867288390276980146176.000000\n', 'Train Epoch: 1 [5760/60000 (10%)]\tLoss: -13533079246985339944342388736.000000\n', 'Train Epoch: 1 [6400/60000 (11%)]\tLoss: -14663990391711341862707003392.000000\n', 'Train Epoch: 1 [7040/60000 (12%)]\tLoss: -17821645602963717396474363904.000000\n', 'Train Epoch: 1 [7680/60000 (13%)]\tLoss: -19392402684270680939687837696.000000\n', 'Train Epoch: 1 [8320/60000 (14%)]\tLoss: -22067594962617437735375339520.000000\n', 'Train Epoch: 1 [8960/60000 (15%)]\tLoss: -21635590515581281156403822592.000000\n', 'Train Epoch: 1 [9600/60000 (16%)]\tLoss: -23997640311265710343148535808.000000\n', 'Train Epoch: 1 [10240/60000 (17%)]\tLoss: -25315513486823383667757285376.000000\n', 'Train Epoch: 1 [10880/60000 (18%)]\tLoss: -29131808957357795793591861248.000000\n', 'Train Epoch: 1 [11520/60000 (19%)]\tLoss: -29977537570774920554912677888.000000\n', 'Train Epoch: 1 [12160/60000 (20%)]\tLoss: -32403344036344572821687500800.000000\n', 'Train Epoch: 1 [12800/60000 (21%)]\tLoss: -34616570813504606574345191424.000000\n', 'Train Epoch: 1 [13440/60000 (22%)]\tLoss: -35834063005919161285469011968.000000\n', 'Train Epoch: 1 [14080/60000 (23%)]\tLoss: -37805497535606544898717646848.000000\n', 'Train Epoch: 1 [14720/60000 (25%)]\tLoss: -39633409903146554254631632896.000000\n', 'Train Epoch: 1 [15360/60000 (26%)]\tLoss: -41778714883183473900180733952.000000\n', 'Train Epoch: 1 [16000/60000 (27%)]\tLoss: -43805360960605327970445295616.000000\n', 'Train Epoch: 1 [16640/60000 (28%)]\tLoss: -46587250387266041530091044864.000000\n', 'Train Epoch: 1 [17280/60000 (29%)]\tLoss: -48798777112492242210471804928.000000\n', 'Train Epoch: 1 [17920/60000 (30%)]\tLoss: -49775239719621130229888581632.000000\n', 'Train Epoch: 1 [18560/60000 (31%)]\tLoss: -51689007071002951170610167808.000000\n', 'Train Epoch: 1 [19200/60000 (32%)]\tLoss: -52311873042994008765361029120.000000\n', 'Train Epoch: 1 [19840/60000 (33%)]\tLoss: -52750977568037159855911337984.000000\n', 'Train Epoch: 1 [20480/60000 (34%)]\tLoss: -56380017040426341940087226368.000000\n', 'Train Epoch: 1 [21120/60000 (35%)]\tLoss: -56526693743384273120424624128.000000\n', 'Train Epoch: 1 [21760/60000 (36%)]\tLoss: -59885788580513177675250008064.000000\n', 'Train Epoch: 1 [22400/60000 (37%)]\tLoss: -59940657756677640082987941888.000000\n', 'Train Epoch: 1 [23040/60000 (38%)]\tLoss: -63336383990614164475735965696.000000\n', 'Train Epoch: 1 [23680/60000 (39%)]\tLoss: -62873870694915428553861365760.000000\n', 'Train Epoch: 1 [24320/60000 (41%)]\tLoss: -67119859014092632567335354368.000000\n', 'Train Epoch: 1 [24960/60000 (42%)]\tLoss: -69347385116962795605700116480.000000\n', 'Train Epoch: 1 [25600/60000 (43%)]\tLoss: -67527923424243881479896039424.000000\n', 'Train Epoch: 1 [26240/60000 (44%)]\tLoss: -73469524652760260303799713792.000000\n', 'Train Epoch: 1 [26880/60000 (45%)]\tLoss: -75040570979014299612782526464.000000\n', 'Train Epoch: 1 [27520/60000 (46%)]\tLoss: -72534548035183382117585256448.000000\n', 'Train Epoch: 1 [28160/60000 (47%)]\tLoss: -75928616718484419264863272960.000000\n', 'Train Epoch: 1 [28800/60000 (48%)]\tLoss: -78909808900188163331107848192.000000\n', 'Train Epoch: 1 [29440/60000 (49%)]\tLoss: -77012347880271691275309154304.000000\n', 'Train Epoch: 1 [30080/60000 (50%)]\tLoss: -83351836819168734926337998848.000000\n', 'Train Epoch: 1 [30720/60000 (51%)]\tLoss: -83536396346052246400579665920.000000\n', 'Train Epoch: 1 [31360/60000 (52%)]\tLoss: -84840487295029664665632243712.000000\n', 'Train Epoch: 1 [32000/60000 (53%)]\tLoss: -85268040911655716603989852160.000000\n', 'Train Epoch: 1 [32640/60000 (54%)]\tLoss: -86644960196531950537528049664.000000\n', 'Train Epoch: 1 [33280/60000 (55%)]\tLoss: -87687951502671506118715375616.000000\n', 'Train Epoch: 1 [33920/60000 (57%)]\tLoss: -90394840304851283973077204992.000000\n', 'Train Epoch: 1 [34560/60000 (58%)]\tLoss: -89859758403410290213203738624.000000\n', 'Train Epoch: 1 [35200/60000 (59%)]\tLoss: -94955087946364014266587021312.000000\n', 'Train Epoch: 1 [35840/60000 (60%)]\tLoss: -97785136066417032468122042368.000000\n', 'Train Epoch: 1 [36480/60000 (61%)]\tLoss: -97317404555754725588286308352.000000\n', 'Train Epoch: 1 [37120/60000 (62%)]\tLoss: -97235972068124121426221334528.000000\n', 'Train Epoch: 1 [37760/60000 (63%)]\tLoss: -102404554959960119416159469568.000000\n', 'Train Epoch: 1 [38400/60000 (64%)]\tLoss: -104825277798010962509861748736.000000\n', 'Train Epoch: 1 [39040/60000 (65%)]\tLoss: -108061147204135866542480949248.000000\n', 'Train Epoch: 1 [39680/60000 (66%)]\tLoss: -107362879206512829322603003904.000000\n', 'Train Epoch: 1 [40320/60000 (67%)]\tLoss: -106225336678653257704947056640.000000\n', 'Train Epoch: 1 [40960/60000 (68%)]\tLoss: -105227746203880010892844204032.000000\n', 'Train Epoch: 1 [41600/60000 (69%)]\tLoss: -114026497213694596812164300800.000000\n', 'Train Epoch: 1 [42240/60000 (70%)]\tLoss: -109199879768349121310730747904.000000\n', 'Train Epoch: 1 [42880/60000 (71%)]\tLoss: -109009558954356508869328371712.000000\n', 'Train Epoch: 1 [43520/60000 (72%)]\tLoss: -114228406715036171362921086976.000000\n', 'Train Epoch: 1 [44160/60000 (74%)]\tLoss: -113746073647208831540084604928.000000\n', 'Train Epoch: 1 [44800/60000 (75%)]\tLoss: -115463069431982440104041906176.000000\n', 'Train Epoch: 1 [45440/60000 (76%)]\tLoss: -118445328868511312710104776704.000000\n', 'Train Epoch: 1 [46080/60000 (77%)]\tLoss: -115241278767747984346935459840.000000\n', 'Train Epoch: 1 [46720/60000 (78%)]\tLoss: -120736942206920499703664607232.000000\n', 'Train Epoch: 1 [47360/60000 (79%)]\tLoss: -123859748714712538690577498112.000000\n', 'Train Epoch: 1 [48000/60000 (80%)]\tLoss: -125017635197380312739814047744.000000\n', 'Train Epoch: 1 [48640/60000 (81%)]\tLoss: -122789112675182264206309195776.000000\n', 'Train Epoch: 1 [49280/60000 (82%)]\tLoss: -125268128405097650200529338368.000000\n', 'Train Epoch: 1 [49920/60000 (83%)]\tLoss: -133097273683916474825282945024.000000\n', 'Train Epoch: 1 [50560/60000 (84%)]\tLoss: -130917523762753503987545145344.000000\n', 'Train Epoch: 1 [51200/60000 (85%)]\tLoss: -133620918013735958304448839680.000000\n', 'Train Epoch: 1 [51840/60000 (86%)]\tLoss: -133050229469014127419664105472.000000\n', 'Train Epoch: 1 [52480/60000 (87%)]\tLoss: -137947021280295045848973180928.000000\n', 'Train Epoch: 1 [53120/60000 (88%)]\tLoss: -134136005415488481986487517184.000000\n', 'Train Epoch: 1 [53760/60000 (90%)]\tLoss: -135001473520804001864801583104.000000\n', 'Train Epoch: 1 [54400/60000 (91%)]\tLoss: -138373696536755284033321041920.000000\n', 'Train Epoch: 1 [55040/60000 (92%)]\tLoss: -142220762947292074767368060928.000000\n', 'Train Epoch: 1 [55680/60000 (93%)]\tLoss: -143522568270891784124137209856.000000\n', 'Train Epoch: 1 [56320/60000 (94%)]\tLoss: -138884798261196265734799360000.000000\n', 'Train Epoch: 1 [56960/60000 (95%)]\tLoss: -140625188649526010521145311232.000000\n', 'Train Epoch: 1 [57600/60000 (96%)]\tLoss: -149440307381570222630776078336.000000\n', 'Train Epoch: 1 [58240/60000 (97%)]\tLoss: -142721532133868537685118812160.000000\n', 'Train Epoch: 1 [58880/60000 (98%)]\tLoss: -144346252877566873381600493568.000000\n', 'Train Epoch: 1 [59520/60000 (99%)]\tLoss: -144877651333151228818207277056.000000\n', '\n', 'Test set: Average loss: -150942098624193635277929971712.0000, Accuracy: 1009/10000 (10%)\n', '\n', '\n', 'Test set: Average loss: -150942096689912319982021115904.0000, Accuracy: 1009/10000 (10%)\n', '\n', '{"accuracy": 10.09, "runtime": 98.56036841403693, "mem_params": 244341408, "mem_bufs": 0, "mem_peak": 3344906752}\n']
[2021-12-11 15:40:49,671 DEBUG] Received error from gpu2: []
[2021-12-11 15:40:49,671 DEBUG] SSH connection with gpu2 has been closed
[2021-12-11 15:40:49,671 INFO] {'batch-size': 64, 'lr': 0.5, 'gamma': 0.7} => {"accuracy": 10.09, "runtime": 98.56036841403693, "mem_params": 244341408, "mem_bufs": 0, "mem_peak": 3344906752}
[2021-12-11 15:40:49,673 DEBUG] gpu2 finished training {'batch-size': 64, 'lr': 0.5, 'gamma': 0.7}
[2021-12-11 15:40:49,673 DEBUG] gpu2 now training {'batch-size': 64, 'lr': 0.9, 'gamma': 0.7}...
[2021-12-11 15:40:49,673 DEBUG] Attempting to establish SSH connection with gpu2...
[2021-12-11 15:40:50,278 DEBUG] Received output from gpu1: ['Train Epoch: 1 [0/60000 (0%)]\tLoss: 0.003708\n', 'Train Epoch: 1 [640/60000 (1%)]\tLoss: -280025374916608.000000\n', 'Train Epoch: 1 [1280/60000 (2%)]\tLoss: -17002990049115095242375168.000000\n', 'Train Epoch: 1 [1920/60000 (3%)]\tLoss: -1050255707742758697451913216.000000\n', 'Train Epoch: 1 [2560/60000 (4%)]\tLoss: -3210907862340170626078081024.000000\n', 'Train Epoch: 1 [3200/60000 (5%)]\tLoss: -5441195073863286510128726016.000000\n', 'Train Epoch: 1 [3840/60000 (6%)]\tLoss: -7640055231590810084635049984.000000\n', 'Train Epoch: 1 [4480/60000 (7%)]\tLoss: -9943778488549505924639752192.000000\n', 'Train Epoch: 1 [5120/60000 (9%)]\tLoss: -11690735327473680952655347712.000000\n', 'Train Epoch: 1 [5760/60000 (10%)]\tLoss: -13927447613744646168372051968.000000\n', 'Train Epoch: 1 [6400/60000 (11%)]\tLoss: -15646733746262446510257995776.000000\n', 'Train Epoch: 1 [7040/60000 (12%)]\tLoss: -17983815209760323165346594816.000000\n', 'Train Epoch: 1 [7680/60000 (13%)]\tLoss: -20066631475312670230605463552.000000\n', 'Train Epoch: 1 [8320/60000 (14%)]\tLoss: -21845303727535797795876241408.000000\n', 'Train Epoch: 1 [8960/60000 (15%)]\tLoss: -23869753904543117481116434432.000000\n', 'Train Epoch: 1 [9600/60000 (16%)]\tLoss: -25404024801811809427997589504.000000\n', 'Train Epoch: 1 [10240/60000 (17%)]\tLoss: -27542472905715602348696403968.000000\n', 'Train Epoch: 1 [10880/60000 (18%)]\tLoss: -30206466091948233780759625728.000000\n', 'Train Epoch: 1 [11520/60000 (19%)]\tLoss: -31279579012698773393942511616.000000\n', 'Train Epoch: 1 [12160/60000 (20%)]\tLoss: -34818303226103073513406464000.000000\n', 'Train Epoch: 1 [12800/60000 (21%)]\tLoss: -36214088365078371679573377024.000000\n', 'Train Epoch: 1 [13440/60000 (22%)]\tLoss: -37939239676767896120814731264.000000\n', 'Train Epoch: 1 [14080/60000 (23%)]\tLoss: -39519258499339387755703566336.000000\n', 'Train Epoch: 1 [14720/60000 (25%)]\tLoss: -41527777773016746692815355904.000000\n', 'Train Epoch: 1 [15360/60000 (26%)]\tLoss: -43891496925252870299143110656.000000\n', 'Train Epoch: 1 [16000/60000 (27%)]\tLoss: -45095440648228071998148837376.000000\n', 'Train Epoch: 1 [16640/60000 (28%)]\tLoss: -47981883268819519502825816064.000000\n', 'Train Epoch: 1 [17280/60000 (29%)]\tLoss: -49730136397343242248452571136.000000\n', 'Train Epoch: 1 [17920/60000 (30%)]\tLoss: -51271115416200850526359781376.000000\n', 'Train Epoch: 1 [18560/60000 (31%)]\tLoss: -52916118723943111349034287104.000000\n', 'Train Epoch: 1 [19200/60000 (32%)]\tLoss: -54409019329638623769020858368.000000\n', 'Train Epoch: 1 [19840/60000 (33%)]\tLoss: -56376144699910388831011995648.000000\n', 'Train Epoch: 1 [20480/60000 (34%)]\tLoss: -58815025037087865710560935936.000000\n', 'Train Epoch: 1 [21120/60000 (35%)]\tLoss: -59395252762105093278677336064.000000\n', 'Train Epoch: 1 [21760/60000 (36%)]\tLoss: -61469887527725868683603476480.000000\n', 'Train Epoch: 1 [22400/60000 (37%)]\tLoss: -62911163223030650142113923072.000000\n', 'Train Epoch: 1 [23040/60000 (38%)]\tLoss: -66752850858143452350262542336.000000\n', 'Train Epoch: 1 [23680/60000 (39%)]\tLoss: -69646731205945419546151092224.000000\n', 'Train Epoch: 1 [24320/60000 (41%)]\tLoss: -68753679758003458070143827968.000000\n', 'Train Epoch: 1 [24960/60000 (42%)]\tLoss: -71773836185557359579046608896.000000\n', 'Train Epoch: 1 [25600/60000 (43%)]\tLoss: -69207215835018258796467191808.000000\n', 'Train Epoch: 1 [26240/60000 (44%)]\tLoss: -73670621907066781275579744256.000000\n', 'Train Epoch: 1 [26880/60000 (45%)]\tLoss: -75505681576278613839524659200.000000\n', 'Train Epoch: 1 [27520/60000 (46%)]\tLoss: -79247817003566041056923353088.000000\n', 'Train Epoch: 1 [28160/60000 (47%)]\tLoss: -77101775334357793746720915456.000000\n', 'Train Epoch: 1 [28800/60000 (48%)]\tLoss: -80080181319836644722289410048.000000\n', 'Train Epoch: 1 [29440/60000 (49%)]\tLoss: -83049662032662872068404019200.000000\n', 'Train Epoch: 1 [30080/60000 (50%)]\tLoss: -86623662323694208437614280704.000000\n', 'Train Epoch: 1 [30720/60000 (51%)]\tLoss: -85182868309770679682915631104.000000\n', 'Train Epoch: 1 [31360/60000 (52%)]\tLoss: -87767400596379305029790597120.000000\n', 'Train Epoch: 1 [32000/60000 (53%)]\tLoss: -91666866385410017347128786944.000000\n', 'Train Epoch: 1 [32640/60000 (54%)]\tLoss: -91191919098761885649406525440.000000\n', 'Train Epoch: 1 [33280/60000 (55%)]\tLoss: -95308434296078252600056610816.000000\n', 'Train Epoch: 1 [33920/60000 (57%)]\tLoss: -93713568353284618800615915520.000000\n', 'Train Epoch: 1 [34560/60000 (58%)]\tLoss: -98024550602365557741166002176.000000\n', 'Train Epoch: 1 [35200/60000 (59%)]\tLoss: -98003876081903554434420441088.000000\n', 'Train Epoch: 1 [35840/60000 (60%)]\tLoss: -98526651496290189898867015680.000000\n', 'Train Epoch: 1 [36480/60000 (61%)]\tLoss: -102507379767758123071042486272.000000\n', 'Train Epoch: 1 [37120/60000 (62%)]\tLoss: -101635196457303962557234544640.000000\n', 'Train Epoch: 1 [37760/60000 (63%)]\tLoss: -103680831170353435470903377920.000000\n', 'Train Epoch: 1 [38400/60000 (64%)]\tLoss: -110533060494861016590299693056.000000\n', 'Train Epoch: 1 [39040/60000 (65%)]\tLoss: -108623892728433510684016246784.000000\n', 'Train Epoch: 1 [39680/60000 (66%)]\tLoss: -113282403371721792555132649472.000000\n', 'Train Epoch: 1 [40320/60000 (67%)]\tLoss: -111416237474487297638165118976.000000\n', 'Train Epoch: 1 [40960/60000 (68%)]\tLoss: -111736177803701716101393022976.000000\n', 'Train Epoch: 1 [41600/60000 (69%)]\tLoss: -116726670810735734031032254464.000000\n', 'Train Epoch: 1 [42240/60000 (70%)]\tLoss: -117540967352842878433810710528.000000\n', 'Train Epoch: 1 [42880/60000 (71%)]\tLoss: -117230632317054616828947464192.000000\n', 'Train Epoch: 1 [43520/60000 (72%)]\tLoss: -121547961426688532572664758272.000000\n', 'Train Epoch: 1 [44160/60000 (74%)]\tLoss: -116478982688709221139573899264.000000\n', 'Train Epoch: 1 [44800/60000 (75%)]\tLoss: -119551165427804897529795969024.000000\n', 'Train Epoch: 1 [45440/60000 (76%)]\tLoss: -126063884936393048376198823936.000000\n', 'Train Epoch: 1 [46080/60000 (77%)]\tLoss: -119866241719541960258453766144.000000\n', 'Train Epoch: 1 [46720/60000 (78%)]\tLoss: -125364644131274540009406857216.000000\n', 'Train Epoch: 1 [47360/60000 (79%)]\tLoss: -124384847533408746020469211136.000000\n', 'Train Epoch: 1 [48000/60000 (80%)]\tLoss: -128025263186655161079964893184.000000\n', 'Train Epoch: 1 [48640/60000 (81%)]\tLoss: -128558201133712932020911341568.000000\n', 'Train Epoch: 1 [49280/60000 (82%)]\tLoss: -130757803883569886847127519232.000000\n', 'Train Epoch: 1 [49920/60000 (83%)]\tLoss: -132672459039850487281149280256.000000\n', 'Train Epoch: 1 [50560/60000 (84%)]\tLoss: -132242827581971972698897645568.000000\n', 'Train Epoch: 1 [51200/60000 (85%)]\tLoss: -135650062223027250417031446528.000000\n', 'Train Epoch: 1 [51840/60000 (86%)]\tLoss: -134987041968832352229028528128.000000\n', 'Train Epoch: 1 [52480/60000 (87%)]\tLoss: -135283993818008161259356160000.000000\n', 'Train Epoch: 1 [53120/60000 (88%)]\tLoss: -145516606407749423294201200640.000000\n', 'Train Epoch: 1 [53760/60000 (90%)]\tLoss: -138416197835101110840244305920.000000\n', 'Train Epoch: 1 [54400/60000 (91%)]\tLoss: -144689257244683627192052088832.000000\n', 'Train Epoch: 1 [55040/60000 (92%)]\tLoss: -142877105775280195277038813184.000000\n', 'Train Epoch: 1 [55680/60000 (93%)]\tLoss: -146735080852392414891529469952.000000\n', 'Train Epoch: 1 [56320/60000 (94%)]\tLoss: -142562426162327693598578966528.000000\n', 'Train Epoch: 1 [56960/60000 (95%)]\tLoss: -146297884163408343137645494272.000000\n', 'Train Epoch: 1 [57600/60000 (96%)]\tLoss: -150114160744476823784899215360.000000\n', 'Train Epoch: 1 [58240/60000 (97%)]\tLoss: -149223409089012019826111021056.000000\n', 'Train Epoch: 1 [58880/60000 (98%)]\tLoss: -154423915178272216617693741056.000000\n', 'Train Epoch: 1 [59520/60000 (99%)]\tLoss: -150039046783200299208130166784.000000\n', 'Train Epoch: 1 [0/60000 (0%)]\tLoss: 0.002807\n', 'Train Epoch: 1 [640/60000 (1%)]\tLoss: -316573415899136.000000\n', 'Train Epoch: 1 [1280/60000 (2%)]\tLoss: -16592320562095640956370944.000000\n', 'Train Epoch: 1 [1920/60000 (3%)]\tLoss: -1013660097618641856059408384.000000\n', 'Train Epoch: 1 [2560/60000 (4%)]\tLoss: -3309267082332810672705896448.000000\n', 'Train Epoch: 1 [3200/60000 (5%)]\tLoss: -5366272958725128512696483840.000000\n', 'Train Epoch: 1 [3840/60000 (6%)]\tLoss: -7939774977821391085763559424.000000\n', 'Train Epoch: 1 [4480/60000 (7%)]\tLoss: -9746015815275701281086242816.000000\n', 'Train Epoch: 1 [5120/60000 (9%)]\tLoss: -11644041748282686618193625088.000000\n', 'Train Epoch: 1 [5760/60000 (10%)]\tLoss: -13732929796540383329786003456.000000\n', 'Train Epoch: 1 [6400/60000 (11%)]\tLoss: -15524494109261745026490171392.000000\n', 'Train Epoch: 1 [7040/60000 (12%)]\tLoss: -17943134383693642606653210624.000000\n', 'Train Epoch: 1 [7680/60000 (13%)]\tLoss: -20389008545632249430763634688.000000\n', 'Train Epoch: 1 [8320/60000 (14%)]\tLoss: -21832319580891147706361184256.000000\n', 'Train Epoch: 1 [8960/60000 (15%)]\tLoss: -23938608369046598343154728960.000000\n', 'Train Epoch: 1 [9600/60000 (16%)]\tLoss: -25806556959628376551190429696.000000\n', 'Train Epoch: 1 [10240/60000 (17%)]\tLoss: -28430147939416816733627875328.000000\n', 'Train Epoch: 1 [10880/60000 (18%)]\tLoss: -28892621095000448263518158848.000000\n', 'Train Epoch: 1 [11520/60000 (19%)]\tLoss: -32189076101917328409406472192.000000\n', 'Train Epoch: 1 [12160/60000 (20%)]\tLoss: -33443381502249093439793659904.000000\n', 'Train Epoch: 1 [12800/60000 (21%)]\tLoss: -35968480445487562866831654912.000000\n', 'Train Epoch: 1 [13440/60000 (22%)]\tLoss: -39008168580814613228338282496.000000\n', 'Train Epoch: 1 [14080/60000 (23%)]\tLoss: -39592412678525521429708931072.000000\n', 'Train Epoch: 1 [14720/60000 (25%)]\tLoss: -42589261866303219804659515392.000000\n', 'Train Epoch: 1 [15360/60000 (26%)]\tLoss: -44172213278460573489226055680.000000\n', 'Train Epoch: 1 [16000/60000 (27%)]\tLoss: -45404292860940712534414983168.000000\n', 'Train Epoch: 1 [16640/60000 (28%)]\tLoss: -47227839400667308903328907264.000000\n', 'Train Epoch: 1 [17280/60000 (29%)]\tLoss: -49349636440352503455004229632.000000\n', 'Train Epoch: 1 [17920/60000 (30%)]\tLoss: -51395800058448057768936996864.000000\n', 'Train Epoch: 1 [18560/60000 (31%)]\tLoss: -53740880030176294885606293504.000000\n', 'Train Epoch: 1 [19200/60000 (32%)]\tLoss: -55661376753796205070757396480.000000\n', 'Train Epoch: 1 [19840/60000 (33%)]\tLoss: -58110117392189913769512534016.000000\n', 'Train Epoch: 1 [20480/60000 (34%)]\tLoss: -58873100700094196607398969344.000000\n', 'Train Epoch: 1 [21120/60000 (35%)]\tLoss: -60288507271805818149428789248.000000\n', 'Train Epoch: 1 [21760/60000 (36%)]\tLoss: -59651275860973871093937864704.000000\n', 'Train Epoch: 1 [22400/60000 (37%)]\tLoss: -64352471974900811688140865536.000000\n', 'Train Epoch: 1 [23040/60000 (38%)]\tLoss: -65561652802305515823688581120.000000\n', 'Train Epoch: 1 [23680/60000 (39%)]\tLoss: -66747065959201937034875764736.000000\n', 'Train Epoch: 1 [24320/60000 (41%)]\tLoss: -67628221765973549874589728768.000000\n', 'Train Epoch: 1 [24960/60000 (42%)]\tLoss: -69646547033652587629987758080.000000\n', 'Train Epoch: 1 [25600/60000 (43%)]\tLoss: -75283262837301936419604791296.000000\n', 'Train Epoch: 1 [26240/60000 (44%)]\tLoss: -75607037728100445034746216448.000000\n', 'Train Epoch: 1 [26880/60000 (45%)]\tLoss: -75572989465758954892755468288.000000\n', 'Train Epoch: 1 [27520/60000 (46%)]\tLoss: -79741360969423713417497149440.000000\n', 'Train Epoch: 1 [28160/60000 (47%)]\tLoss: -80366148944573298957849985024.000000\n', 'Train Epoch: 1 [28800/60000 (48%)]\tLoss: -80291261656887952124051193856.000000\n', 'Train Epoch: 1 [29440/60000 (49%)]\tLoss: -80295662902449986633390358528.000000\n', 'Train Epoch: 1 [30080/60000 (50%)]\tLoss: -84350362322505589928193163264.000000\n', 'Train Epoch: 1 [30720/60000 (51%)]\tLoss: -81562399932547906004802600960.000000\n', 'Train Epoch: 1 [31360/60000 (52%)]\tLoss: -88443029569083465170514083840.000000\n', 'Train Epoch: 1 [32000/60000 (53%)]\tLoss: -89867049737259840945413685248.000000\n', 'Train Epoch: 1 [32640/60000 (54%)]\tLoss: -90308997126925679562382639104.000000\n', 'Train Epoch: 1 [33280/60000 (55%)]\tLoss: -92587453952313591724377112576.000000\n', 'Train Epoch: 1 [33920/60000 (57%)]\tLoss: -91728748275801541178009059328.000000\n', 'Train Epoch: 1 [34560/60000 (58%)]\tLoss: -99985296055518965912473436160.000000\n', 'Train Epoch: 1 [35200/60000 (59%)]\tLoss: -98837628773920121775479324672.000000\n', 'Train Epoch: 1 [35840/60000 (60%)]\tLoss: -97342593658574352275856162816.000000\n', 'Train Epoch: 1 [36480/60000 (61%)]\tLoss: -99483384056253648540580970496.000000\n', 'Train Epoch: 1 [37120/60000 (62%)]\tLoss: -101886454688391524900474454016.000000\n', 'Train Epoch: 1 [37760/60000 (63%)]\tLoss: -106479088319243775220859797504.000000\n', 'Train Epoch: 1 [38400/60000 (64%)]\tLoss: -105643210562309916539454750720.000000\n', 'Train Epoch: 1 [39040/60000 (65%)]\tLoss: -106535652824975587831229448192.000000\n', 'Train Epoch: 1 [39680/60000 (66%)]\tLoss: -111868016831170470856468987904.000000\n', 'Train Epoch: 1 [40320/60000 (67%)]\tLoss: -108150041030809404743983562752.000000\n', 'Train Epoch: 1 [40960/60000 (68%)]\tLoss: -112056533701166627093399732224.000000\n', 'Train Epoch: 1 [41600/60000 (69%)]\tLoss: -113240515981018738802087165952.000000\n', 'Train Epoch: 1 [42240/60000 (70%)]\tLoss: -114726984723564582765292683264.000000\n', 'Train Epoch: 1 [42880/60000 (71%)]\tLoss: -115823914899671475434110844928.000000\n', 'Train Epoch: 1 [43520/60000 (72%)]\tLoss: -117967434825177870353769168896.000000\n', 'Train Epoch: 1 [44160/60000 (74%)]\tLoss: -120605122068917676427169497088.000000\n', 'Train Epoch: 1 [44800/60000 (75%)]\tLoss: -121851515144207393367001137152.000000\n', 'Train Epoch: 1 [45440/60000 (76%)]\tLoss: -123363050208044309407000952832.000000\n', 'Train Epoch: 1 [46080/60000 (77%)]\tLoss: -124429011104756542942507696128.000000\n', 'Train Epoch: 1 [46720/60000 (78%)]\tLoss: -125210430531409948875308400640.000000\n', 'Train Epoch: 1 [47360/60000 (79%)]\tLoss: -126841942038110651121607376896.000000\n', 'Train Epoch: 1 [48000/60000 (80%)]\tLoss: -128592523293310428602324484096.000000\n', 'Train Epoch: 1 [48640/60000 (81%)]\tLoss: -128384880839058650302278270976.000000\n', 'Train Epoch: 1 [49280/60000 (82%)]\tLoss: -133310290191225758781582344192.000000\n', 'Train Epoch: 1 [49920/60000 (83%)]\tLoss: -126560829006118386881326481408.000000\n', 'Train Epoch: 1 [50560/60000 (84%)]\tLoss: -134034276196714504089294077952.000000\n', 'Train Epoch: 1 [51200/60000 (85%)]\tLoss: -134829437709833060689666637824.000000\n', 'Train Epoch: 1 [51840/60000 (86%)]\tLoss: -134873714617976446483190251520.000000\n', 'Train Epoch: 1 [52480/60000 (87%)]\tLoss: -144021495734539927880254619648.000000\n', 'Train Epoch: 1 [53120/60000 (88%)]\tLoss: -141044591461602629451864080384.000000\n', 'Train Epoch: 1 [53760/60000 (90%)]\tLoss: -137963984020701513614580776960.000000\n', 'Train Epoch: 1 [54400/60000 (91%)]\tLoss: -139858833571952958756576296960.000000\n', 'Train Epoch: 1 [55040/60000 (92%)]\tLoss: -146239865168799806676550025216.000000\n', 'Train Epoch: 1 [55680/60000 (93%)]\tLoss: -144031960498665967014048169984.000000\n', 'Train Epoch: 1 [56320/60000 (94%)]\tLoss: -144496178568665018877844914176.000000\n', 'Train Epoch: 1 [56960/60000 (95%)]\tLoss: -150712541246254202269217062912.000000\n', 'Train Epoch: 1 [57600/60000 (96%)]\tLoss: -147264977595435217780958298112.000000\n', 'Train Epoch: 1 [58240/60000 (97%)]\tLoss: -149522646563565537764722081792.000000\n', 'Train Epoch: 1 [58880/60000 (98%)]\tLoss: -154185586786614751363048931328.000000\n', 'Train Epoch: 1 [59520/60000 (99%)]\tLoss: -152715891889816060379642462208.000000\n', '\n', 'Test set: Average loss: -155801045194030390148316790784.0000, Accuracy: 1135/10000 (11%)\n', '\n', '\n', 'Test set: Average loss: -155801051964014967295718719488.0000, Accuracy: 1135/10000 (11%)\n', '\n', '{"accuracy": 11.35, "runtime": 99.16920200129971, "mem_params": 244341408, "mem_bufs": 0, "mem_peak": 3344906752}\n']
[2021-12-11 15:40:50,279 DEBUG] Received error from gpu1: []
[2021-12-11 15:40:50,279 DEBUG] SSH connection with gpu1 has been closed
[2021-12-11 15:40:50,279 INFO] {'batch-size': 64, 'lr': 0.5, 'gamma': 0.9} => {"accuracy": 11.35, "runtime": 99.16920200129971, "mem_params": 244341408, "mem_bufs": 0, "mem_peak": 3344906752}
[2021-12-11 15:40:50,281 DEBUG] gpu1 finished training {'batch-size': 64, 'lr': 0.5, 'gamma': 0.9}
[2021-12-11 15:40:50,282 DEBUG] gpu1 now training {'batch-size': 64, 'lr': 0.9, 'gamma': 0.9}...
[2021-12-11 15:40:50,282 DEBUG] Attempting to establish SSH connection with gpu1...
[2021-12-11 15:40:50,381 DEBUG] SSH connection with gpu1 established successfully!
[2021-12-11 15:40:50,381 DEBUG] Running cmd on gpu1: source /u5/p3basta/CS848/CS848-Project/venv/bin/activate && python /u5/p3basta/CS848/CS848-Project/models/MNIST/train.py --arch "alexnet" --parallelism "dp" --epochs "1" --batch-size "64" --lr "0.9" --gamma "0.9"
[2021-12-11 15:40:50,381 INFO] Training {'batch-size': 64, 'lr': 0.9, 'gamma': 0.9} on gpu1...
[2021-12-11 15:40:50,756 DEBUG] SSH connection with gpu2 established successfully!
[2021-12-11 15:40:50,756 DEBUG] Running cmd on gpu2: source /u5/p3basta/CS848/CS848-Project/venv/bin/activate && python /u5/p3basta/CS848/CS848-Project/models/MNIST/train.py --arch "alexnet" --parallelism "dp" --epochs "1" --batch-size "64" --lr "0.9" --gamma "0.7"
[2021-12-11 15:40:50,757 INFO] Training {'batch-size': 64, 'lr': 0.9, 'gamma': 0.7} on gpu2...
[2021-12-11 15:42:30,341 DEBUG] Received output from gpu3: ['Train Epoch: 1 [0/60000 (0%)]\tLoss: -0.002679\n', 'Train Epoch: 1 [640/60000 (1%)]\tLoss: -152286105658458112.000000\n', 'Train Epoch: 1 [1280/60000 (2%)]\tLoss: -63708819031095877453217792.000000\n', 'Train Epoch: 1 [1920/60000 (3%)]\tLoss: -1797123718663319986531991552.000000\n', 'Train Epoch: 1 [2560/60000 (4%)]\tLoss: -4422896431766845945058164736.000000\n', 'Train Epoch: 1 [3200/60000 (5%)]\tLoss: -6891344095789380031995707392.000000\n', 'Train Epoch: 1 [3840/60000 (6%)]\tLoss: -9447042793245224042607149056.000000\n', 'Train Epoch: 1 [4480/60000 (7%)]\tLoss: -11997791860331210306328985600.000000\n', 'Train Epoch: 1 [5120/60000 (9%)]\tLoss: -14379120717181954819658612736.000000\n', 'Train Epoch: 1 [5760/60000 (10%)]\tLoss: -16679285080699998023289143296.000000\n', 'Train Epoch: 1 [6400/60000 (11%)]\tLoss: -18417304841055342247737819136.000000\n', 'Train Epoch: 1 [7040/60000 (12%)]\tLoss: -21345160254518315106116304896.000000\n', 'Train Epoch: 1 [7680/60000 (13%)]\tLoss: -23504377326213768726464954368.000000\n', 'Train Epoch: 1 [8320/60000 (14%)]\tLoss: -26225371837077878211080093696.000000\n', 'Train Epoch: 1 [8960/60000 (15%)]\tLoss: -29195464096363637176249876480.000000\n', 'Train Epoch: 1 [9600/60000 (16%)]\tLoss: -31084384716495839478679601152.000000\n', 'Train Epoch: 1 [10240/60000 (17%)]\tLoss: -32751911351178147074200829952.000000\n', 'Train Epoch: 1 [10880/60000 (18%)]\tLoss: -35248043298410694097498013696.000000\n', 'Train Epoch: 1 [11520/60000 (19%)]\tLoss: -37046580185244012825360203776.000000\n', 'Train Epoch: 1 [12160/60000 (20%)]\tLoss: -39912615099079739158246195200.000000\n', 'Train Epoch: 1 [12800/60000 (21%)]\tLoss: -43130898412422436632089591808.000000\n', 'Train Epoch: 1 [13440/60000 (22%)]\tLoss: -43593718661942559080903081984.000000\n', 'Train Epoch: 1 [14080/60000 (23%)]\tLoss: -47309678011815439854882258944.000000\n', 'Train Epoch: 1 [14720/60000 (25%)]\tLoss: -47187855123656851617304543232.000000\n', 'Train Epoch: 1 [15360/60000 (26%)]\tLoss: -52827923807509037855023300608.000000\n', 'Train Epoch: 1 [16000/60000 (27%)]\tLoss: -51901825238919954601810591744.000000\n', 'Train Epoch: 1 [16640/60000 (28%)]\tLoss: -56190532085301197425887674368.000000\n', 'Train Epoch: 1 [17280/60000 (29%)]\tLoss: -58497545060811022332489367552.000000\n', 'Train Epoch: 1 [17920/60000 (30%)]\tLoss: -57163410416269587384587255808.000000\n', 'Train Epoch: 1 [18560/60000 (31%)]\tLoss: -62373894865908087736506515456.000000\n', 'Train Epoch: 1 [19200/60000 (32%)]\tLoss: -62137072909158657898684874752.000000\n', 'Train Epoch: 1 [19840/60000 (33%)]\tLoss: -66499902019855022674036129792.000000\n', 'Train Epoch: 1 [20480/60000 (34%)]\tLoss: -67535006973968185947716583424.000000\n', 'Train Epoch: 1 [21120/60000 (35%)]\tLoss: -71474041471758863022300332032.000000\n', 'Train Epoch: 1 [21760/60000 (36%)]\tLoss: -72051884401702241419583815680.000000\n', 'Train Epoch: 1 [22400/60000 (37%)]\tLoss: -74813684881344827508490502144.000000\n', 'Train Epoch: 1 [23040/60000 (38%)]\tLoss: -75146588106554723147830001664.000000\n', 'Train Epoch: 1 [23680/60000 (39%)]\tLoss: -79287891005539672866206777344.000000\n', 'Train Epoch: 1 [24320/60000 (41%)]\tLoss: -78168690149099566950560825344.000000\n', 'Train Epoch: 1 [24960/60000 (42%)]\tLoss: -83875877827772779455701843968.000000\n', 'Train Epoch: 1 [25600/60000 (43%)]\tLoss: -88339231953789990368717045760.000000\n', 'Train Epoch: 1 [26240/60000 (44%)]\tLoss: -88703439746414828886178136064.000000\n', 'Train Epoch: 1 [26880/60000 (45%)]\tLoss: -89097247332154294339838672896.000000\n', 'Train Epoch: 1 [27520/60000 (46%)]\tLoss: -89069328701507568997335302144.000000\n', 'Train Epoch: 1 [28160/60000 (47%)]\tLoss: -93095278354415461892077125632.000000\n', 'Train Epoch: 1 [28800/60000 (48%)]\tLoss: -93216898180815286734910652416.000000\n', 'Train Epoch: 1 [29440/60000 (49%)]\tLoss: -93535846813068302572643680256.000000\n', 'Train Epoch: 1 [30080/60000 (50%)]\tLoss: -95145644878680770190250082304.000000\n', 'Train Epoch: 1 [30720/60000 (51%)]\tLoss: -98338276297288519751292682240.000000\n', 'Train Epoch: 1 [31360/60000 (52%)]\tLoss: -103134651707677698044777725952.000000\n', 'Train Epoch: 1 [32000/60000 (53%)]\tLoss: -102363290921632804456282193920.000000\n', 'Train Epoch: 1 [32640/60000 (54%)]\tLoss: -106716056669354174017683062784.000000\n', 'Train Epoch: 1 [33280/60000 (55%)]\tLoss: -109246064512551586440920694784.000000\n', 'Train Epoch: 1 [33920/60000 (57%)]\tLoss: -106692416502740928573743300608.000000\n', 'Train Epoch: 1 [34560/60000 (58%)]\tLoss: -109057708203015847771927216128.000000\n', 'Train Epoch: 1 [35200/60000 (59%)]\tLoss: -112196627425247437988309237760.000000\n', 'Train Epoch: 1 [35840/60000 (60%)]\tLoss: -113966542048828083796531216384.000000\n', 'Train Epoch: 1 [36480/60000 (61%)]\tLoss: -114489279684282856303816081408.000000\n', 'Train Epoch: 1 [37120/60000 (62%)]\tLoss: -117961947435324775826030854144.000000\n', 'Train Epoch: 1 [37760/60000 (63%)]\tLoss: -113990097212844637586857132032.000000\n', 'Train Epoch: 1 [38400/60000 (64%)]\tLoss: -120014882926956765211200061440.000000\n', 'Train Epoch: 1 [39040/60000 (65%)]\tLoss: -123591159398632844749403324416.000000\n', 'Train Epoch: 1 [39680/60000 (66%)]\tLoss: -120709854712774759418718846976.000000\n', 'Train Epoch: 1 [40320/60000 (67%)]\tLoss: -124734680442459729337899810816.000000\n', 'Train Epoch: 1 [40960/60000 (68%)]\tLoss: -128243993757408717306972864512.000000\n', 'Train Epoch: 1 [41600/60000 (69%)]\tLoss: -128435192931567143502384988160.000000\n', 'Train Epoch: 1 [42240/60000 (70%)]\tLoss: -134076626379332879067570503680.000000\n', 'Train Epoch: 1 [42880/60000 (71%)]\tLoss: -132791604346213288429890830336.000000\n', 'Train Epoch: 1 [43520/60000 (72%)]\tLoss: -134391126542359031699512229888.000000\n', 'Train Epoch: 1 [44160/60000 (74%)]\tLoss: -138151650864730753315373056000.000000\n', 'Train Epoch: 1 [44800/60000 (75%)]\tLoss: -139665254325087166259976470528.000000\n', 'Train Epoch: 1 [45440/60000 (76%)]\tLoss: -141959965535909115740796485632.000000\n', 'Train Epoch: 1 [46080/60000 (77%)]\tLoss: -149147822891087208284820602880.000000\n', 'Train Epoch: 1 [46720/60000 (78%)]\tLoss: -141787126922636086725975212032.000000\n', 'Train Epoch: 1 [47360/60000 (79%)]\tLoss: -143049132141518170712883331072.000000\n', 'Train Epoch: 1 [48000/60000 (80%)]\tLoss: -144804671881524961321074819072.000000\n', 'Train Epoch: 1 [48640/60000 (81%)]\tLoss: -147423838003918952645947031552.000000\n', 'Train Epoch: 1 [49280/60000 (82%)]\tLoss: -151812984863024349954074214400.000000\n', 'Train Epoch: 1 [49920/60000 (83%)]\tLoss: -147554571997630715904042991616.000000\n', 'Train Epoch: 1 [50560/60000 (84%)]\tLoss: -154252143819824316142690762752.000000\n', 'Train Epoch: 1 [51200/60000 (85%)]\tLoss: -157139946481962830105189285888.000000\n', 'Train Epoch: 1 [51840/60000 (86%)]\tLoss: -156117280241165545477001707520.000000\n', 'Train Epoch: 1 [52480/60000 (87%)]\tLoss: -152628159765297308110862417920.000000\n', 'Train Epoch: 1 [53120/60000 (88%)]\tLoss: -159865649192210360626082480128.000000\n', 'Train Epoch: 1 [53760/60000 (90%)]\tLoss: -157148097286512263112828125184.000000\n', 'Train Epoch: 1 [54400/60000 (91%)]\tLoss: -164872868821326702839068622848.000000\n', 'Train Epoch: 1 [55040/60000 (92%)]\tLoss: -158859237336847113316720443392.000000\n', 'Train Epoch: 1 [55680/60000 (93%)]\tLoss: -163813283119366343324600369152.000000\n', 'Train Epoch: 1 [56320/60000 (94%)]\tLoss: -166985428912171404364705955840.000000\n', 'Train Epoch: 1 [56960/60000 (95%)]\tLoss: -172686987529997036252752248832.000000\n', 'Train Epoch: 1 [57600/60000 (96%)]\tLoss: -164805716769940296484129865728.000000\n', 'Train Epoch: 1 [58240/60000 (97%)]\tLoss: -166803938923501758159853191168.000000\n', 'Train Epoch: 1 [58880/60000 (98%)]\tLoss: -176041700011029837776819322880.000000\n', 'Train Epoch: 1 [59520/60000 (99%)]\tLoss: -175388332273925925143633199104.000000\n', 'Train Epoch: 1 [0/60000 (0%)]\tLoss: -0.006635\n', 'Train Epoch: 1 [640/60000 (1%)]\tLoss: -154757464200314880.000000\n', 'Train Epoch: 1 [1280/60000 (2%)]\tLoss: -64823140723728487192461312.000000\n', 'Train Epoch: 1 [1920/60000 (3%)]\tLoss: -1790835297395568695224303616.000000\n', 'Train Epoch: 1 [2560/60000 (4%)]\tLoss: -4486122720866461728060211200.000000\n', 'Train Epoch: 1 [3200/60000 (5%)]\tLoss: -7085416239656822047814713344.000000\n', 'Train Epoch: 1 [3840/60000 (6%)]\tLoss: -9257450404282594243978985472.000000\n', 'Train Epoch: 1 [4480/60000 (7%)]\tLoss: -11846148408424920976638083072.000000\n', 'Train Epoch: 1 [5120/60000 (9%)]\tLoss: -14845215927857947367427801088.000000\n', 'Train Epoch: 1 [5760/60000 (10%)]\tLoss: -16153974936103682276774117376.000000\n', 'Train Epoch: 1 [6400/60000 (11%)]\tLoss: -18983334771241822227519242240.000000\n', 'Train Epoch: 1 [7040/60000 (12%)]\tLoss: -21281982074527243557624872960.000000\n', 'Train Epoch: 1 [7680/60000 (13%)]\tLoss: -23519321254948809718743695360.000000\n', 'Train Epoch: 1 [8320/60000 (14%)]\tLoss: -26704597587759489807365963776.000000\n', 'Train Epoch: 1 [8960/60000 (15%)]\tLoss: -27514490523121358265982648320.000000\n', 'Train Epoch: 1 [9600/60000 (16%)]\tLoss: -30533997625283865198668546048.000000\n', 'Train Epoch: 1 [10240/60000 (17%)]\tLoss: -33416296369286594589670506496.000000\n', 'Train Epoch: 1 [10880/60000 (18%)]\tLoss: -34744558751106581133749387264.000000\n', 'Train Epoch: 1 [11520/60000 (19%)]\tLoss: -37185018719872577909622308864.000000\n', 'Train Epoch: 1 [12160/60000 (20%)]\tLoss: -40579328243864241408806223872.000000\n', 'Train Epoch: 1 [12800/60000 (21%)]\tLoss: -43917399105411410303140233216.000000\n', 'Train Epoch: 1 [13440/60000 (22%)]\tLoss: -43743096558528691698302713856.000000\n', 'Train Epoch: 1 [14080/60000 (23%)]\tLoss: -47133878474757651572511997952.000000\n', 'Train Epoch: 1 [14720/60000 (25%)]\tLoss: -48708258791748596851015680000.000000\n', 'Train Epoch: 1 [15360/60000 (26%)]\tLoss: -49746395505143762436923326464.000000\n', 'Train Epoch: 1 [16000/60000 (27%)]\tLoss: -51592670794752410408250769408.000000\n', 'Train Epoch: 1 [16640/60000 (28%)]\tLoss: -53586656985578738012217409536.000000\n', 'Train Epoch: 1 [17280/60000 (29%)]\tLoss: -57430965534089532873459630080.000000\n', 'Train Epoch: 1 [17920/60000 (30%)]\tLoss: -58810826853284594595965960192.000000\n', 'Train Epoch: 1 [18560/60000 (31%)]\tLoss: -61955087072008310381084672000.000000\n', 'Train Epoch: 1 [19200/60000 (32%)]\tLoss: -65267761046610606323459424256.000000\n', 'Train Epoch: 1 [19840/60000 (33%)]\tLoss: -67508849786019570982877921280.000000\n', 'Train Epoch: 1 [20480/60000 (34%)]\tLoss: -70095573250676247845132042240.000000\n', 'Train Epoch: 1 [21120/60000 (35%)]\tLoss: -71766568463540223195062730752.000000\n', 'Train Epoch: 1 [21760/60000 (36%)]\tLoss: -70927739227554570985399123968.000000\n', 'Train Epoch: 1 [22400/60000 (37%)]\tLoss: -74130788186623530983783137280.000000\n', 'Train Epoch: 1 [23040/60000 (38%)]\tLoss: -77279969111222396939214520320.000000\n', 'Train Epoch: 1 [23680/60000 (39%)]\tLoss: -80196398758980066690998468608.000000\n', 'Train Epoch: 1 [24320/60000 (41%)]\tLoss: -80826513563522329191152353280.000000\n', 'Train Epoch: 1 [24960/60000 (42%)]\tLoss: -82256653918660504026248904704.000000\n', 'Train Epoch: 1 [25600/60000 (43%)]\tLoss: -83059475110214275191158079488.000000\n', 'Train Epoch: 1 [26240/60000 (44%)]\tLoss: -86654981058208599924671512576.000000\n', 'Train Epoch: 1 [26880/60000 (45%)]\tLoss: -87919234123536529862701350912.000000\n', 'Train Epoch: 1 [27520/60000 (46%)]\tLoss: -90742094801802620464221126656.000000\n', 'Train Epoch: 1 [28160/60000 (47%)]\tLoss: -90500082964288516886309634048.000000\n', 'Train Epoch: 1 [28800/60000 (48%)]\tLoss: -96773529607922628549024940032.000000\n', 'Train Epoch: 1 [29440/60000 (49%)]\tLoss: -99848866887828861862249758720.000000\n', 'Train Epoch: 1 [30080/60000 (50%)]\tLoss: -98356712416037642846206951424.000000\n', 'Train Epoch: 1 [30720/60000 (51%)]\tLoss: -103208537853668676513791213568.000000\n', 'Train Epoch: 1 [31360/60000 (52%)]\tLoss: -101493837139005742597407768576.000000\n', 'Train Epoch: 1 [32000/60000 (53%)]\tLoss: -101498446168693023371136335872.000000\n', 'Train Epoch: 1 [32640/60000 (54%)]\tLoss: -103302286273086604710573506560.000000\n', 'Train Epoch: 1 [33280/60000 (55%)]\tLoss: -105380420312271186522602995712.000000\n', 'Train Epoch: 1 [33920/60000 (57%)]\tLoss: -111392238408021354101189115904.000000\n', 'Train Epoch: 1 [34560/60000 (58%)]\tLoss: -111707768046940772315787427840.000000\n', 'Train Epoch: 1 [35200/60000 (59%)]\tLoss: -110768536577162828579235430400.000000\n', 'Train Epoch: 1 [35840/60000 (60%)]\tLoss: -117000256390554304056842518528.000000\n', 'Train Epoch: 1 [36480/60000 (61%)]\tLoss: -121455214148964972740667768832.000000\n', 'Train Epoch: 1 [37120/60000 (62%)]\tLoss: -119538367814636320791266852864.000000\n', 'Train Epoch: 1 [37760/60000 (63%)]\tLoss: -115643652726287375337013641216.000000\n', 'Train Epoch: 1 [38400/60000 (64%)]\tLoss: -122063709959748658005033353216.000000\n', 'Train Epoch: 1 [39040/60000 (65%)]\tLoss: -126429433881099021872900603904.000000\n', 'Train Epoch: 1 [39680/60000 (66%)]\tLoss: -117224228788103845590037692416.000000\n', 'Train Epoch: 1 [40320/60000 (67%)]\tLoss: -131258327507089240543327158272.000000\n', 'Train Epoch: 1 [40960/60000 (68%)]\tLoss: -126559884532821812952283742208.000000\n', 'Train Epoch: 1 [41600/60000 (69%)]\tLoss: -126377771191776427954262769664.000000\n', 'Train Epoch: 1 [42240/60000 (70%)]\tLoss: -133368630306755130378552344576.000000\n', 'Train Epoch: 1 [42880/60000 (71%)]\tLoss: -130453815708334602045431480320.000000\n', 'Train Epoch: 1 [43520/60000 (72%)]\tLoss: -136268125548305229582599979008.000000\n', 'Train Epoch: 1 [44160/60000 (74%)]\tLoss: -134578188923478464085717155840.000000\n', 'Train Epoch: 1 [44800/60000 (75%)]\tLoss: -132508281246707041195649925120.000000\n', 'Train Epoch: 1 [45440/60000 (76%)]\tLoss: -136951404754711638548569653248.000000\n', 'Train Epoch: 1 [46080/60000 (77%)]\tLoss: -144895832444110276952280006656.000000\n', 'Train Epoch: 1 [46720/60000 (78%)]\tLoss: -145930824061427851354475331584.000000\n', 'Train Epoch: 1 [47360/60000 (79%)]\tLoss: -147942457735800662822605553664.000000\n', 'Train Epoch: 1 [48000/60000 (80%)]\tLoss: -146606424699933114277327536128.000000\n', 'Train Epoch: 1 [48640/60000 (81%)]\tLoss: -148611513174360668417191575552.000000\n', 'Train Epoch: 1 [49280/60000 (82%)]\tLoss: -140969893068576597403873837056.000000\n', 'Train Epoch: 1 [49920/60000 (83%)]\tLoss: -153876479566112035865941245952.000000\n', 'Train Epoch: 1 [50560/60000 (84%)]\tLoss: -153863190826829240684309905408.000000\n', 'Train Epoch: 1 [51200/60000 (85%)]\tLoss: -154065600899017999417459343360.000000\n', 'Train Epoch: 1 [51840/60000 (86%)]\tLoss: -157606809077192288970305699840.000000\n', 'Train Epoch: 1 [52480/60000 (87%)]\tLoss: -154418097222765321214790467584.000000\n', 'Train Epoch: 1 [53120/60000 (88%)]\tLoss: -158461292958068654053852708864.000000\n', 'Train Epoch: 1 [53760/60000 (90%)]\tLoss: -156929546165685055932338274304.000000\n', 'Train Epoch: 1 [54400/60000 (91%)]\tLoss: -167162479876347153103057846272.000000\n', 'Train Epoch: 1 [55040/60000 (92%)]\tLoss: -160623570123245007204299833344.000000\n', 'Train Epoch: 1 [55680/60000 (93%)]\tLoss: -166400233257614197929824747520.000000\n', 'Train Epoch: 1 [56320/60000 (94%)]\tLoss: -168900537415634360284668231680.000000\n', 'Train Epoch: 1 [56960/60000 (95%)]\tLoss: -177780135339635674530046803968.000000\n', 'Train Epoch: 1 [57600/60000 (96%)]\tLoss: -172425009526993359814877249536.000000\n', 'Train Epoch: 1 [58240/60000 (97%)]\tLoss: -171266877481268476544089587712.000000\n', 'Train Epoch: 1 [58880/60000 (98%)]\tLoss: -174281938475387361705806790656.000000\n', 'Train Epoch: 1 [59520/60000 (99%)]\tLoss: -177238461014584594745455017984.000000\n', '\n', 'Test set: Average loss: -177077446179397711026425167872.0000, Accuracy: 1009/10000 (10%)\n', '\n', '\n', 'Test set: Average loss: -177077438442272485027161833472.0000, Accuracy: 1009/10000 (10%)\n', '\n', '{"accuracy": 10.09, "runtime": 99.85920097492635, "mem_params": 244341408, "mem_bufs": 0, "mem_peak": 3344906752}\n']
[2021-12-11 15:42:30,341 DEBUG] Received error from gpu3: []
[2021-12-11 15:42:30,341 DEBUG] SSH connection with gpu3 has been closed
[2021-12-11 15:42:30,341 INFO] {'batch-size': 64, 'lr': 0.9, 'gamma': 0.5} => {"accuracy": 10.09, "runtime": 99.85920097492635, "mem_params": 244341408, "mem_bufs": 0, "mem_peak": 3344906752}
[2021-12-11 15:42:30,342 DEBUG] gpu3 finished training {'batch-size': 64, 'lr': 0.9, 'gamma': 0.5}
[2021-12-11 15:42:30,342 DEBUG] gpu3 now training {'batch-size': 64, 'lr': 0.99, 'gamma': 0.5}...
[2021-12-11 15:42:30,343 DEBUG] Attempting to establish SSH connection with gpu3...
[2021-12-11 15:42:30,445 DEBUG] SSH connection with gpu3 established successfully!
[2021-12-11 15:42:30,446 DEBUG] Running cmd on gpu3: source /u5/p3basta/CS848/CS848-Project/venv/bin/activate && python /u5/p3basta/CS848/CS848-Project/models/MNIST/train.py --arch "alexnet" --parallelism "dp" --epochs "1" --batch-size "64" --lr "0.99" --gamma "0.5"
[2021-12-11 15:42:30,446 INFO] Training {'batch-size': 64, 'lr': 0.99, 'gamma': 0.5} on gpu3...
[2021-12-11 15:42:30,849 DEBUG] Received output from gpu1: ['Train Epoch: 1 [0/60000 (0%)]\tLoss: 0.001733\n', 'Train Epoch: 1 [640/60000 (1%)]\tLoss: -174758250724458496.000000\n', 'Train Epoch: 1 [1280/60000 (2%)]\tLoss: -63761138608974936168988672.000000\n', 'Train Epoch: 1 [1920/60000 (3%)]\tLoss: -1710004026047814874865598464.000000\n', 'Train Epoch: 1 [2560/60000 (4%)]\tLoss: -4366536758681227805549658112.000000\n', 'Train Epoch: 1 [3200/60000 (5%)]\tLoss: -6895531063972254331183300608.000000\n', 'Train Epoch: 1 [3840/60000 (6%)]\tLoss: -9051552274150425919133581312.000000\n', 'Train Epoch: 1 [4480/60000 (7%)]\tLoss: -11396874267160910105120079872.000000\n', 'Train Epoch: 1 [5120/60000 (9%)]\tLoss: -13954909355434153872700997632.000000\n', 'Train Epoch: 1 [5760/60000 (10%)]\tLoss: -16303609021071510572426592256.000000\n', 'Train Epoch: 1 [6400/60000 (11%)]\tLoss: -18348783303388903695687090176.000000\n', 'Train Epoch: 1 [7040/60000 (12%)]\tLoss: -21182321252272762565035032576.000000\n', 'Train Epoch: 1 [7680/60000 (13%)]\tLoss: -24247928096041042974297030656.000000\n', 'Train Epoch: 1 [8320/60000 (14%)]\tLoss: -26612544497908911813215387648.000000\n', 'Train Epoch: 1 [8960/60000 (15%)]\tLoss: -28569445944745264093318873088.000000\n', 'Train Epoch: 1 [9600/60000 (16%)]\tLoss: -30438190254079405836573081600.000000\n', 'Train Epoch: 1 [10240/60000 (17%)]\tLoss: -32621522090219633300205469696.000000\n', 'Train Epoch: 1 [10880/60000 (18%)]\tLoss: -34014641453315351551649251328.000000\n', 'Train Epoch: 1 [11520/60000 (19%)]\tLoss: -39211381455305459801174048768.000000\n', 'Train Epoch: 1 [12160/60000 (20%)]\tLoss: -38892116424498091697211703296.000000\n', 'Train Epoch: 1 [12800/60000 (21%)]\tLoss: -42160282094999341233447370752.000000\n', 'Train Epoch: 1 [13440/60000 (22%)]\tLoss: -45749101172053922549338210304.000000\n', 'Train Epoch: 1 [14080/60000 (23%)]\tLoss: -48188534026109895177377153024.000000\n', 'Train Epoch: 1 [14720/60000 (25%)]\tLoss: -48598595997283397949863231488.000000\n', 'Train Epoch: 1 [15360/60000 (26%)]\tLoss: -49676660319291226386052677632.000000\n', 'Train Epoch: 1 [16000/60000 (27%)]\tLoss: -54546742425745034102033088512.000000\n', 'Train Epoch: 1 [16640/60000 (28%)]\tLoss: -55269741456638859653895159808.000000\n', 'Train Epoch: 1 [17280/60000 (29%)]\tLoss: -55132400872217561762145239040.000000\n', 'Train Epoch: 1 [17920/60000 (30%)]\tLoss: -59540758318175272787001737216.000000\n', 'Train Epoch: 1 [18560/60000 (31%)]\tLoss: -63321215749471187175309574144.000000\n', 'Train Epoch: 1 [19200/60000 (32%)]\tLoss: -63684809634453252638892883968.000000\n', 'Train Epoch: 1 [19840/60000 (33%)]\tLoss: -64363333417811411872132366336.000000\n', 'Train Epoch: 1 [20480/60000 (34%)]\tLoss: -65879954470350378520027332608.000000\n', 'Train Epoch: 1 [21120/60000 (35%)]\tLoss: -71230518476970241157920456704.000000\n', 'Train Epoch: 1 [21760/60000 (36%)]\tLoss: -73932250454950725359708930048.000000\n', 'Train Epoch: 1 [22400/60000 (37%)]\tLoss: -73944202764518868431744794624.000000\n', 'Train Epoch: 1 [23040/60000 (38%)]\tLoss: -76043606342342295125816770560.000000\n', 'Train Epoch: 1 [23680/60000 (39%)]\tLoss: -77132329045501960351253528576.000000\n', 'Train Epoch: 1 [24320/60000 (41%)]\tLoss: -81188690738559533761171554304.000000\n', 'Train Epoch: 1 [24960/60000 (42%)]\tLoss: -82958123680758926865581735936.000000\n', 'Train Epoch: 1 [25600/60000 (43%)]\tLoss: -87991779117446373352474148864.000000\n', 'Train Epoch: 1 [26240/60000 (44%)]\tLoss: -87115751800675156947462258688.000000\n', 'Train Epoch: 1 [26880/60000 (45%)]\tLoss: -87110236076623165201852661760.000000\n', 'Train Epoch: 1 [27520/60000 (46%)]\tLoss: -92931827805710377731940679680.000000\n', 'Train Epoch: 1 [28160/60000 (47%)]\tLoss: -90704901443383539138518056960.000000\n', 'Train Epoch: 1 [28800/60000 (48%)]\tLoss: -95725315364453019140231266304.000000\n', 'Train Epoch: 1 [29440/60000 (49%)]\tLoss: -93725279822162135520745881600.000000\n', 'Train Epoch: 1 [30080/60000 (50%)]\tLoss: -100711784915243632132148428800.000000\n', 'Train Epoch: 1 [30720/60000 (51%)]\tLoss: -100740723577050657318017957888.000000\n', 'Train Epoch: 1 [31360/60000 (52%)]\tLoss: -104386182717700777158601867264.000000\n', 'Train Epoch: 1 [32000/60000 (53%)]\tLoss: -104176179080207564035948806144.000000\n', 'Train Epoch: 1 [32640/60000 (54%)]\tLoss: -106021576009650398253266501632.000000\n', 'Train Epoch: 1 [33280/60000 (55%)]\tLoss: -110844472230207372474271662080.000000\n', 'Train Epoch: 1 [33920/60000 (57%)]\tLoss: -114244934997726215121169022976.000000\n', 'Train Epoch: 1 [34560/60000 (58%)]\tLoss: -111492957040367997894306824192.000000\n', 'Train Epoch: 1 [35200/60000 (59%)]\tLoss: -118197971312138600693811380224.000000\n', 'Train Epoch: 1 [35840/60000 (60%)]\tLoss: -120323026784696975300684152832.000000\n', 'Train Epoch: 1 [36480/60000 (61%)]\tLoss: -118596255701303826571134500864.000000\n', 'Train Epoch: 1 [37120/60000 (62%)]\tLoss: -120470411842627336927803604992.000000\n', 'Train Epoch: 1 [37760/60000 (63%)]\tLoss: -122155389982647089297212047360.000000\n', 'Train Epoch: 1 [38400/60000 (64%)]\tLoss: -122483915574127364775438450688.000000\n', 'Train Epoch: 1 [39040/60000 (65%)]\tLoss: -129680018181184547720005681152.000000\n', 'Train Epoch: 1 [39680/60000 (66%)]\tLoss: -124443631551387507364089298944.000000\n', 'Train Epoch: 1 [40320/60000 (67%)]\tLoss: -129311522479793263564690554880.000000\n', 'Train Epoch: 1 [40960/60000 (68%)]\tLoss: -128469751209488783566058815488.000000\n', 'Train Epoch: 1 [41600/60000 (69%)]\tLoss: -132162632354359880383878660096.000000\n', 'Train Epoch: 1 [42240/60000 (70%)]\tLoss: -137466152146077395616152944640.000000\n', 'Train Epoch: 1 [42880/60000 (71%)]\tLoss: -141878429156215888446536810496.000000\n', 'Train Epoch: 1 [43520/60000 (72%)]\tLoss: -134598844554474535913881862144.000000\n', 'Train Epoch: 1 [44160/60000 (74%)]\tLoss: -138645657622503746901177794560.000000\n', 'Train Epoch: 1 [44800/60000 (75%)]\tLoss: -144726101147982976164009345024.000000\n', 'Train Epoch: 1 [45440/60000 (76%)]\tLoss: -146394976018296143043239084032.000000\n', 'Train Epoch: 1 [46080/60000 (77%)]\tLoss: -147748037907700919529157689344.000000\n', 'Train Epoch: 1 [46720/60000 (78%)]\tLoss: -147219104527420622047352455168.000000\n', 'Train Epoch: 1 [47360/60000 (79%)]\tLoss: -143709347310022244331629314048.000000\n', 'Train Epoch: 1 [48000/60000 (80%)]\tLoss: -147120992641372522298392707072.000000\n', 'Train Epoch: 1 [48640/60000 (81%)]\tLoss: -152093398984777149486863482880.000000\n', 'Train Epoch: 1 [49280/60000 (82%)]\tLoss: -151538747596631143917224460288.000000\n', 'Train Epoch: 1 [49920/60000 (83%)]\tLoss: -150694426248425914310177325056.000000\n', 'Train Epoch: 1 [50560/60000 (84%)]\tLoss: -156268093737162470466546302976.000000\n', 'Train Epoch: 1 [51200/60000 (85%)]\tLoss: -158924594888970029206477996032.000000\n', 'Train Epoch: 1 [51840/60000 (86%)]\tLoss: -157211518668377202448048062464.000000\n', 'Train Epoch: 1 [52480/60000 (87%)]\tLoss: -160756174174083986841900417024.000000\n', 'Train Epoch: 1 [53120/60000 (88%)]\tLoss: -163187569560386115333785649152.000000\n', 'Train Epoch: 1 [53760/60000 (90%)]\tLoss: -169792516886384710351211986944.000000\n', 'Train Epoch: 1 [54400/60000 (91%)]\tLoss: -163370910716717046439562182656.000000\n', 'Train Epoch: 1 [55040/60000 (92%)]\tLoss: -171478401720769173692501458944.000000\n', 'Train Epoch: 1 [55680/60000 (93%)]\tLoss: -165064464674269690084678696960.000000\n', 'Train Epoch: 1 [56320/60000 (94%)]\tLoss: -169640003338453952289390460928.000000\n', 'Train Epoch: 1 [56960/60000 (95%)]\tLoss: -179931532172435496017921572864.000000\n', 'Train Epoch: 1 [57600/60000 (96%)]\tLoss: -179040704959106966144809959424.000000\n', 'Train Epoch: 1 [58240/60000 (97%)]\tLoss: -176413010242844912240681811968.000000\n', 'Train Epoch: 1 [58880/60000 (98%)]\tLoss: -176930846061890466056234860544.000000\n', 'Train Epoch: 1 [59520/60000 (99%)]\tLoss: -177042293910886189683278086144.000000\n', 'Train Epoch: 1 [0/60000 (0%)]\tLoss: 0.001687\n', 'Train Epoch: 1 [640/60000 (1%)]\tLoss: -165281302306619392.000000\n', 'Train Epoch: 1 [1280/60000 (2%)]\tLoss: -60607409455157256386510848.000000\n', 'Train Epoch: 1 [1920/60000 (3%)]\tLoss: -1625327272643479266538815488.000000\n', 'Train Epoch: 1 [2560/60000 (4%)]\tLoss: -4213200338390829708049645568.000000\n', 'Train Epoch: 1 [3200/60000 (5%)]\tLoss: -6425470836338082357551562752.000000\n', 'Train Epoch: 1 [3840/60000 (6%)]\tLoss: -9217747698373678060550488064.000000\n', 'Train Epoch: 1 [4480/60000 (7%)]\tLoss: -11406968325518043971764355072.000000\n', 'Train Epoch: 1 [5120/60000 (9%)]\tLoss: -14144629248291821151749931008.000000\n', 'Train Epoch: 1 [5760/60000 (10%)]\tLoss: -17444400537071296505989562368.000000\n', 'Train Epoch: 1 [6400/60000 (11%)]\tLoss: -18013869530648926304897859584.000000\n', 'Train Epoch: 1 [7040/60000 (12%)]\tLoss: -21784099496734565759084134400.000000\n', 'Train Epoch: 1 [7680/60000 (13%)]\tLoss: -24042512237585937711969075200.000000\n', 'Train Epoch: 1 [8320/60000 (14%)]\tLoss: -27043677668328978942644977664.000000\n', 'Train Epoch: 1 [8960/60000 (15%)]\tLoss: -28288694173788939380896825344.000000\n', 'Train Epoch: 1 [9600/60000 (16%)]\tLoss: -31249086692318884094797676544.000000\n', 'Train Epoch: 1 [10240/60000 (17%)]\tLoss: -32222217669894107579516190720.000000\n', 'Train Epoch: 1 [10880/60000 (18%)]\tLoss: -36690364997891431182423293952.000000\n', 'Train Epoch: 1 [11520/60000 (19%)]\tLoss: -38445116102695582559864094720.000000\n', 'Train Epoch: 1 [12160/60000 (20%)]\tLoss: -38643436605510176180258471936.000000\n', 'Train Epoch: 1 [12800/60000 (21%)]\tLoss: -42931335927222848295004012544.000000\n', 'Train Epoch: 1 [13440/60000 (22%)]\tLoss: -43979828790314947012865294336.000000\n', 'Train Epoch: 1 [14080/60000 (23%)]\tLoss: -48278617889137116529473617920.000000\n', 'Train Epoch: 1 [14720/60000 (25%)]\tLoss: -47304790362505669772086083584.000000\n', 'Train Epoch: 1 [15360/60000 (26%)]\tLoss: -50189820995518739252844167168.000000\n', 'Train Epoch: 1 [16000/60000 (27%)]\tLoss: -53903475830547979639959060480.000000\n', 'Train Epoch: 1 [16640/60000 (28%)]\tLoss: -56017542356300716582419562496.000000\n', 'Train Epoch: 1 [17280/60000 (29%)]\tLoss: -57951370320501767776008929280.000000\n', 'Train Epoch: 1 [17920/60000 (30%)]\tLoss: -62660150555000197020425125888.000000\n', 'Train Epoch: 1 [18560/60000 (31%)]\tLoss: -62147854071839049298707742720.000000\n', 'Train Epoch: 1 [19200/60000 (32%)]\tLoss: -61561567550624299975782170624.000000\n', 'Train Epoch: 1 [19840/60000 (33%)]\tLoss: -66559857184721535689669214208.000000\n', 'Train Epoch: 1 [20480/60000 (34%)]\tLoss: -69255048685123245432836718592.000000\n', 'Train Epoch: 1 [21120/60000 (35%)]\tLoss: -71118607836059196305646288896.000000\n', 'Train Epoch: 1 [21760/60000 (36%)]\tLoss: -74727676420592322660213456896.000000\n', 'Train Epoch: 1 [22400/60000 (37%)]\tLoss: -74910757846766695935503237120.000000\n', 'Train Epoch: 1 [23040/60000 (38%)]\tLoss: -77318404452026472981608792064.000000\n', 'Train Epoch: 1 [23680/60000 (39%)]\tLoss: -79974192526495118405113217024.000000\n', 'Train Epoch: 1 [24320/60000 (41%)]\tLoss: -81551047363523087377708875776.000000\n', 'Train Epoch: 1 [24960/60000 (42%)]\tLoss: -83719199152604130366801838080.000000\n', 'Train Epoch: 1 [25600/60000 (43%)]\tLoss: -84990356317730015726134099968.000000\n', 'Train Epoch: 1 [26240/60000 (44%)]\tLoss: -87094661711962661111937892352.000000\n', 'Train Epoch: 1 [26880/60000 (45%)]\tLoss: -90110308279525422109661593600.000000\n', 'Train Epoch: 1 [27520/60000 (46%)]\tLoss: -90685331956678527328752500736.000000\n', 'Train Epoch: 1 [28160/60000 (47%)]\tLoss: -93501307424612593987550707712.000000\n', 'Train Epoch: 1 [28800/60000 (48%)]\tLoss: -91477244481656869613218037760.000000\n', 'Train Epoch: 1 [29440/60000 (49%)]\tLoss: -99503945239920062975841402880.000000\n', 'Train Epoch: 1 [30080/60000 (50%)]\tLoss: -99113008853002182266470793216.000000\n', 'Train Epoch: 1 [30720/60000 (51%)]\tLoss: -104444598391093874669895286784.000000\n', 'Train Epoch: 1 [31360/60000 (52%)]\tLoss: -106877353818943069619602063360.000000\n', 'Train Epoch: 1 [32000/60000 (53%)]\tLoss: -104660835552344475724230426624.000000\n', 'Train Epoch: 1 [32640/60000 (54%)]\tLoss: -107573732869972958981394530304.000000\n', 'Train Epoch: 1 [33280/60000 (55%)]\tLoss: -113557632335076401217477279744.000000\n', 'Train Epoch: 1 [33920/60000 (57%)]\tLoss: -112538007298294084640807321600.000000\n', 'Train Epoch: 1 [34560/60000 (58%)]\tLoss: -113680300526835423121548247040.000000\n', 'Train Epoch: 1 [35200/60000 (59%)]\tLoss: -113094377627839854761304129536.000000\n', 'Train Epoch: 1 [35840/60000 (60%)]\tLoss: -113155787281583091627663032320.000000\n', 'Train Epoch: 1 [36480/60000 (61%)]\tLoss: -117635943587546352738348564480.000000\n', 'Train Epoch: 1 [37120/60000 (62%)]\tLoss: -117072603045071867021516341248.000000\n', 'Train Epoch: 1 [37760/60000 (63%)]\tLoss: -122208667721306824634512965632.000000\n', 'Train Epoch: 1 [38400/60000 (64%)]\tLoss: -124760379560859505947152744448.000000\n', 'Train Epoch: 1 [39040/60000 (65%)]\tLoss: -126746852466611587945584394240.000000\n', 'Train Epoch: 1 [39680/60000 (66%)]\tLoss: -129146522994881798160924016640.000000\n', 'Train Epoch: 1 [40320/60000 (67%)]\tLoss: -132398665675906670990949613568.000000\n', 'Train Epoch: 1 [40960/60000 (68%)]\tLoss: -131994478328637858057109372928.000000\n', 'Train Epoch: 1 [41600/60000 (69%)]\tLoss: -134017058448517961362844942336.000000\n', 'Train Epoch: 1 [42240/60000 (70%)]\tLoss: -140594096588602796777058336768.000000\n', 'Train Epoch: 1 [42880/60000 (71%)]\tLoss: -139388891993776668882780553216.000000\n', 'Train Epoch: 1 [43520/60000 (72%)]\tLoss: -138767645793489235576337989632.000000\n', 'Train Epoch: 1 [44160/60000 (74%)]\tLoss: -139912205757942351486781489152.000000\n', 'Train Epoch: 1 [44800/60000 (75%)]\tLoss: -145492777346476863064452890624.000000\n', 'Train Epoch: 1 [45440/60000 (76%)]\tLoss: -142667904940089069994072080384.000000\n', 'Train Epoch: 1 [46080/60000 (77%)]\tLoss: -151282105867753110178440937472.000000\n', 'Train Epoch: 1 [46720/60000 (78%)]\tLoss: -145954058104523570008926715904.000000\n', 'Train Epoch: 1 [47360/60000 (79%)]\tLoss: -149272625592496487268528160768.000000\n', 'Train Epoch: 1 [48000/60000 (80%)]\tLoss: -146199158369717470334807965696.000000\n', 'Train Epoch: 1 [48640/60000 (81%)]\tLoss: -156654005526142577873409540096.000000\n', 'Train Epoch: 1 [49280/60000 (82%)]\tLoss: -154532340712718903671800201216.000000\n', 'Train Epoch: 1 [49920/60000 (83%)]\tLoss: -156926240509147047180688687104.000000\n', 'Train Epoch: 1 [50560/60000 (84%)]\tLoss: -150834784425029765905218797568.000000\n', 'Train Epoch: 1 [51200/60000 (85%)]\tLoss: -161516002941177712756784103424.000000\n', 'Train Epoch: 1 [51840/60000 (86%)]\tLoss: -158915943513573412016446504960.000000\n', 'Train Epoch: 1 [52480/60000 (87%)]\tLoss: -170641277259083837424759996416.000000\n', 'Train Epoch: 1 [53120/60000 (88%)]\tLoss: -164199270466210176645787025408.000000\n', 'Train Epoch: 1 [53760/60000 (90%)]\tLoss: -164211019714019556323078701056.000000\n', 'Train Epoch: 1 [54400/60000 (91%)]\tLoss: -164838754445854452522044882944.000000\n', 'Train Epoch: 1 [55040/60000 (92%)]\tLoss: -166889111525386795080927412224.000000\n', 'Train Epoch: 1 [55680/60000 (93%)]\tLoss: -172372647927431301188747788288.000000\n', 'Train Epoch: 1 [56320/60000 (94%)]\tLoss: -178151993365962761872754081792.000000\n', 'Train Epoch: 1 [56960/60000 (95%)]\tLoss: -173456034356465323715093069824.000000\n', 'Train Epoch: 1 [57600/60000 (96%)]\tLoss: -172703534702153011489581039616.000000\n', 'Train Epoch: 1 [58240/60000 (97%)]\tLoss: -168625771244195072847554543616.000000\n', 'Train Epoch: 1 [58880/60000 (98%)]\tLoss: -171759590310625163847105773568.000000\n', 'Train Epoch: 1 [59520/60000 (99%)]\tLoss: -172177463075961333012775305216.000000\n', '\n', 'Test set: Average loss: -181996445413968335082560159744.0000, Accuracy: 1028/10000 (10%)\n', '\n', '\n', 'Test set: Average loss: -181996451216812263378100682752.0000, Accuracy: 1028/10000 (10%)\n', '\n', '{"accuracy": 10.28, "runtime": 97.7788297929801, "mem_params": 244341408, "mem_bufs": 0, "mem_peak": 3344906752}\n']
[2021-12-11 15:42:30,849 DEBUG] Received error from gpu1: []
[2021-12-11 15:42:30,850 DEBUG] SSH connection with gpu1 has been closed
[2021-12-11 15:42:30,850 INFO] {'batch-size': 64, 'lr': 0.9, 'gamma': 0.9} => {"accuracy": 10.28, "runtime": 97.7788297929801, "mem_params": 244341408, "mem_bufs": 0, "mem_peak": 3344906752}
[2021-12-11 15:42:30,851 DEBUG] gpu1 finished training {'batch-size': 64, 'lr': 0.9, 'gamma': 0.9}
[2021-12-11 15:42:30,851 DEBUG] gpu1 now training {'batch-size': 64, 'lr': 0.99, 'gamma': 0.7}...
[2021-12-11 15:42:30,851 DEBUG] Attempting to establish SSH connection with gpu1...
[2021-12-11 15:42:30,960 DEBUG] SSH connection with gpu1 established successfully!
[2021-12-11 15:42:30,960 DEBUG] Running cmd on gpu1: source /u5/p3basta/CS848/CS848-Project/venv/bin/activate && python /u5/p3basta/CS848/CS848-Project/models/MNIST/train.py --arch "alexnet" --parallelism "dp" --epochs "1" --batch-size "64" --lr "0.99" --gamma "0.7"
[2021-12-11 15:42:30,960 INFO] Training {'batch-size': 64, 'lr': 0.99, 'gamma': 0.7} on gpu1...
[2021-12-11 15:42:32,628 DEBUG] Received output from gpu2: ['Train Epoch: 1 [0/60000 (0%)]\tLoss: -0.001468\n', 'Train Epoch: 1 [640/60000 (1%)]\tLoss: -140192345336315904.000000\n', 'Train Epoch: 1 [1280/60000 (2%)]\tLoss: -61809874302660068790763520.000000\n', 'Train Epoch: 1 [1920/60000 (3%)]\tLoss: -1740600090916374716528721920.000000\n', 'Train Epoch: 1 [2560/60000 (4%)]\tLoss: -4374681955420462405484806144.000000\n', 'Train Epoch: 1 [3200/60000 (5%)]\tLoss: -6583929253374962943991480320.000000\n', 'Train Epoch: 1 [3840/60000 (6%)]\tLoss: -9188753548760479156349698048.000000\n', 'Train Epoch: 1 [4480/60000 (7%)]\tLoss: -11794935524509820391706853376.000000\n', 'Train Epoch: 1 [5120/60000 (9%)]\tLoss: -14671033801320541938543230976.000000\n', 'Train Epoch: 1 [5760/60000 (10%)]\tLoss: -16906596191352928395650400256.000000\n', 'Train Epoch: 1 [6400/60000 (11%)]\tLoss: -19318582651410462645707341824.000000\n', 'Train Epoch: 1 [7040/60000 (12%)]\tLoss: -21933994492450572602634665984.000000\n', 'Train Epoch: 1 [7680/60000 (13%)]\tLoss: -23809142330735485584798646272.000000\n', 'Train Epoch: 1 [8320/60000 (14%)]\tLoss: -27038886827532107687575683072.000000\n', 'Train Epoch: 1 [8960/60000 (15%)]\tLoss: -30002306382977571844058513408.000000\n', 'Train Epoch: 1 [9600/60000 (16%)]\tLoss: -32012891691991186250951294976.000000\n', 'Train Epoch: 1 [10240/60000 (17%)]\tLoss: -35315188266247376147968950272.000000\n', 'Train Epoch: 1 [10880/60000 (18%)]\tLoss: -36250443503446743643251015680.000000\n', 'Train Epoch: 1 [11520/60000 (19%)]\tLoss: -37095782521629031658841702400.000000\n', 'Train Epoch: 1 [12160/60000 (20%)]\tLoss: -41546912802005334495221252096.000000\n', 'Train Epoch: 1 [12800/60000 (21%)]\tLoss: -42752660468976992398698610688.000000\n', 'Train Epoch: 1 [13440/60000 (22%)]\tLoss: -44792897517136545307888189440.000000\n', 'Train Epoch: 1 [14080/60000 (23%)]\tLoss: -46836383553436312532984791040.000000\n', 'Train Epoch: 1 [14720/60000 (25%)]\tLoss: -48686049502179660909575667712.000000\n', 'Train Epoch: 1 [15360/60000 (26%)]\tLoss: -53352942345975036400946380800.000000\n', 'Train Epoch: 1 [16000/60000 (27%)]\tLoss: -55839830260817366093737754624.000000\n', 'Train Epoch: 1 [16640/60000 (28%)]\tLoss: -57523538084253226528583712768.000000\n', 'Train Epoch: 1 [17280/60000 (29%)]\tLoss: -57157205226711096670776459264.000000\n', 'Train Epoch: 1 [17920/60000 (30%)]\tLoss: -63050614705269790765274365952.000000\n', 'Train Epoch: 1 [18560/60000 (31%)]\tLoss: -64763960100752141093481480192.000000\n', 'Train Epoch: 1 [19200/60000 (32%)]\tLoss: -68384579593702366600241348608.000000\n', 'Train Epoch: 1 [19840/60000 (33%)]\tLoss: -68478993866794379416998772736.000000\n', 'Train Epoch: 1 [20480/60000 (34%)]\tLoss: -70458029045335941724218851328.000000\n', 'Train Epoch: 1 [21120/60000 (35%)]\tLoss: -75775923720627312156523626496.000000\n', 'Train Epoch: 1 [21760/60000 (36%)]\tLoss: -75882771984668720749128712192.000000\n', 'Train Epoch: 1 [22400/60000 (37%)]\tLoss: -76894742065382305630907269120.000000\n', 'Train Epoch: 1 [23040/60000 (38%)]\tLoss: -80684814234837342616870191104.000000\n', 'Train Epoch: 1 [23680/60000 (39%)]\tLoss: -79712818986401249281825570816.000000\n', 'Train Epoch: 1 [24320/60000 (41%)]\tLoss: -84313716758598521481334882304.000000\n', 'Train Epoch: 1 [24960/60000 (42%)]\tLoss: -86722388117385081240451809280.000000\n', 'Train Epoch: 1 [25600/60000 (43%)]\tLoss: -85427014656935040340463714304.000000\n', 'Train Epoch: 1 [26240/60000 (44%)]\tLoss: -88525992103454519097628295168.000000\n', 'Train Epoch: 1 [26880/60000 (45%)]\tLoss: -92002796647535432429050265600.000000\n', 'Train Epoch: 1 [27520/60000 (46%)]\tLoss: -96777874185086868622621540352.000000\n', 'Train Epoch: 1 [28160/60000 (47%)]\tLoss: -97012292457296517811029409792.000000\n', 'Train Epoch: 1 [28800/60000 (48%)]\tLoss: -96302426327591552742506627072.000000\n', 'Train Epoch: 1 [29440/60000 (49%)]\tLoss: -106049655200757541163707138048.000000\n', 'Train Epoch: 1 [30080/60000 (50%)]\tLoss: -107752559443946266706346770432.000000\n', 'Train Epoch: 1 [30720/60000 (51%)]\tLoss: -107318045059124464910944174080.000000\n', 'Train Epoch: 1 [31360/60000 (52%)]\tLoss: -106624159417597530721824538624.000000\n', 'Train Epoch: 1 [32000/60000 (53%)]\tLoss: -107808207810580402605544964096.000000\n', 'Train Epoch: 1 [32640/60000 (54%)]\tLoss: -112139080667287188491735138304.000000\n', 'Train Epoch: 1 [33280/60000 (55%)]\tLoss: -114163332504902227651876356096.000000\n', 'Train Epoch: 1 [33920/60000 (57%)]\tLoss: -119178655714903174176049201152.000000\n', 'Train Epoch: 1 [34560/60000 (58%)]\tLoss: -114357365098950375634416697344.000000\n', 'Train Epoch: 1 [35200/60000 (59%)]\tLoss: -118562783567673246525859823616.000000\n', 'Train Epoch: 1 [35840/60000 (60%)]\tLoss: -123566017519478046758285606912.000000\n', 'Train Epoch: 1 [36480/60000 (61%)]\tLoss: -121766351987055322185217343488.000000\n', 'Train Epoch: 1 [37120/60000 (62%)]\tLoss: -121538988930371080246758735872.000000\n', 'Train Epoch: 1 [37760/60000 (63%)]\tLoss: -122164088581708535183695675392.000000\n', 'Train Epoch: 1 [38400/60000 (64%)]\tLoss: -128549965326566807359658655744.000000\n', 'Train Epoch: 1 [39040/60000 (65%)]\tLoss: -132226242630884134504907145216.000000\n', 'Train Epoch: 1 [39680/60000 (66%)]\tLoss: -129722000019217258865955438592.000000\n', 'Train Epoch: 1 [40320/60000 (67%)]\tLoss: -132630259972959564131519692800.000000\n', 'Train Epoch: 1 [40960/60000 (68%)]\tLoss: -134922298324352209393148755968.000000\n', 'Train Epoch: 1 [41600/60000 (69%)]\tLoss: -137081817627502566670791081984.000000\n', 'Train Epoch: 1 [42240/60000 (70%)]\tLoss: -138211530471733540416682721280.000000\n', 'Train Epoch: 1 [42880/60000 (71%)]\tLoss: -138847633236976081626967572480.000000\n', 'Train Epoch: 1 [43520/60000 (72%)]\tLoss: -146311380686816384583666237440.000000\n', 'Train Epoch: 1 [44160/60000 (74%)]\tLoss: -148847933729959054335170052096.000000\n', 'Train Epoch: 1 [44800/60000 (75%)]\tLoss: -152874081722259227755010850816.000000\n', 'Train Epoch: 1 [45440/60000 (76%)]\tLoss: -147808843098534349080929239040.000000\n', 'Train Epoch: 1 [46080/60000 (77%)]\tLoss: -155381913332453084324324966400.000000\n', 'Train Epoch: 1 [46720/60000 (78%)]\tLoss: -150485725984081973209603244032.000000\n', 'Train Epoch: 1 [47360/60000 (79%)]\tLoss: -157185998999903774885313249280.000000\n', 'Train Epoch: 1 [48000/60000 (80%)]\tLoss: -153577667104541976195399417856.000000\n', 'Train Epoch: 1 [48640/60000 (81%)]\tLoss: -161124632096543408040053833728.000000\n', 'Train Epoch: 1 [49280/60000 (82%)]\tLoss: -162418107165667335342666022912.000000\n', 'Train Epoch: 1 [49920/60000 (83%)]\tLoss: -160833620984403049023405031424.000000\n', 'Train Epoch: 1 [50560/60000 (84%)]\tLoss: -165841331739633609679493398528.000000\n', 'Train Epoch: 1 [51200/60000 (85%)]\tLoss: -164987112311280285296078356480.000000\n', 'Train Epoch: 1 [51840/60000 (86%)]\tLoss: -165630865310225075331609395200.000000\n', 'Train Epoch: 1 [52480/60000 (87%)]\tLoss: -168798855420525211083926929408.000000\n', 'Train Epoch: 1 [53120/60000 (88%)]\tLoss: -168638521633698820889631522816.000000\n', 'Train Epoch: 1 [53760/60000 (90%)]\tLoss: -167310611068181808134121062400.000000\n', 'Train Epoch: 1 [54400/60000 (91%)]\tLoss: -172354854050523848365582581760.000000\n', 'Train Epoch: 1 [55040/60000 (92%)]\tLoss: -173516707321037232916798636032.000000\n', 'Train Epoch: 1 [55680/60000 (93%)]\tLoss: -176433278639789388757938995200.000000\n', 'Train Epoch: 1 [56320/60000 (94%)]\tLoss: -177000000396665609140744224768.000000\n', 'Train Epoch: 1 [56960/60000 (95%)]\tLoss: -179353061167749895957824667648.000000\n', 'Train Epoch: 1 [57600/60000 (96%)]\tLoss: -186513698802520727866837041152.000000\n', 'Train Epoch: 1 [58240/60000 (97%)]\tLoss: -181692615970693175589593939968.000000\n', 'Train Epoch: 1 [58880/60000 (98%)]\tLoss: -177836898184759767665515429888.000000\n', 'Train Epoch: 1 [59520/60000 (99%)]\tLoss: -185311648748505156895562006528.000000\n', 'Train Epoch: 1 [0/60000 (0%)]\tLoss: -0.000379\n', 'Train Epoch: 1 [640/60000 (1%)]\tLoss: -142541743986835456.000000\n', 'Train Epoch: 1 [1280/60000 (2%)]\tLoss: -61656342051734584192663552.000000\n', 'Train Epoch: 1 [1920/60000 (3%)]\tLoss: -1774117677324352382138580992.000000\n', 'Train Epoch: 1 [2560/60000 (4%)]\tLoss: -4314588956482230632082046976.000000\n', 'Train Epoch: 1 [3200/60000 (5%)]\tLoss: -6962672490034074229420326912.000000\n', 'Train Epoch: 1 [3840/60000 (6%)]\tLoss: -9555997823033802855683194880.000000\n', 'Train Epoch: 1 [4480/60000 (7%)]\tLoss: -12046159518440381930018963456.000000\n', 'Train Epoch: 1 [5120/60000 (9%)]\tLoss: -14194666262952687195022950400.000000\n', 'Train Epoch: 1 [5760/60000 (10%)]\tLoss: -16478911529056976824638111744.000000\n', 'Train Epoch: 1 [6400/60000 (11%)]\tLoss: -19386487920250886709057683456.000000\n', 'Train Epoch: 1 [7040/60000 (12%)]\tLoss: -20719307385726842460767780864.000000\n', 'Train Epoch: 1 [7680/60000 (13%)]\tLoss: -24819816121849522748966043648.000000\n', 'Train Epoch: 1 [8320/60000 (14%)]\tLoss: -26164373029218651003854782464.000000\n', 'Train Epoch: 1 [8960/60000 (15%)]\tLoss: -30092069125083958060280446976.000000\n', 'Train Epoch: 1 [9600/60000 (16%)]\tLoss: -33076193896373564176202727424.000000\n', 'Train Epoch: 1 [10240/60000 (17%)]\tLoss: -34995195991001646118643695616.000000\n', 'Train Epoch: 1 [10880/60000 (18%)]\tLoss: -37948582878854253713870028800.000000\n', 'Train Epoch: 1 [11520/60000 (19%)]\tLoss: -38932261261968966551173332992.000000\n', 'Train Epoch: 1 [12160/60000 (20%)]\tLoss: -40300921127866661475232776192.000000\n', 'Train Epoch: 1 [12800/60000 (21%)]\tLoss: -44375841721201912590840627200.000000\n', 'Train Epoch: 1 [13440/60000 (22%)]\tLoss: -45358183674601973318548455424.000000\n', 'Train Epoch: 1 [14080/60000 (23%)]\tLoss: -46715689310867130140613148672.000000\n', 'Train Epoch: 1 [14720/60000 (25%)]\tLoss: -49779924307172136917940568064.000000\n', 'Train Epoch: 1 [15360/60000 (26%)]\tLoss: -52343475119497372431131082752.000000\n', 'Train Epoch: 1 [16000/60000 (27%)]\tLoss: -53914323106359131215014920192.000000\n', 'Train Epoch: 1 [16640/60000 (28%)]\tLoss: -59145614302721155223745724416.000000\n', 'Train Epoch: 1 [17280/60000 (29%)]\tLoss: -60058594137220826602554785792.000000\n', 'Train Epoch: 1 [17920/60000 (30%)]\tLoss: -59880480640586432194029813760.000000\n', 'Train Epoch: 1 [18560/60000 (31%)]\tLoss: -64119682919127752527331721216.000000\n', 'Train Epoch: 1 [19200/60000 (32%)]\tLoss: -66581207003590589355680333824.000000\n', 'Train Epoch: 1 [19840/60000 (33%)]\tLoss: -68895081577600023856777527296.000000\n', 'Train Epoch: 1 [20480/60000 (34%)]\tLoss: -74309614760596838708735377408.000000\n', 'Train Epoch: 1 [21120/60000 (35%)]\tLoss: -71592832600635448947650854912.000000\n', 'Train Epoch: 1 [21760/60000 (36%)]\tLoss: -77324529361354754911450955776.000000\n', 'Train Epoch: 1 [22400/60000 (37%)]\tLoss: -75984184804888346380092833792.000000\n', 'Train Epoch: 1 [23040/60000 (38%)]\tLoss: -75546426154292813138428428288.000000\n', 'Train Epoch: 1 [23680/60000 (39%)]\tLoss: -82222407316926733359159181312.000000\n', 'Train Epoch: 1 [24320/60000 (41%)]\tLoss: -81311557269710836190341496832.000000\n', 'Train Epoch: 1 [24960/60000 (42%)]\tLoss: -84946230525314081761257324544.000000\n', 'Train Epoch: 1 [25600/60000 (43%)]\tLoss: -92150285597528417188364419072.000000\n', 'Train Epoch: 1 [26240/60000 (44%)]\tLoss: -90596145343283051209246638080.000000\n', 'Train Epoch: 1 [26880/60000 (45%)]\tLoss: -90995402539943748233483780096.000000\n', 'Train Epoch: 1 [27520/60000 (46%)]\tLoss: -93187770624348946763232575488.000000\n', 'Train Epoch: 1 [28160/60000 (47%)]\tLoss: -97500745712085656694062841856.000000\n', 'Train Epoch: 1 [28800/60000 (48%)]\tLoss: -98119243495080059866991034368.000000\n', 'Train Epoch: 1 [29440/60000 (49%)]\tLoss: -103751118873084467270264029184.000000\n', 'Train Epoch: 1 [30080/60000 (50%)]\tLoss: -102316586717117223665118740480.000000\n', 'Train Epoch: 1 [30720/60000 (51%)]\tLoss: -103653403665820928571502231552.000000\n', 'Train Epoch: 1 [31360/60000 (52%)]\tLoss: -103565756543898867956336033792.000000\n', 'Train Epoch: 1 [32000/60000 (53%)]\tLoss: -109505738000711622491931410432.000000\n', 'Train Epoch: 1 [32640/60000 (54%)]\tLoss: -111739256786648547110072352768.000000\n', 'Train Epoch: 1 [33280/60000 (55%)]\tLoss: -115750548213993612626070863872.000000\n', 'Train Epoch: 1 [33920/60000 (57%)]\tLoss: -110026671692169938794744643584.000000\n', 'Train Epoch: 1 [34560/60000 (58%)]\tLoss: -117972043854865151127497736192.000000\n', 'Train Epoch: 1 [35200/60000 (59%)]\tLoss: -116883651717359286777225936896.000000\n', 'Train Epoch: 1 [35840/60000 (60%)]\tLoss: -121987774306704114109997121536.000000\n', 'Train Epoch: 1 [36480/60000 (61%)]\tLoss: -122614999022958860387280224256.000000\n', 'Train Epoch: 1 [37120/60000 (62%)]\tLoss: -129165818584330803531267178496.000000\n', 'Train Epoch: 1 [37760/60000 (63%)]\tLoss: -125897185399547749900155355136.000000\n', 'Train Epoch: 1 [38400/60000 (64%)]\tLoss: -133021885825383943809091502080.000000\n', 'Train Epoch: 1 [39040/60000 (65%)]\tLoss: -131652125648095740257697267712.000000\n', 'Train Epoch: 1 [39680/60000 (66%)]\tLoss: -131725634004768089155093659648.000000\n', 'Train Epoch: 1 [40320/60000 (67%)]\tLoss: -139496788623177274536623079424.000000\n', 'Train Epoch: 1 [40960/60000 (68%)]\tLoss: -138780972311703893715131039744.000000\n', 'Train Epoch: 1 [41600/60000 (69%)]\tLoss: -133127591276736497947554873344.000000\n', 'Train Epoch: 1 [42240/60000 (70%)]\tLoss: -141167335211225377270258466816.000000\n', 'Train Epoch: 1 [42880/60000 (71%)]\tLoss: -145607578075675424139597840384.000000\n', 'Train Epoch: 1 [43520/60000 (72%)]\tLoss: -142763655642895734920424980480.000000\n', 'Train Epoch: 1 [44160/60000 (74%)]\tLoss: -142148690190030518242116632576.000000\n', 'Train Epoch: 1 [44800/60000 (75%)]\tLoss: -153322168188352796910757609472.000000\n', 'Train Epoch: 1 [45440/60000 (76%)]\tLoss: -152528121153724197546655481856.000000\n', 'Train Epoch: 1 [46080/60000 (77%)]\tLoss: -146931502963880894914547941376.000000\n', 'Train Epoch: 1 [46720/60000 (78%)]\tLoss: -145817506155304911347927482368.000000\n', 'Train Epoch: 1 [47360/60000 (79%)]\tLoss: -152258389024955649151339593728.000000\n', 'Train Epoch: 1 [48000/60000 (80%)]\tLoss: -149053082774707877462543433728.000000\n', 'Train Epoch: 1 [48640/60000 (81%)]\tLoss: -159445660806689865859357212672.000000\n', 'Train Epoch: 1 [49280/60000 (82%)]\tLoss: -157588240732181645525325447168.000000\n', 'Train Epoch: 1 [49920/60000 (83%)]\tLoss: -166041541189041351157973254144.000000\n', 'Train Epoch: 1 [50560/60000 (84%)]\tLoss: -156400112214557574268140388352.000000\n', 'Train Epoch: 1 [51200/60000 (85%)]\tLoss: -157253037714494592368766877696.000000\n', 'Train Epoch: 1 [51840/60000 (86%)]\tLoss: -161418986644153638765513932800.000000\n', 'Train Epoch: 1 [52480/60000 (87%)]\tLoss: -170586063350166125532921462784.000000\n', 'Train Epoch: 1 [53120/60000 (88%)]\tLoss: -176698411183603622118816743424.000000\n', 'Train Epoch: 1 [53760/60000 (90%)]\tLoss: -174045593477652701702151733248.000000\n', 'Train Epoch: 1 [54400/60000 (91%)]\tLoss: -171243511211911237539572219904.000000\n', 'Train Epoch: 1 [55040/60000 (92%)]\tLoss: -173794779149014529105561911296.000000\n', 'Train Epoch: 1 [55680/60000 (93%)]\tLoss: -177007915082890898666122379264.000000\n', 'Train Epoch: 1 [56320/60000 (94%)]\tLoss: -181554307301142889420575211520.000000\n', 'Train Epoch: 1 [56960/60000 (95%)]\tLoss: -176006603383329150573591134208.000000\n', 'Train Epoch: 1 [57600/60000 (96%)]\tLoss: -181342726393244397836420775936.000000\n', 'Train Epoch: 1 [58240/60000 (97%)]\tLoss: -178118540121798113306060259328.000000\n', 'Train Epoch: 1 [58880/60000 (98%)]\tLoss: -193821485376897777920708182016.000000\n', 'Train Epoch: 1 [59520/60000 (99%)]\tLoss: -193553764976250931994253328384.000000\n', '\n', 'Test set: Average loss: -189951039973059508109760790528.0000, Accuracy: 1028/10000 (10%)\n', '\n', '\n', 'Test set: Average loss: -189951051578747364700841836544.0000, Accuracy: 1028/10000 (10%)\n', '\n', '{"accuracy": 10.28, "runtime": 98.76292283693328, "mem_params": 244341408, "mem_bufs": 0, "mem_peak": 3344906752}\n']
[2021-12-11 15:42:32,628 DEBUG] Received error from gpu2: []
[2021-12-11 15:42:32,628 DEBUG] SSH connection with gpu2 has been closed
[2021-12-11 15:42:32,628 INFO] {'batch-size': 64, 'lr': 0.9, 'gamma': 0.7} => {"accuracy": 10.28, "runtime": 98.76292283693328, "mem_params": 244341408, "mem_bufs": 0, "mem_peak": 3344906752}
[2021-12-11 15:42:32,629 DEBUG] gpu2 finished training {'batch-size': 64, 'lr': 0.9, 'gamma': 0.7}
[2021-12-11 15:42:32,629 DEBUG] gpu2 now training {'batch-size': 64, 'lr': 0.99, 'gamma': 0.9}...
[2021-12-11 15:42:32,629 DEBUG] Attempting to establish SSH connection with gpu2...
[2021-12-11 15:42:32,718 DEBUG] SSH connection with gpu2 established successfully!
[2021-12-11 15:42:32,718 DEBUG] Running cmd on gpu2: source /u5/p3basta/CS848/CS848-Project/venv/bin/activate && python /u5/p3basta/CS848/CS848-Project/models/MNIST/train.py --arch "alexnet" --parallelism "dp" --epochs "1" --batch-size "64" --lr "0.99" --gamma "0.9"
[2021-12-11 15:42:32,718 INFO] Training {'batch-size': 64, 'lr': 0.99, 'gamma': 0.9} on gpu2...
[2021-12-11 15:44:11,004 DEBUG] Received output from gpu3: ['Train Epoch: 1 [0/60000 (0%)]\tLoss: 0.001422\n', 'Train Epoch: 1 [640/60000 (1%)]\tLoss: -447612489337667584.000000\n', 'Train Epoch: 1 [1280/60000 (2%)]\tLoss: -82794152491149106327060480.000000\n', 'Train Epoch: 1 [1920/60000 (3%)]\tLoss: -1742484462716992294645399552.000000\n', 'Train Epoch: 1 [2560/60000 (4%)]\tLoss: -3925401911198347946910285824.000000\n', 'Train Epoch: 1 [3200/60000 (5%)]\tLoss: -6190526610561403562408017920.000000\n', 'Train Epoch: 1 [3840/60000 (6%)]\tLoss: -8416340265285715995677163520.000000\n', 'Train Epoch: 1 [4480/60000 (7%)]\tLoss: -10124099691514641892302127104.000000\n', 'Train Epoch: 1 [5120/60000 (9%)]\tLoss: -12110528915376757346515550208.000000\n', 'Train Epoch: 1 [5760/60000 (10%)]\tLoss: -13970946512009979187846709248.000000\n', 'Train Epoch: 1 [6400/60000 (11%)]\tLoss: -16136263700609679672400150528.000000\n', 'Train Epoch: 1 [7040/60000 (12%)]\tLoss: -17958271929454481254385713152.000000\n', 'Train Epoch: 1 [7680/60000 (13%)]\tLoss: -20102589934896481144085151744.000000\n', 'Train Epoch: 1 [8320/60000 (14%)]\tLoss: -22200756252701395991111139328.000000\n', 'Train Epoch: 1 [8960/60000 (15%)]\tLoss: -23260212089583476590336016384.000000\n', 'Train Epoch: 1 [9600/60000 (16%)]\tLoss: -26023455252186579355855486976.000000\n', 'Train Epoch: 1 [10240/60000 (17%)]\tLoss: -27693338347743838904338350080.000000\n', 'Train Epoch: 1 [10880/60000 (18%)]\tLoss: -29209468274168587109131091968.000000\n', 'Train Epoch: 1 [11520/60000 (19%)]\tLoss: -30576586287409625094028263424.000000\n', 'Train Epoch: 1 [12160/60000 (20%)]\tLoss: -32250601453639395582073110528.000000\n', 'Train Epoch: 1 [12800/60000 (21%)]\tLoss: -36304465014827530949673091072.000000\n', 'Train Epoch: 1 [13440/60000 (22%)]\tLoss: -37751679085984520987039760384.000000\n', 'Train Epoch: 1 [14080/60000 (23%)]\tLoss: -39017027740336476682759176192.000000\n', 'Train Epoch: 1 [14720/60000 (25%)]\tLoss: -42855575001738170576840687616.000000\n', 'Train Epoch: 1 [15360/60000 (26%)]\tLoss: -44562497978803818187557175296.000000\n', 'Train Epoch: 1 [16000/60000 (27%)]\tLoss: -44612909241008451650213380096.000000\n', 'Train Epoch: 1 [16640/60000 (28%)]\tLoss: -47472528819977199570076565504.000000\n', 'Train Epoch: 1 [17280/60000 (29%)]\tLoss: -48608234347274934895744385024.000000\n', 'Train Epoch: 1 [17920/60000 (30%)]\tLoss: -49867188917409085091844456448.000000\n', 'Train Epoch: 1 [18560/60000 (31%)]\tLoss: -53489484850460729322655186944.000000\n', 'Train Epoch: 1 [19200/60000 (32%)]\tLoss: -53229839696499590489515753472.000000\n', 'Train Epoch: 1 [19840/60000 (33%)]\tLoss: -56229614390313426609676222464.000000\n', 'Train Epoch: 1 [20480/60000 (34%)]\tLoss: -57054106521657086576471048192.000000\n', 'Train Epoch: 1 [21120/60000 (35%)]\tLoss: -59269458363734411669474902016.000000\n', 'Train Epoch: 1 [21760/60000 (36%)]\tLoss: -62954528714442842094111293440.000000\n', 'Train Epoch: 1 [22400/60000 (37%)]\tLoss: -63414723328198489020185968640.000000\n', 'Train Epoch: 1 [23040/60000 (38%)]\tLoss: -64241855262406073118655250432.000000\n', 'Train Epoch: 1 [23680/60000 (39%)]\tLoss: -65136040078303923309513801728.000000\n', 'Train Epoch: 1 [24320/60000 (41%)]\tLoss: -68920454852712482460510715904.000000\n', 'Train Epoch: 1 [24960/60000 (42%)]\tLoss: -69117410591613526753438334976.000000\n', 'Train Epoch: 1 [25600/60000 (43%)]\tLoss: -73569926886552551830688104448.000000\n', 'Train Epoch: 1 [26240/60000 (44%)]\tLoss: -70306025512985333584080404480.000000\n', 'Train Epoch: 1 [26880/60000 (45%)]\tLoss: -74551843826969154290326700032.000000\n', 'Train Epoch: 1 [27520/60000 (46%)]\tLoss: -76861680777635735244766183424.000000\n', 'Train Epoch: 1 [28160/60000 (47%)]\tLoss: -79205877666831675737780518912.000000\n', 'Train Epoch: 1 [28800/60000 (48%)]\tLoss: -77865759783956444949392654336.000000\n', 'Train Epoch: 1 [29440/60000 (49%)]\tLoss: -81394113680564363327967330304.000000\n', 'Train Epoch: 1 [30080/60000 (50%)]\tLoss: -81106351556564218627225550848.000000\n', 'Train Epoch: 1 [30720/60000 (51%)]\tLoss: -86955710800570704671170101248.000000\n', 'Train Epoch: 1 [31360/60000 (52%)]\tLoss: -85793593077534279419822080000.000000\n', 'Train Epoch: 1 [32000/60000 (53%)]\tLoss: -90106322602213880129101234176.000000\n', 'Train Epoch: 1 [32640/60000 (54%)]\tLoss: -90513485040366900939426103296.000000\n', 'Train Epoch: 1 [33280/60000 (55%)]\tLoss: -88733842341831543662063910912.000000\n', 'Train Epoch: 1 [33920/60000 (57%)]\tLoss: -91564561037925129353219276800.000000\n', 'Train Epoch: 1 [34560/60000 (58%)]\tLoss: -94845717938620753283437821952.000000\n', 'Train Epoch: 1 [35200/60000 (59%)]\tLoss: -96883192402387827450177388544.000000\n', 'Train Epoch: 1 [35840/60000 (60%)]\tLoss: -96067063582085329625056018432.000000\n', 'Train Epoch: 1 [36480/60000 (61%)]\tLoss: -95672273744117427285191032832.000000\n', 'Train Epoch: 1 [37120/60000 (62%)]\tLoss: -96804565000448047857369350144.000000\n', 'Train Epoch: 1 [37760/60000 (63%)]\tLoss: -100576479670776451057485611008.000000\n', 'Train Epoch: 1 [38400/60000 (64%)]\tLoss: -102986001055529927352741003264.000000\n', 'Train Epoch: 1 [39040/60000 (65%)]\tLoss: -100900566237762829069211140096.000000\n', 'Train Epoch: 1 [39680/60000 (66%)]\tLoss: -101539275749303914323653951488.000000\n', 'Train Epoch: 1 [40320/60000 (67%)]\tLoss: -106473383700532468689441652736.000000\n', 'Train Epoch: 1 [40960/60000 (68%)]\tLoss: -111197469124801878453995438080.000000\n', 'Train Epoch: 1 [41600/60000 (69%)]\tLoss: -117073717523561824257786773504.000000\n', 'Train Epoch: 1 [42240/60000 (70%)]\tLoss: -114991191683548173675708547072.000000\n', 'Train Epoch: 1 [42880/60000 (71%)]\tLoss: -106744570318177740935483359232.000000\n', 'Train Epoch: 1 [43520/60000 (72%)]\tLoss: -114544276364342356191974785024.000000\n', 'Train Epoch: 1 [44160/60000 (74%)]\tLoss: -115009165010381975545391874048.000000\n', 'Train Epoch: 1 [44800/60000 (75%)]\tLoss: -112732474350058656630707322880.000000\n', 'Train Epoch: 1 [45440/60000 (76%)]\tLoss: -119930239230117809690389774336.000000\n', 'Train Epoch: 1 [46080/60000 (77%)]\tLoss: -118174038358803417331868368896.000000\n', 'Train Epoch: 1 [46720/60000 (78%)]\tLoss: -122423129272759866702247755776.000000\n', 'Train Epoch: 1 [47360/60000 (79%)]\tLoss: -126098537661644345832776925184.000000\n', 'Train Epoch: 1 [48000/60000 (80%)]\tLoss: -121040382587643771626515857408.000000\n', 'Train Epoch: 1 [48640/60000 (81%)]\tLoss: -122372741622387647587817619456.000000\n', 'Train Epoch: 1 [49280/60000 (82%)]\tLoss: -130479373155739892565328003072.000000\n', 'Train Epoch: 1 [49920/60000 (83%)]\tLoss: -124674536382933901536458178560.000000\n', 'Train Epoch: 1 [50560/60000 (84%)]\tLoss: -132735672637590180351979814912.000000\n', 'Train Epoch: 1 [51200/60000 (85%)]\tLoss: -128494468075660123289107300352.000000\n', 'Train Epoch: 1 [51840/60000 (86%)]\tLoss: -129662668206726484643490562048.000000\n', 'Train Epoch: 1 [52480/60000 (87%)]\tLoss: -128768610894723671933052780544.000000\n', 'Train Epoch: 1 [53120/60000 (88%)]\tLoss: -136654056226751268468044070912.000000\n', 'Train Epoch: 1 [53760/60000 (90%)]\tLoss: -127911973614731118291288326144.000000\n', 'Train Epoch: 1 [54400/60000 (91%)]\tLoss: -131373761033396506150930743296.000000\n', 'Train Epoch: 1 [55040/60000 (92%)]\tLoss: -138569854195720723356207546368.000000\n', 'Train Epoch: 1 [55680/60000 (93%)]\tLoss: -144550674677877334583610966016.000000\n', 'Train Epoch: 1 [56320/60000 (94%)]\tLoss: -142396822214506420880225075200.000000\n', 'Train Epoch: 1 [56960/60000 (95%)]\tLoss: -143961295006616305643070423040.000000\n', 'Train Epoch: 1 [57600/60000 (96%)]\tLoss: -138835090631597579849279995904.000000\n', 'Train Epoch: 1 [58240/60000 (97%)]\tLoss: -144801800682703376576784891904.000000\n', 'Train Epoch: 1 [58880/60000 (98%)]\tLoss: -148088803873104793127777992704.000000\n', 'Train Epoch: 1 [59520/60000 (99%)]\tLoss: -146785855736816229316867129344.000000\n', 'Train Epoch: 1 [0/60000 (0%)]\tLoss: 0.001875\n', 'Train Epoch: 1 [640/60000 (1%)]\tLoss: -442497320727085056.000000\n', 'Train Epoch: 1 [1280/60000 (2%)]\tLoss: -85925155256267975941947392.000000\n', 'Train Epoch: 1 [1920/60000 (3%)]\tLoss: -1804740305504378365556031488.000000\n', 'Train Epoch: 1 [2560/60000 (4%)]\tLoss: -3733945958362415714539667456.000000\n', 'Train Epoch: 1 [3200/60000 (5%)]\tLoss: -6048151393173556270154645504.000000\n', 'Train Epoch: 1 [3840/60000 (6%)]\tLoss: -7801188869240236325088526336.000000\n', 'Train Epoch: 1 [4480/60000 (7%)]\tLoss: -10233545257121628789774745600.000000\n', 'Train Epoch: 1 [5120/60000 (9%)]\tLoss: -12300175611553940146063671296.000000\n', 'Train Epoch: 1 [5760/60000 (10%)]\tLoss: -14253008739665300226815557632.000000\n', 'Train Epoch: 1 [6400/60000 (11%)]\tLoss: -16364306778067454839769530368.000000\n', 'Train Epoch: 1 [7040/60000 (12%)]\tLoss: -17981668894193858911596969984.000000\n', 'Train Epoch: 1 [7680/60000 (13%)]\tLoss: -20355066536536623855790194688.000000\n', 'Train Epoch: 1 [8320/60000 (14%)]\tLoss: -21777521240223928343301455872.000000\n', 'Train Epoch: 1 [8960/60000 (15%)]\tLoss: -25152289611709477250591096832.000000\n', 'Train Epoch: 1 [9600/60000 (16%)]\tLoss: -25824173747792721762660122624.000000\n', 'Train Epoch: 1 [10240/60000 (17%)]\tLoss: -28178285245419447075800612864.000000\n', 'Train Epoch: 1 [10880/60000 (18%)]\tLoss: -29450948845453367851956043776.000000\n', 'Train Epoch: 1 [11520/60000 (19%)]\tLoss: -31929138161234251658263789568.000000\n', 'Train Epoch: 1 [12160/60000 (20%)]\tLoss: -32579013708324082188814385152.000000\n', 'Train Epoch: 1 [12800/60000 (21%)]\tLoss: -37807662740638940631048126464.000000\n', 'Train Epoch: 1 [13440/60000 (22%)]\tLoss: -36979069234004908377385205760.000000\n', 'Train Epoch: 1 [14080/60000 (23%)]\tLoss: -39703877055803935100510404608.000000\n', 'Train Epoch: 1 [14720/60000 (25%)]\tLoss: -42872806917034161912225464320.000000\n', 'Train Epoch: 1 [15360/60000 (26%)]\tLoss: -43672624683504827982778728448.000000\n', 'Train Epoch: 1 [16000/60000 (27%)]\tLoss: -43135592444706409059432005632.000000\n', 'Train Epoch: 1 [16640/60000 (28%)]\tLoss: -45588177089417173649391091712.000000\n', 'Train Epoch: 1 [17280/60000 (29%)]\tLoss: -47733033444638220678644891648.000000\n', 'Train Epoch: 1 [17920/60000 (30%)]\tLoss: -51875091922260429540255858688.000000\n', 'Train Epoch: 1 [18560/60000 (31%)]\tLoss: -52730614723763025945749880832.000000\n', 'Train Epoch: 1 [19200/60000 (32%)]\tLoss: -54314345326390053121776680960.000000\n', 'Train Epoch: 1 [19840/60000 (33%)]\tLoss: -55343575656598526556811296768.000000\n', 'Train Epoch: 1 [20480/60000 (34%)]\tLoss: -57294295525708802471330054144.000000\n', 'Train Epoch: 1 [21120/60000 (35%)]\tLoss: -58331194979085456210191712256.000000\n', 'Train Epoch: 1 [21760/60000 (36%)]\tLoss: -60645678738371180895521472512.000000\n', 'Train Epoch: 1 [22400/60000 (37%)]\tLoss: -60154944580570815973849825280.000000\n', 'Train Epoch: 1 [23040/60000 (38%)]\tLoss: -65154433695754700577621147648.000000\n', 'Train Epoch: 1 [23680/60000 (39%)]\tLoss: -68829742914943039445600829440.000000\n', 'Train Epoch: 1 [24320/60000 (41%)]\tLoss: -67930708228667282129107812352.000000\n', 'Train Epoch: 1 [24960/60000 (42%)]\tLoss: -65975615448193868923121172480.000000\n', 'Train Epoch: 1 [25600/60000 (43%)]\tLoss: -72687274089605869313441398784.000000\n', 'Train Epoch: 1 [26240/60000 (44%)]\tLoss: -76898694686128467523951132672.000000\n', 'Train Epoch: 1 [26880/60000 (45%)]\tLoss: -73842775777199794191845031936.000000\n', 'Train Epoch: 1 [27520/60000 (46%)]\tLoss: -75519985624355225994876944384.000000\n', 'Train Epoch: 1 [28160/60000 (47%)]\tLoss: -77521985671102983386771226624.000000\n', 'Train Epoch: 1 [28800/60000 (48%)]\tLoss: -78169563786898897834925359104.000000\n', 'Train Epoch: 1 [29440/60000 (49%)]\tLoss: -79341792096575146996675903488.000000\n', 'Train Epoch: 1 [30080/60000 (50%)]\tLoss: -82673468873904510391390568448.000000\n', 'Train Epoch: 1 [30720/60000 (51%)]\tLoss: -81731753439356577221456166912.000000\n', 'Train Epoch: 1 [31360/60000 (52%)]\tLoss: -87750570082234357614248984576.000000\n', 'Train Epoch: 1 [32000/60000 (53%)]\tLoss: -87669005368342233102118027264.000000\n', 'Train Epoch: 1 [32640/60000 (54%)]\tLoss: -90580750428548896165849989120.000000\n', 'Train Epoch: 1 [33280/60000 (55%)]\tLoss: -89875181652343342474471669760.000000\n', 'Train Epoch: 1 [33920/60000 (57%)]\tLoss: -95807068973004458438170771456.000000\n', 'Train Epoch: 1 [34560/60000 (58%)]\tLoss: -90077657837662861382654099456.000000\n', 'Train Epoch: 1 [35200/60000 (59%)]\tLoss: -94225708998351831824041246720.000000\n', 'Train Epoch: 1 [35840/60000 (60%)]\tLoss: -95391491277778963920075096064.000000\n', 'Train Epoch: 1 [36480/60000 (61%)]\tLoss: -93923893111698667059143507968.000000\n', 'Train Epoch: 1 [37120/60000 (62%)]\tLoss: -98458394411146792046948253696.000000\n', 'Train Epoch: 1 [37760/60000 (63%)]\tLoss: -101497841705783216056548982784.000000\n', 'Train Epoch: 1 [38400/60000 (64%)]\tLoss: -107083078992402802843691515904.000000\n', 'Train Epoch: 1 [39040/60000 (65%)]\tLoss: -102181895380292815644333703168.000000\n', 'Train Epoch: 1 [39680/60000 (66%)]\tLoss: -108340342955336085706805084160.000000\n', 'Train Epoch: 1 [40320/60000 (67%)]\tLoss: -104915569445163430126347616256.000000\n', 'Train Epoch: 1 [40960/60000 (68%)]\tLoss: -105392537904666230032221339648.000000\n', 'Train Epoch: 1 [41600/60000 (69%)]\tLoss: -107955479531715175361179287552.000000\n', 'Train Epoch: 1 [42240/60000 (70%)]\tLoss: -109814731884418749117553967104.000000\n', 'Train Epoch: 1 [42880/60000 (71%)]\tLoss: -118057131454153496394958110720.000000\n', 'Train Epoch: 1 [43520/60000 (72%)]\tLoss: -114318367796534838104241995776.000000\n', 'Train Epoch: 1 [44160/60000 (74%)]\tLoss: -111153012766732143613953703936.000000\n', 'Train Epoch: 1 [44800/60000 (75%)]\tLoss: -116042248791640470610920865792.000000\n', 'Train Epoch: 1 [45440/60000 (76%)]\tLoss: -117679606588046965477994397696.000000\n', 'Train Epoch: 1 [46080/60000 (77%)]\tLoss: -121763036885784347694277328896.000000\n', 'Train Epoch: 1 [46720/60000 (78%)]\tLoss: -124220499735071916627742162944.000000\n', 'Train Epoch: 1 [47360/60000 (79%)]\tLoss: -123621231428395758650124140544.000000\n', 'Train Epoch: 1 [48000/60000 (80%)]\tLoss: -120941581236089172909354909696.000000\n', 'Train Epoch: 1 [48640/60000 (81%)]\tLoss: -122283951687776732518509707264.000000\n', 'Train Epoch: 1 [49280/60000 (82%)]\tLoss: -125665987781279417809783226368.000000\n', 'Train Epoch: 1 [49920/60000 (83%)]\tLoss: -131404550862864816237724041216.000000\n', 'Train Epoch: 1 [50560/60000 (84%)]\tLoss: -124480371562624233203851853824.000000\n', 'Train Epoch: 1 [51200/60000 (85%)]\tLoss: -127804313103654656119706484736.000000\n', 'Train Epoch: 1 [51840/60000 (86%)]\tLoss: -133184458013923214215218200576.000000\n', 'Train Epoch: 1 [52480/60000 (87%)]\tLoss: -134571520942004652146675417088.000000\n', 'Train Epoch: 1 [53120/60000 (88%)]\tLoss: -130752420385779415451583905792.000000\n', 'Train Epoch: 1 [53760/60000 (90%)]\tLoss: -129341216720237547893794275328.000000\n', 'Train Epoch: 1 [54400/60000 (91%)]\tLoss: -132292100753854234577057349632.000000\n', 'Train Epoch: 1 [55040/60000 (92%)]\tLoss: -142488625018933406783179325440.000000\n', 'Train Epoch: 1 [55680/60000 (93%)]\tLoss: -144138563199650266385102143488.000000\n', 'Train Epoch: 1 [56320/60000 (94%)]\tLoss: -138257894665862354593390788608.000000\n', 'Train Epoch: 1 [56960/60000 (95%)]\tLoss: -141353934800429488431232450560.000000\n', 'Train Epoch: 1 [57600/60000 (96%)]\tLoss: -140408620922621608591645212672.000000\n', 'Train Epoch: 1 [58240/60000 (97%)]\tLoss: -149925077190502723190542827520.000000\n', 'Train Epoch: 1 [58880/60000 (98%)]\tLoss: -147349857410598316784029270016.000000\n', 'Train Epoch: 1 [59520/60000 (99%)]\tLoss: -144925602242418287195707146240.000000\n', '\n', 'Test set: Average loss: -149160019139218388078712324096.0000, Accuracy: 958/10000 (10%)\n', '\n', '\n', 'Test set: Average loss: -149160014303515108635033206784.0000, Accuracy: 958/10000 (10%)\n', '\n', '{"accuracy": 9.58, "runtime": 99.04266539029777, "mem_params": 244341408, "mem_bufs": 0, "mem_peak": 3344906752}\n']
[2021-12-11 15:44:11,004 DEBUG] Received error from gpu3: []
[2021-12-11 15:44:11,005 DEBUG] SSH connection with gpu3 has been closed
[2021-12-11 15:44:11,005 INFO] {'batch-size': 64, 'lr': 0.99, 'gamma': 0.5} => {"accuracy": 9.58, "runtime": 99.04266539029777, "mem_params": 244341408, "mem_bufs": 0, "mem_peak": 3344906752}
[2021-12-11 15:44:11,005 DEBUG] gpu3 finished training {'batch-size': 64, 'lr': 0.99, 'gamma': 0.5}
[2021-12-11 15:44:11,006 DEBUG] gpu3 now training {'batch-size': 128, 'lr': 0.5, 'gamma': 0.5}...
[2021-12-11 15:44:11,006 DEBUG] Attempting to establish SSH connection with gpu3...
[2021-12-11 15:44:11,100 DEBUG] SSH connection with gpu3 established successfully!
[2021-12-11 15:44:11,100 DEBUG] Running cmd on gpu3: source /u5/p3basta/CS848/CS848-Project/venv/bin/activate && python /u5/p3basta/CS848/CS848-Project/models/MNIST/train.py --arch "alexnet" --parallelism "dp" --epochs "1" --batch-size "128" --lr "0.5" --gamma "0.5"
[2021-12-11 15:44:11,100 INFO] Training {'batch-size': 128, 'lr': 0.5, 'gamma': 0.5} on gpu3...
[2021-12-11 15:44:11,954 DEBUG] Received output from gpu1: ['Train Epoch: 1 [0/60000 (0%)]\tLoss: 0.000904\n', 'Train Epoch: 1 [640/60000 (1%)]\tLoss: -601488454450151424.000000\n', 'Train Epoch: 1 [1280/60000 (2%)]\tLoss: -77315312703932742965919744.000000\n', 'Train Epoch: 1 [1920/60000 (3%)]\tLoss: -1759672253401159316782710784.000000\n', 'Train Epoch: 1 [2560/60000 (4%)]\tLoss: -3842000196744387142791200768.000000\n', 'Train Epoch: 1 [3200/60000 (5%)]\tLoss: -5789157925787053448054702080.000000\n', 'Train Epoch: 1 [3840/60000 (6%)]\tLoss: -7470662174962844834702819328.000000\n', 'Train Epoch: 1 [4480/60000 (7%)]\tLoss: -9500878361445748356748935168.000000\n', 'Train Epoch: 1 [5120/60000 (9%)]\tLoss: -11651373222247341742387888128.000000\n', 'Train Epoch: 1 [5760/60000 (10%)]\tLoss: -13403198821015355374618804224.000000\n', 'Train Epoch: 1 [6400/60000 (11%)]\tLoss: -14850853252846873006401650688.000000\n', 'Train Epoch: 1 [7040/60000 (12%)]\tLoss: -17592691108774748387578740736.000000\n', 'Train Epoch: 1 [7680/60000 (13%)]\tLoss: -18187653797810149966173175808.000000\n', 'Train Epoch: 1 [8320/60000 (14%)]\tLoss: -21449817340511672183342235648.000000\n', 'Train Epoch: 1 [8960/60000 (15%)]\tLoss: -23390525792678264450007957504.000000\n', 'Train Epoch: 1 [9600/60000 (16%)]\tLoss: -24987105954505179930661224448.000000\n', 'Train Epoch: 1 [10240/60000 (17%)]\tLoss: -27374616389082000809575579648.000000\n', 'Train Epoch: 1 [10880/60000 (18%)]\tLoss: -28648526693867399172067426304.000000\n', 'Train Epoch: 1 [11520/60000 (19%)]\tLoss: -30428854135542772547985604608.000000\n', 'Train Epoch: 1 [12160/60000 (20%)]\tLoss: -34064759928798047096302206976.000000\n', 'Train Epoch: 1 [12800/60000 (21%)]\tLoss: -34879209947815884762550108160.000000\n', 'Train Epoch: 1 [13440/60000 (22%)]\tLoss: -34816886516158212619842355200.000000\n', 'Train Epoch: 1 [14080/60000 (23%)]\tLoss: -39233885892779575095439917056.000000\n', 'Train Epoch: 1 [14720/60000 (25%)]\tLoss: -39401258366848682495926337536.000000\n', 'Train Epoch: 1 [15360/60000 (26%)]\tLoss: -42749113971748357295143124992.000000\n', 'Train Epoch: 1 [16000/60000 (27%)]\tLoss: -42919435563686016789065498624.000000\n', 'Train Epoch: 1 [16640/60000 (28%)]\tLoss: -44131884268696866719101091840.000000\n', 'Train Epoch: 1 [17280/60000 (29%)]\tLoss: -45951766252032756243329187840.000000\n', 'Train Epoch: 1 [17920/60000 (30%)]\tLoss: -46979112358014564689923538944.000000\n', 'Train Epoch: 1 [18560/60000 (31%)]\tLoss: -47944416013144431737700352000.000000\n', 'Train Epoch: 1 [19200/60000 (32%)]\tLoss: -50887475085499003418844332032.000000\n', 'Train Epoch: 1 [19840/60000 (33%)]\tLoss: -51252943749974768131577479168.000000\n', 'Train Epoch: 1 [20480/60000 (34%)]\tLoss: -55561111468631916763580203008.000000\n', 'Train Epoch: 1 [21120/60000 (35%)]\tLoss: -56302938574692943590909280256.000000\n', 'Train Epoch: 1 [21760/60000 (36%)]\tLoss: -59593799938510864642041970688.000000\n', 'Train Epoch: 1 [22400/60000 (37%)]\tLoss: -62864959589362253533343121408.000000\n', 'Train Epoch: 1 [23040/60000 (38%)]\tLoss: -65165229025534540586579656704.000000\n', 'Train Epoch: 1 [23680/60000 (39%)]\tLoss: -62053831755165114662503055360.000000\n', 'Train Epoch: 1 [24320/60000 (41%)]\tLoss: -64575055996704389545643212800.000000\n', 'Train Epoch: 1 [24960/60000 (42%)]\tLoss: -64549394657236475893551988736.000000\n', 'Train Epoch: 1 [25600/60000 (43%)]\tLoss: -72986218777437449334049210368.000000\n', 'Train Epoch: 1 [26240/60000 (44%)]\tLoss: -69645238938136832738263564288.000000\n', 'Train Epoch: 1 [26880/60000 (45%)]\tLoss: -75052065219033604329232662528.000000\n', 'Train Epoch: 1 [27520/60000 (46%)]\tLoss: -72144990579278499344617046016.000000\n', 'Train Epoch: 1 [28160/60000 (47%)]\tLoss: -72522756286075656613486657536.000000\n', 'Train Epoch: 1 [28800/60000 (48%)]\tLoss: -76380462188298352658200133632.000000\n', 'Train Epoch: 1 [29440/60000 (49%)]\tLoss: -77048346479970606580773158912.000000\n', 'Train Epoch: 1 [30080/60000 (50%)]\tLoss: -83127590524363186953720430592.000000\n', 'Train Epoch: 1 [30720/60000 (51%)]\tLoss: -83317835780492073480799387648.000000\n', 'Train Epoch: 1 [31360/60000 (52%)]\tLoss: -85195760370268913814349021184.000000\n', 'Train Epoch: 1 [32000/60000 (53%)]\tLoss: -83686161476689974328886820864.000000\n', 'Train Epoch: 1 [32640/60000 (54%)]\tLoss: -90660086185461106205440081920.000000\n', 'Train Epoch: 1 [33280/60000 (55%)]\tLoss: -86353524071408133252810014720.000000\n', 'Train Epoch: 1 [33920/60000 (57%)]\tLoss: -91410857453640688140803899392.000000\n', 'Train Epoch: 1 [34560/60000 (58%)]\tLoss: -91619859949439532898671656960.000000\n', 'Train Epoch: 1 [35200/60000 (59%)]\tLoss: -98612277445357582305881751552.000000\n', 'Train Epoch: 1 [35840/60000 (60%)]\tLoss: -94390009573023832520316157952.000000\n', 'Train Epoch: 1 [36480/60000 (61%)]\tLoss: -93588567312483059291809382400.000000\n', 'Train Epoch: 1 [37120/60000 (62%)]\tLoss: -98965614350338854900060913664.000000\n', 'Train Epoch: 1 [37760/60000 (63%)]\tLoss: -96845649588849013770728505344.000000\n', 'Train Epoch: 1 [38400/60000 (64%)]\tLoss: -99396076944718354539870158848.000000\n', 'Train Epoch: 1 [39040/60000 (65%)]\tLoss: -100991160116370200342990684160.000000\n', 'Train Epoch: 1 [39680/60000 (66%)]\tLoss: -107123634675757687356786737152.000000\n', 'Train Epoch: 1 [40320/60000 (67%)]\tLoss: -106595910221297004504156209152.000000\n', 'Train Epoch: 1 [40960/60000 (68%)]\tLoss: -105342376927885188660761460736.000000\n', 'Train Epoch: 1 [41600/60000 (69%)]\tLoss: -103680028368051347631217049600.000000\n', 'Train Epoch: 1 [42240/60000 (70%)]\tLoss: -107620115953567704636683452416.000000\n', 'Train Epoch: 1 [42880/60000 (71%)]\tLoss: -109443742773524509789566009344.000000\n', 'Train Epoch: 1 [43520/60000 (72%)]\tLoss: -113945348068052964828812148736.000000\n', 'Train Epoch: 1 [44160/60000 (74%)]\tLoss: -109927672001223059552484720640.000000\n', 'Train Epoch: 1 [44800/60000 (75%)]\tLoss: -112837452556972848843807784960.000000\n', 'Train Epoch: 1 [45440/60000 (76%)]\tLoss: -110850847424959246495310151680.000000\n', 'Train Epoch: 1 [46080/60000 (77%)]\tLoss: -114834380782118004236742557696.000000\n', 'Train Epoch: 1 [46720/60000 (78%)]\tLoss: -114358696806298544874366959616.000000\n', 'Train Epoch: 1 [47360/60000 (79%)]\tLoss: -120739095606036688261882052608.000000\n', 'Train Epoch: 1 [48000/60000 (80%)]\tLoss: -119640843167314592092404056064.000000\n', 'Train Epoch: 1 [48640/60000 (81%)]\tLoss: -123174448335451461516456361984.000000\n', 'Train Epoch: 1 [49280/60000 (82%)]\tLoss: -123995422303765383597566984192.000000\n', 'Train Epoch: 1 [49920/60000 (83%)]\tLoss: -125169619840264989401371639808.000000\n', 'Train Epoch: 1 [50560/60000 (84%)]\tLoss: -129847086062615510028375818240.000000\n', 'Train Epoch: 1 [51200/60000 (85%)]\tLoss: -129933883158570654107403550720.000000\n', 'Train Epoch: 1 [51840/60000 (86%)]\tLoss: -129953745431997603835172356096.000000\n', 'Train Epoch: 1 [52480/60000 (87%)]\tLoss: -129724351757725727949271859200.000000\n', 'Train Epoch: 1 [53120/60000 (88%)]\tLoss: -133089642339680157478617612288.000000\n', 'Train Epoch: 1 [53760/60000 (90%)]\tLoss: -130590518773280712535077552128.000000\n', 'Train Epoch: 1 [54400/60000 (91%)]\tLoss: -126910388017913363759334686720.000000\n', 'Train Epoch: 1 [55040/60000 (92%)]\tLoss: -137485910527441722211727048704.000000\n', 'Train Epoch: 1 [55680/60000 (93%)]\tLoss: -149586256840089791885750566912.000000\n', 'Train Epoch: 1 [56320/60000 (94%)]\tLoss: -137353580373858749013548859392.000000\n', 'Train Epoch: 1 [56960/60000 (95%)]\tLoss: -139398440618805031305402646528.000000\n', 'Train Epoch: 1 [57600/60000 (96%)]\tLoss: -134516061470029831033285771264.000000\n', 'Train Epoch: 1 [58240/60000 (97%)]\tLoss: -147925476105928263578417102848.000000\n', 'Train Epoch: 1 [58880/60000 (98%)]\tLoss: -144295383545813401563358560256.000000\n', 'Train Epoch: 1 [59520/60000 (99%)]\tLoss: -143657505170773301366473359360.000000\n', 'Train Epoch: 1 [0/60000 (0%)]\tLoss: -0.002475\n', 'Train Epoch: 1 [640/60000 (1%)]\tLoss: -575953774363803648.000000\n', 'Train Epoch: 1 [1280/60000 (2%)]\tLoss: -85554255796549934842380288.000000\n', 'Train Epoch: 1 [1920/60000 (3%)]\tLoss: -1705784296447465667514335232.000000\n', 'Train Epoch: 1 [2560/60000 (4%)]\tLoss: -3654803818476003330403336192.000000\n', 'Train Epoch: 1 [3200/60000 (5%)]\tLoss: -5433466921114070335736512512.000000\n', 'Train Epoch: 1 [3840/60000 (6%)]\tLoss: -7759091333228694872831033344.000000\n', 'Train Epoch: 1 [4480/60000 (7%)]\tLoss: -9453288713214629507107913728.000000\n', 'Train Epoch: 1 [5120/60000 (9%)]\tLoss: -11605967668514550103658201088.000000\n', 'Train Epoch: 1 [5760/60000 (10%)]\tLoss: -13358440231490716877283393536.000000\n', 'Train Epoch: 1 [6400/60000 (11%)]\tLoss: -15418723725370051430405111808.000000\n', 'Train Epoch: 1 [7040/60000 (12%)]\tLoss: -17884003271778390344109916160.000000\n', 'Train Epoch: 1 [7680/60000 (13%)]\tLoss: -19158850966310638331176681472.000000\n', 'Train Epoch: 1 [8320/60000 (14%)]\tLoss: -20888271297300676931691216896.000000\n', 'Train Epoch: 1 [8960/60000 (15%)]\tLoss: -23754967342444005014907125760.000000\n', 'Train Epoch: 1 [9600/60000 (16%)]\tLoss: -25404036607728016602110623744.000000\n', 'Train Epoch: 1 [10240/60000 (17%)]\tLoss: -28344096977365966058543906816.000000\n', 'Train Epoch: 1 [10880/60000 (18%)]\tLoss: -29239117652131284176605282304.000000\n', 'Train Epoch: 1 [11520/60000 (19%)]\tLoss: -30780696411532216899454631936.000000\n', 'Train Epoch: 1 [12160/60000 (20%)]\tLoss: -33734243859845242062618230784.000000\n', 'Train Epoch: 1 [12800/60000 (21%)]\tLoss: -33557889444725716596935360512.000000\n', 'Train Epoch: 1 [13440/60000 (22%)]\tLoss: -37368756554988070065596792832.000000\n', 'Train Epoch: 1 [14080/60000 (23%)]\tLoss: -39328203357358689084470460416.000000\n', 'Train Epoch: 1 [14720/60000 (25%)]\tLoss: -39587168490546294688699121664.000000\n', 'Train Epoch: 1 [15360/60000 (26%)]\tLoss: -42150152618893585844463992832.000000\n', 'Train Epoch: 1 [16000/60000 (27%)]\tLoss: -42341257345722354646971842560.000000\n', 'Train Epoch: 1 [16640/60000 (28%)]\tLoss: -46239613378629592597684813824.000000\n', 'Train Epoch: 1 [17280/60000 (29%)]\tLoss: -45270555442145844181963112448.000000\n', 'Train Epoch: 1 [17920/60000 (30%)]\tLoss: -47993514457466827438987149312.000000\n', 'Train Epoch: 1 [18560/60000 (31%)]\tLoss: -48758892005177925186996928512.000000\n', 'Train Epoch: 1 [19200/60000 (32%)]\tLoss: -49499132396100707813534203904.000000\n', 'Train Epoch: 1 [19840/60000 (33%)]\tLoss: -52513305585320813481951232000.000000\n', 'Train Epoch: 1 [20480/60000 (34%)]\tLoss: -51179038714517858183983136768.000000\n', 'Train Epoch: 1 [21120/60000 (35%)]\tLoss: -57511859671941089895970242560.000000\n', 'Train Epoch: 1 [21760/60000 (36%)]\tLoss: -59770624229095435637423603712.000000\n', 'Train Epoch: 1 [22400/60000 (37%)]\tLoss: -58240152475662212320116867072.000000\n', 'Train Epoch: 1 [23040/60000 (38%)]\tLoss: -59137411552140410650009534464.000000\n', 'Train Epoch: 1 [23680/60000 (39%)]\tLoss: -62262890919361753856113377280.000000\n', 'Train Epoch: 1 [24320/60000 (41%)]\tLoss: -62867358551535551313111678976.000000\n', 'Train Epoch: 1 [24960/60000 (42%)]\tLoss: -68527265896982272930373173248.000000\n', 'Train Epoch: 1 [25600/60000 (43%)]\tLoss: -67684167641696106561436385280.000000\n', 'Train Epoch: 1 [26240/60000 (44%)]\tLoss: -70102113728255022303753011200.000000\n', 'Train Epoch: 1 [26880/60000 (45%)]\tLoss: -69058942972189117676047564800.000000\n', 'Train Epoch: 1 [27520/60000 (46%)]\tLoss: -72948175393051451472207675392.000000\n', 'Train Epoch: 1 [28160/60000 (47%)]\tLoss: -72693394276567668373638348800.000000\n', 'Train Epoch: 1 [28800/60000 (48%)]\tLoss: -77660974361426802784700727296.000000\n', 'Train Epoch: 1 [29440/60000 (49%)]\tLoss: -79802940628360333591083745280.000000\n', 'Train Epoch: 1 [30080/60000 (50%)]\tLoss: -78105037371276967002725416960.000000\n', 'Train Epoch: 1 [30720/60000 (51%)]\tLoss: -85500098000623930969790873600.000000\n', 'Train Epoch: 1 [31360/60000 (52%)]\tLoss: -83260213464668098069901869056.000000\n', 'Train Epoch: 1 [32000/60000 (53%)]\tLoss: -83277213984006428792671174656.000000\n', 'Train Epoch: 1 [32640/60000 (54%)]\tLoss: -86904614795226055109957910528.000000\n', 'Train Epoch: 1 [33280/60000 (55%)]\tLoss: -87983854986488118087805566976.000000\n', 'Train Epoch: 1 [33920/60000 (57%)]\tLoss: -85528809988839778412690145280.000000\n', 'Train Epoch: 1 [34560/60000 (58%)]\tLoss: -93622426680165234647991582720.000000\n', 'Train Epoch: 1 [35200/60000 (59%)]\tLoss: -95731624446074132986236764160.000000\n', 'Train Epoch: 1 [35840/60000 (60%)]\tLoss: -96829744658534708805648777216.000000\n', 'Train Epoch: 1 [36480/60000 (61%)]\tLoss: -93127673788487947658243080192.000000\n', 'Train Epoch: 1 [37120/60000 (62%)]\tLoss: -95368068340023930479815163904.000000\n', 'Train Epoch: 1 [37760/60000 (63%)]\tLoss: -101526478136135337585124835328.000000\n', 'Train Epoch: 1 [38400/60000 (64%)]\tLoss: -97966607165620747194393952256.000000\n', 'Train Epoch: 1 [39040/60000 (65%)]\tLoss: -102913257722227803337869230080.000000\n', 'Train Epoch: 1 [39680/60000 (66%)]\tLoss: -98026278988498288031314214912.000000\n', 'Train Epoch: 1 [40320/60000 (67%)]\tLoss: -102374577377526862908342927360.000000\n', 'Train Epoch: 1 [40960/60000 (68%)]\tLoss: -101774638494810137441104560128.000000\n', 'Train Epoch: 1 [41600/60000 (69%)]\tLoss: -112637120326036552754552373248.000000\n', 'Train Epoch: 1 [42240/60000 (70%)]\tLoss: -109477621030672616624329064448.000000\n', 'Train Epoch: 1 [42880/60000 (71%)]\tLoss: -106684907940033165837853523968.000000\n', 'Train Epoch: 1 [43520/60000 (72%)]\tLoss: -115810890612911720952611471360.000000\n', 'Train Epoch: 1 [44160/60000 (74%)]\tLoss: -111034972494126333962192158720.000000\n', 'Train Epoch: 1 [44800/60000 (75%)]\tLoss: -112205911597752759710799364096.000000\n', 'Train Epoch: 1 [45440/60000 (76%)]\tLoss: -113046908399954049087616057344.000000\n', 'Train Epoch: 1 [46080/60000 (77%)]\tLoss: -115138359512620323299148169216.000000\n', 'Train Epoch: 1 [46720/60000 (78%)]\tLoss: -121563091888899646915929440256.000000\n', 'Train Epoch: 1 [47360/60000 (79%)]\tLoss: -121577532885604262290992922624.000000\n', 'Train Epoch: 1 [48000/60000 (80%)]\tLoss: -120760742933994162715541635072.000000\n', 'Train Epoch: 1 [48640/60000 (81%)]\tLoss: -125496832613863027118228635648.000000\n', 'Train Epoch: 1 [49280/60000 (82%)]\tLoss: -122145000776384776077741916160.000000\n', 'Train Epoch: 1 [49920/60000 (83%)]\tLoss: -127998846268549988284639477760.000000\n', 'Train Epoch: 1 [50560/60000 (84%)]\tLoss: -126411762785720123660510953472.000000\n', 'Train Epoch: 1 [51200/60000 (85%)]\tLoss: -129075904726496965486398406656.000000\n', 'Train Epoch: 1 [51840/60000 (86%)]\tLoss: -129183678574369016529465376768.000000\n', 'Train Epoch: 1 [52480/60000 (87%)]\tLoss: -131229011055963585785840533504.000000\n', 'Train Epoch: 1 [53120/60000 (88%)]\tLoss: -128389744876536006036848377856.000000\n', 'Train Epoch: 1 [53760/60000 (90%)]\tLoss: -136054381796557583700937670656.000000\n', 'Train Epoch: 1 [54400/60000 (91%)]\tLoss: -136475069092317543175154565120.000000\n', 'Train Epoch: 1 [55040/60000 (92%)]\tLoss: -137588026980267295419828011008.000000\n', 'Train Epoch: 1 [55680/60000 (93%)]\tLoss: -136613028306748096990427480064.000000\n', 'Train Epoch: 1 [56320/60000 (94%)]\tLoss: -138566841325904652522561208320.000000\n', 'Train Epoch: 1 [56960/60000 (95%)]\tLoss: -143481181451035914553484378112.000000\n', 'Train Epoch: 1 [57600/60000 (96%)]\tLoss: -143902577101768304474483326976.000000\n', 'Train Epoch: 1 [58240/60000 (97%)]\tLoss: -138069425019531027052912181248.000000\n', 'Train Epoch: 1 [58880/60000 (98%)]\tLoss: -141891462887708608667326611456.000000\n', 'Train Epoch: 1 [59520/60000 (99%)]\tLoss: -147915719696774654891405606912.000000\n', '\n', 'Test set: Average loss: -147241213045466701022917296128.0000, Accuracy: 982/10000 (10%)\n', '\n', '\n', 'Test set: Average loss: -147241213045466701022917296128.0000, Accuracy: 982/10000 (10%)\n', '\n', '{"accuracy": 9.82, "runtime": 98.22968475613743, "mem_params": 244341408, "mem_bufs": 0, "mem_peak": 3344906752}\n']
[2021-12-11 15:44:11,954 DEBUG] Received error from gpu1: []
[2021-12-11 15:44:11,954 DEBUG] SSH connection with gpu1 has been closed
[2021-12-11 15:44:11,955 INFO] {'batch-size': 64, 'lr': 0.99, 'gamma': 0.7} => {"accuracy": 9.82, "runtime": 98.22968475613743, "mem_params": 244341408, "mem_bufs": 0, "mem_peak": 3344906752}
[2021-12-11 15:44:11,955 DEBUG] gpu1 finished training {'batch-size': 64, 'lr': 0.99, 'gamma': 0.7}
[2021-12-11 15:44:11,956 DEBUG] gpu1 now training {'batch-size': 128, 'lr': 0.5, 'gamma': 0.7}...
[2021-12-11 15:44:11,956 DEBUG] Attempting to establish SSH connection with gpu1...
[2021-12-11 15:44:12,060 DEBUG] SSH connection with gpu1 established successfully!
[2021-12-11 15:44:12,060 DEBUG] Running cmd on gpu1: source /u5/p3basta/CS848/CS848-Project/venv/bin/activate && python /u5/p3basta/CS848/CS848-Project/models/MNIST/train.py --arch "alexnet" --parallelism "dp" --epochs "1" --batch-size "128" --lr "0.5" --gamma "0.7"
[2021-12-11 15:44:12,060 INFO] Training {'batch-size': 128, 'lr': 0.5, 'gamma': 0.7} on gpu1...
[2021-12-11 15:44:13,633 DEBUG] Received output from gpu2: ['Train Epoch: 1 [0/60000 (0%)]\tLoss: 0.011550\n', 'Train Epoch: 1 [640/60000 (1%)]\tLoss: -173069692921970688.000000\n', 'Train Epoch: 1 [1280/60000 (2%)]\tLoss: -55973107728495500572229632.000000\n', 'Train Epoch: 1 [1920/60000 (3%)]\tLoss: -1707873943616135485521395712.000000\n', 'Train Epoch: 1 [2560/60000 (4%)]\tLoss: -4846933656250591073848524800.000000\n', 'Train Epoch: 1 [3200/60000 (5%)]\tLoss: -7474497917138555704027643904.000000\n', 'Train Epoch: 1 [3840/60000 (6%)]\tLoss: -10399530536036393231979642880.000000\n', 'Train Epoch: 1 [4480/60000 (7%)]\tLoss: -13060098825977323453851631616.000000\n', 'Train Epoch: 1 [5120/60000 (9%)]\tLoss: -16390374241052895281349132288.000000\n', 'Train Epoch: 1 [5760/60000 (10%)]\tLoss: -19170008737718038585405341696.000000\n', 'Train Epoch: 1 [6400/60000 (11%)]\tLoss: -21680561611597648787773849600.000000\n', 'Train Epoch: 1 [7040/60000 (12%)]\tLoss: -24199469532377076109936689152.000000\n', 'Train Epoch: 1 [7680/60000 (13%)]\tLoss: -28031825771319727899143045120.000000\n', 'Train Epoch: 1 [8320/60000 (14%)]\tLoss: -30497663737564666148394369024.000000\n', 'Train Epoch: 1 [8960/60000 (15%)]\tLoss: -31814129647910444318729437184.000000\n', 'Train Epoch: 1 [9600/60000 (16%)]\tLoss: -34343587335412602428299673600.000000\n', 'Train Epoch: 1 [10240/60000 (17%)]\tLoss: -37768063336496837221108678656.000000\n', 'Train Epoch: 1 [10880/60000 (18%)]\tLoss: -40291764459256377233163419648.000000\n', 'Train Epoch: 1 [11520/60000 (19%)]\tLoss: -44001801961559739472044621824.000000\n', 'Train Epoch: 1 [12160/60000 (20%)]\tLoss: -44562261860479674705296490496.000000\n', 'Train Epoch: 1 [12800/60000 (21%)]\tLoss: -47535548800691094985453338624.000000\n', 'Train Epoch: 1 [13440/60000 (22%)]\tLoss: -49786998412163475646470684672.000000\n', 'Train Epoch: 1 [14080/60000 (23%)]\tLoss: -55669423666283014946201534464.000000\n', 'Train Epoch: 1 [14720/60000 (25%)]\tLoss: -55506898701408573236526972928.000000\n', 'Train Epoch: 1 [15360/60000 (26%)]\tLoss: -59351542537939651842579365888.000000\n', 'Train Epoch: 1 [16000/60000 (27%)]\tLoss: -58284268823345180545703215104.000000\n', 'Train Epoch: 1 [16640/60000 (28%)]\tLoss: -63752972272266993097907372032.000000\n', 'Train Epoch: 1 [17280/60000 (29%)]\tLoss: -65682691777627947700160823296.000000\n', 'Train Epoch: 1 [17920/60000 (30%)]\tLoss: -67039087657769630155600297984.000000\n', 'Train Epoch: 1 [18560/60000 (31%)]\tLoss: -69391265346321620349025779712.000000\n', 'Train Epoch: 1 [19200/60000 (32%)]\tLoss: -73887416307562360948050100224.000000\n', 'Train Epoch: 1 [19840/60000 (33%)]\tLoss: -77788114634245102242789064704.000000\n', 'Train Epoch: 1 [20480/60000 (34%)]\tLoss: -75988194094032302708879261696.000000\n', 'Train Epoch: 1 [21120/60000 (35%)]\tLoss: -78415665193787166525591912448.000000\n', 'Train Epoch: 1 [21760/60000 (36%)]\tLoss: -84216558790579961400708300800.000000\n', 'Train Epoch: 1 [22400/60000 (37%)]\tLoss: -82049323140596595122786795520.000000\n', 'Train Epoch: 1 [23040/60000 (38%)]\tLoss: -86577165903303873910840229888.000000\n', 'Train Epoch: 1 [23680/60000 (39%)]\tLoss: -90092334952691620239978266624.000000\n', 'Train Epoch: 1 [24320/60000 (41%)]\tLoss: -91756081333004390684505931776.000000\n', 'Train Epoch: 1 [24960/60000 (42%)]\tLoss: -95693099380306882420583432192.000000\n', 'Train Epoch: 1 [25600/60000 (43%)]\tLoss: -97490337616357411996011855872.000000\n', 'Train Epoch: 1 [26240/60000 (44%)]\tLoss: -93646727978086081842261262336.000000\n', 'Train Epoch: 1 [26880/60000 (45%)]\tLoss: -99500214570398595956122583040.000000\n', 'Train Epoch: 1 [27520/60000 (46%)]\tLoss: -101872542596732990925674905600.000000\n', 'Train Epoch: 1 [28160/60000 (47%)]\tLoss: -102951234993483041024677773312.000000\n', 'Train Epoch: 1 [28800/60000 (48%)]\tLoss: -104477296056621264093354917888.000000\n', 'Train Epoch: 1 [29440/60000 (49%)]\tLoss: -112724512440168538408877031424.000000\n', 'Train Epoch: 1 [30080/60000 (50%)]\tLoss: -110444072220857820995892805632.000000\n', 'Train Epoch: 1 [30720/60000 (51%)]\tLoss: -113874125336758324839699185664.000000\n', 'Train Epoch: 1 [31360/60000 (52%)]\tLoss: -113900485586465703199282036736.000000\n', 'Train Epoch: 1 [32000/60000 (53%)]\tLoss: -118490852481406176089964806144.000000\n', 'Train Epoch: 1 [32640/60000 (54%)]\tLoss: -122909334681103159634159468544.000000\n', 'Train Epoch: 1 [33280/60000 (55%)]\tLoss: -123447769462746990842134659072.000000\n', 'Train Epoch: 1 [33920/60000 (57%)]\tLoss: -124833642354474745622998024192.000000\n', 'Train Epoch: 1 [34560/60000 (58%)]\tLoss: -127659619794619530190358839296.000000\n', 'Train Epoch: 1 [35200/60000 (59%)]\tLoss: -124461916554409178630356729856.000000\n', 'Train Epoch: 1 [35840/60000 (60%)]\tLoss: -129983940243289072346668728320.000000\n', 'Train Epoch: 1 [36480/60000 (61%)]\tLoss: -130018942423660102156992643072.000000\n', 'Train Epoch: 1 [37120/60000 (62%)]\tLoss: -132440024161563643343731163136.000000\n', 'Train Epoch: 1 [37760/60000 (63%)]\tLoss: -133089897347470232439459151872.000000\n', 'Train Epoch: 1 [38400/60000 (64%)]\tLoss: -140913073555054709832662646784.000000\n', 'Train Epoch: 1 [39040/60000 (65%)]\tLoss: -140693124613748573237189541888.000000\n', 'Train Epoch: 1 [39680/60000 (66%)]\tLoss: -140509424557564944038376767488.000000\n', 'Train Epoch: 1 [40320/60000 (67%)]\tLoss: -147008675876943950656630161408.000000\n', 'Train Epoch: 1 [40960/60000 (68%)]\tLoss: -143550137446418777112894767104.000000\n', 'Train Epoch: 1 [41600/60000 (69%)]\tLoss: -146584097351202106594757181440.000000\n', 'Train Epoch: 1 [42240/60000 (70%)]\tLoss: -153389783031654524490927308800.000000\n', 'Train Epoch: 1 [42880/60000 (71%)]\tLoss: -153150632948229039918015315968.000000\n', 'Train Epoch: 1 [43520/60000 (72%)]\tLoss: -156277595138526004192716259328.000000\n', 'Train Epoch: 1 [44160/60000 (74%)]\tLoss: -154355469198469503979966431232.000000\n', 'Train Epoch: 1 [44800/60000 (75%)]\tLoss: -159574392517012892387882565632.000000\n', 'Train Epoch: 1 [45440/60000 (76%)]\tLoss: -163086492028186773447631699968.000000\n', 'Train Epoch: 1 [46080/60000 (77%)]\tLoss: -164299214630453629817089687552.000000\n', 'Train Epoch: 1 [46720/60000 (78%)]\tLoss: -161189857422404803579745402880.000000\n', 'Train Epoch: 1 [47360/60000 (79%)]\tLoss: -163435588248066429100408963072.000000\n', 'Train Epoch: 1 [48000/60000 (80%)]\tLoss: -170280828470179363144889008128.000000\n', 'Train Epoch: 1 [48640/60000 (81%)]\tLoss: -172552853432417606850102427648.000000\n', 'Train Epoch: 1 [49280/60000 (82%)]\tLoss: -170127880464532181075707822080.000000\n', 'Train Epoch: 1 [49920/60000 (83%)]\tLoss: -173263135130373064447404015616.000000\n', 'Train Epoch: 1 [50560/60000 (84%)]\tLoss: -174270661464226268993036484608.000000\n', 'Train Epoch: 1 [51200/60000 (85%)]\tLoss: -177775054073300106791796867072.000000\n', 'Train Epoch: 1 [51840/60000 (86%)]\tLoss: -180545213141617372152731795456.000000\n', 'Train Epoch: 1 [52480/60000 (87%)]\tLoss: -183060345530393745193546285056.000000\n', 'Train Epoch: 1 [53120/60000 (88%)]\tLoss: -181273288716480282573198589952.000000\n', 'Train Epoch: 1 [53760/60000 (90%)]\tLoss: -184779513603749473794301886464.000000\n', 'Train Epoch: 1 [54400/60000 (91%)]\tLoss: -184179659723629439980677365760.000000\n', 'Train Epoch: 1 [55040/60000 (92%)]\tLoss: -187619393690819826597171822592.000000\n', 'Train Epoch: 1 [55680/60000 (93%)]\tLoss: -196061473804916233952791887872.000000\n', 'Train Epoch: 1 [56320/60000 (94%)]\tLoss: -188760903006525008716807274496.000000\n', 'Train Epoch: 1 [56960/60000 (95%)]\tLoss: -194532447095626768746920542208.000000\n', 'Train Epoch: 1 [57600/60000 (96%)]\tLoss: -188305289088257745346589884416.000000\n', 'Train Epoch: 1 [58240/60000 (97%)]\tLoss: -199309026345719757487669772288.000000\n', 'Train Epoch: 1 [58880/60000 (98%)]\tLoss: -195201738652510917823767248896.000000\n', 'Train Epoch: 1 [59520/60000 (99%)]\tLoss: -204641484799244297905813585920.000000\n', 'Train Epoch: 1 [0/60000 (0%)]\tLoss: 0.010798\n', 'Train Epoch: 1 [640/60000 (1%)]\tLoss: -167201307306754048.000000\n', 'Train Epoch: 1 [1280/60000 (2%)]\tLoss: -57026896430450232417845248.000000\n', 'Train Epoch: 1 [1920/60000 (3%)]\tLoss: -1661457065586246794333913088.000000\n', 'Train Epoch: 1 [2560/60000 (4%)]\tLoss: -4820409304307932994094497792.000000\n', 'Train Epoch: 1 [3200/60000 (5%)]\tLoss: -7740995224866338392372150272.000000\n', 'Train Epoch: 1 [3840/60000 (6%)]\tLoss: -10610944980516363661140295680.000000\n', 'Train Epoch: 1 [4480/60000 (7%)]\tLoss: -13259496028350011353354731520.000000\n', 'Train Epoch: 1 [5120/60000 (9%)]\tLoss: -16415680222442972992638025728.000000\n', 'Train Epoch: 1 [5760/60000 (10%)]\tLoss: -18837070094759521423726739456.000000\n', 'Train Epoch: 1 [6400/60000 (11%)]\tLoss: -21154761521478735315567902720.000000\n', 'Train Epoch: 1 [7040/60000 (12%)]\tLoss: -24358282717195982278473285632.000000\n', 'Train Epoch: 1 [7680/60000 (13%)]\tLoss: -26167631462091831059052232704.000000\n', 'Train Epoch: 1 [8320/60000 (14%)]\tLoss: -29736630767017808473981190144.000000\n', 'Train Epoch: 1 [8960/60000 (15%)]\tLoss: -32924674406587450174698684416.000000\n', 'Train Epoch: 1 [9600/60000 (16%)]\tLoss: -35701947720011158656148045824.000000\n', 'Train Epoch: 1 [10240/60000 (17%)]\tLoss: -37575523010257276046455865344.000000\n', 'Train Epoch: 1 [10880/60000 (18%)]\tLoss: -40972592757458176853267185664.000000\n', 'Train Epoch: 1 [11520/60000 (19%)]\tLoss: -42081961646880948167578222592.000000\n', 'Train Epoch: 1 [12160/60000 (20%)]\tLoss: -44643292946959234947518300160.000000\n', 'Train Epoch: 1 [12800/60000 (21%)]\tLoss: -47393641687880862146781773824.000000\n', 'Train Epoch: 1 [13440/60000 (22%)]\tLoss: -49346925801991336278651568128.000000\n', 'Train Epoch: 1 [14080/60000 (23%)]\tLoss: -53387410898933501941361147904.000000\n', 'Train Epoch: 1 [14720/60000 (25%)]\tLoss: -55104019449655515194410926080.000000\n', 'Train Epoch: 1 [15360/60000 (26%)]\tLoss: -59122687213446823096233230336.000000\n', 'Train Epoch: 1 [16000/60000 (27%)]\tLoss: -61626920380380732995894509568.000000\n', 'Train Epoch: 1 [16640/60000 (28%)]\tLoss: -63370356695091928703403294720.000000\n', 'Train Epoch: 1 [17280/60000 (29%)]\tLoss: -66727765647386448794887389184.000000\n', 'Train Epoch: 1 [17920/60000 (30%)]\tLoss: -68810555939923140077097582592.000000\n', 'Train Epoch: 1 [18560/60000 (31%)]\tLoss: -71951897736160442421474230272.000000\n', 'Train Epoch: 1 [19200/60000 (32%)]\tLoss: -70222090171118808510052171776.000000\n', 'Train Epoch: 1 [19840/60000 (33%)]\tLoss: -73607842767043512212108869632.000000\n', 'Train Epoch: 1 [20480/60000 (34%)]\tLoss: -76927638070301975579465875456.000000\n', 'Train Epoch: 1 [21120/60000 (35%)]\tLoss: -79931729007081154555351662592.000000\n', 'Train Epoch: 1 [21760/60000 (36%)]\tLoss: -84991149675299137826530000896.000000\n', 'Train Epoch: 1 [22400/60000 (37%)]\tLoss: -84486083135223263531634786304.000000\n', 'Train Epoch: 1 [23040/60000 (38%)]\tLoss: -84300994703293670657129185280.000000\n', 'Train Epoch: 1 [23680/60000 (39%)]\tLoss: -87603213358502893205000814592.000000\n', 'Train Epoch: 1 [24320/60000 (41%)]\tLoss: -92427044607623475615758286848.000000\n', 'Train Epoch: 1 [24960/60000 (42%)]\tLoss: -92937995216337005488589766656.000000\n', 'Train Epoch: 1 [25600/60000 (43%)]\tLoss: -96809759603579204467104415744.000000\n', 'Train Epoch: 1 [26240/60000 (44%)]\tLoss: -97925909811271376591942320128.000000\n', 'Train Epoch: 1 [26880/60000 (45%)]\tLoss: -100741753052943922900674543616.000000\n', 'Train Epoch: 1 [27520/60000 (46%)]\tLoss: -101608241189419742622354767872.000000\n', 'Train Epoch: 1 [28160/60000 (47%)]\tLoss: -104759240225114513391193423872.000000\n', 'Train Epoch: 1 [28800/60000 (48%)]\tLoss: -105144736445844128269277855744.000000\n', 'Train Epoch: 1 [29440/60000 (49%)]\tLoss: -108233013009913424410388201472.000000\n', 'Train Epoch: 1 [30080/60000 (50%)]\tLoss: -114242139356768356291202514944.000000\n', 'Train Epoch: 1 [30720/60000 (51%)]\tLoss: -114944600815828181756030222336.000000\n', 'Train Epoch: 1 [31360/60000 (52%)]\tLoss: -108542894698519330529310932992.000000\n', 'Train Epoch: 1 [32000/60000 (53%)]\tLoss: -116320056167094726099552174080.000000\n', 'Train Epoch: 1 [32640/60000 (54%)]\tLoss: -119075292557326123381611823104.000000\n', 'Train Epoch: 1 [33280/60000 (55%)]\tLoss: -126016009584989715913022373888.000000\n', 'Train Epoch: 1 [33920/60000 (57%)]\tLoss: -126510630250405482552704892928.000000\n', 'Train Epoch: 1 [34560/60000 (58%)]\tLoss: -127541655079877446452920713216.000000\n', 'Train Epoch: 1 [35200/60000 (59%)]\tLoss: -132905441712649344097412186112.000000\n', 'Train Epoch: 1 [35840/60000 (60%)]\tLoss: -130806614263536827500056281088.000000\n', 'Train Epoch: 1 [36480/60000 (61%)]\tLoss: -134605342530754964545695907840.000000\n', 'Train Epoch: 1 [37120/60000 (62%)]\tLoss: -132609207663178931253157036032.000000\n', 'Train Epoch: 1 [37760/60000 (63%)]\tLoss: -140313134672337984365424279552.000000\n', 'Train Epoch: 1 [38400/60000 (64%)]\tLoss: -136368315275605791975453753344.000000\n', 'Train Epoch: 1 [39040/60000 (65%)]\tLoss: -142144307833934415211358322688.000000\n', 'Train Epoch: 1 [39680/60000 (66%)]\tLoss: -143063762032882100873755361280.000000\n', 'Train Epoch: 1 [40320/60000 (67%)]\tLoss: -142621852422148125213948116992.000000\n', 'Train Epoch: 1 [40960/60000 (68%)]\tLoss: -142177118836257393506303082496.000000\n', 'Train Epoch: 1 [41600/60000 (69%)]\tLoss: -151856128403211847032746541056.000000\n', 'Train Epoch: 1 [42240/60000 (70%)]\tLoss: -153737311425861867421493624832.000000\n', 'Train Epoch: 1 [42880/60000 (71%)]\tLoss: -155756888120658865632873283584.000000\n', 'Train Epoch: 1 [43520/60000 (72%)]\tLoss: -154816098269941574913400766464.000000\n', 'Train Epoch: 1 [44160/60000 (74%)]\tLoss: -156719636975521500202589487104.000000\n', 'Train Epoch: 1 [44800/60000 (75%)]\tLoss: -161996815406997568553861775360.000000\n', 'Train Epoch: 1 [45440/60000 (76%)]\tLoss: -159586878453993599729827577856.000000\n', 'Train Epoch: 1 [46080/60000 (77%)]\tLoss: -156761297692633376212664713216.000000\n', 'Train Epoch: 1 [46720/60000 (78%)]\tLoss: -168818802696548852465309581312.000000\n', 'Train Epoch: 1 [47360/60000 (79%)]\tLoss: -165695240610119554335162499072.000000\n', 'Train Epoch: 1 [48000/60000 (80%)]\tLoss: -168987598964112545063827931136.000000\n', 'Train Epoch: 1 [48640/60000 (81%)]\tLoss: -169860160063885335149252968448.000000\n', 'Train Epoch: 1 [49280/60000 (82%)]\tLoss: -174077252222553859803664351232.000000\n', 'Train Epoch: 1 [49920/60000 (83%)]\tLoss: -175213510266730090877822173184.000000\n', 'Train Epoch: 1 [50560/60000 (84%)]\tLoss: -178059963887944598226829574144.000000\n', 'Train Epoch: 1 [51200/60000 (85%)]\tLoss: -180179003065603796905700098048.000000\n', 'Train Epoch: 1 [51840/60000 (86%)]\tLoss: -180778705829996378890677780480.000000\n', 'Train Epoch: 1 [52480/60000 (87%)]\tLoss: -179044445073361398903819206656.000000\n', 'Train Epoch: 1 [53120/60000 (88%)]\tLoss: -183549903818939875573559721984.000000\n', 'Train Epoch: 1 [53760/60000 (90%)]\tLoss: -184824848321985022388353368064.000000\n', 'Train Epoch: 1 [54400/60000 (91%)]\tLoss: -183904024636757304528844357632.000000\n', 'Train Epoch: 1 [55040/60000 (92%)]\tLoss: -180457244898774476401691066368.000000\n', 'Train Epoch: 1 [55680/60000 (93%)]\tLoss: -190447845651001634858624614400.000000\n', 'Train Epoch: 1 [56320/60000 (94%)]\tLoss: -193368383757599401201744478208.000000\n', 'Train Epoch: 1 [56960/60000 (95%)]\tLoss: -192675952604949190863350661120.000000\n', 'Train Epoch: 1 [57600/60000 (96%)]\tLoss: -195087778504546307545470337024.000000\n', 'Train Epoch: 1 [58240/60000 (97%)]\tLoss: -189330458183290950886740721664.000000\n', 'Train Epoch: 1 [58880/60000 (98%)]\tLoss: -200084835600991514281956605952.000000\n', 'Train Epoch: 1 [59520/60000 (99%)]\tLoss: -209778682843435144233661497344.000000\n', '\n', 'Test set: Average loss: -202758371091837212924523315200.0000, Accuracy: 1028/10000 (10%)\n', '\n', '\n', 'Test set: Average loss: -202758355617586725741624557568.0000, Accuracy: 1028/10000 (10%)\n', '\n', '{"accuracy": 10.28, "runtime": 98.22733215102926, "mem_params": 244341408, "mem_bufs": 0, "mem_peak": 3344906752}\n']
[2021-12-11 15:44:13,634 DEBUG] Received error from gpu2: []
[2021-12-11 15:44:13,634 DEBUG] SSH connection with gpu2 has been closed
[2021-12-11 15:44:13,634 INFO] {'batch-size': 64, 'lr': 0.99, 'gamma': 0.9} => {"accuracy": 10.28, "runtime": 98.22733215102926, "mem_params": 244341408, "mem_bufs": 0, "mem_peak": 3344906752}
[2021-12-11 15:44:13,635 DEBUG] gpu2 finished training {'batch-size': 64, 'lr': 0.99, 'gamma': 0.9}
[2021-12-11 15:44:13,635 DEBUG] gpu2 now training {'batch-size': 128, 'lr': 0.5, 'gamma': 0.9}...
[2021-12-11 15:44:13,635 DEBUG] Attempting to establish SSH connection with gpu2...
[2021-12-11 15:44:13,741 DEBUG] SSH connection with gpu2 established successfully!
[2021-12-11 15:44:13,741 DEBUG] Running cmd on gpu2: source /u5/p3basta/CS848/CS848-Project/venv/bin/activate && python /u5/p3basta/CS848/CS848-Project/models/MNIST/train.py --arch "alexnet" --parallelism "dp" --epochs "1" --batch-size "128" --lr "0.5" --gamma "0.9"
[2021-12-11 15:44:13,742 INFO] Training {'batch-size': 128, 'lr': 0.5, 'gamma': 0.9} on gpu2...
[2021-12-11 15:45:19,644 DEBUG] Received output from gpu3: ['Train Epoch: 1 [0/60000 (0%)]\tLoss: -0.007550\n', 'Train Epoch: 1 [1280/60000 (2%)]\tLoss: -665780798619648.000000\n', 'Train Epoch: 1 [2560/60000 (4%)]\tLoss: -19684506765997407247269888.000000\n', 'Train Epoch: 1 [3840/60000 (6%)]\tLoss: -1119621220844057608908177408.000000\n', 'Train Epoch: 1 [5120/60000 (9%)]\tLoss: -3598062224001083108338171904.000000\n', 'Train Epoch: 1 [6400/60000 (11%)]\tLoss: -5718755705668812059797618688.000000\n', 'Train Epoch: 1 [7680/60000 (13%)]\tLoss: -8083216269442746200423923712.000000\n', 'Train Epoch: 1 [8960/60000 (15%)]\tLoss: -10425223751478066254176059392.000000\n', 'Train Epoch: 1 [10240/60000 (17%)]\tLoss: -12889641466003281457629364224.000000\n', 'Train Epoch: 1 [11520/60000 (19%)]\tLoss: -14450080176545174826050912256.000000\n', 'Train Epoch: 1 [12800/60000 (21%)]\tLoss: -17547991548831145760808501248.000000\n', 'Train Epoch: 1 [14080/60000 (23%)]\tLoss: -18858137752231223628436340736.000000\n', 'Train Epoch: 1 [15360/60000 (26%)]\tLoss: -21957915639869548790464643072.000000\n', 'Train Epoch: 1 [16640/60000 (28%)]\tLoss: -23328733627249915142386745344.000000\n', 'Train Epoch: 1 [17920/60000 (30%)]\tLoss: -26031055901040758049826930688.000000\n', 'Train Epoch: 1 [19200/60000 (32%)]\tLoss: -28594061280037222118995263488.000000\n', 'Train Epoch: 1 [20480/60000 (34%)]\tLoss: -29896610376357983444885569536.000000\n', 'Train Epoch: 1 [21760/60000 (36%)]\tLoss: -31998202771046220219514093568.000000\n', 'Train Epoch: 1 [23040/60000 (38%)]\tLoss: -35156455361658678763400986624.000000\n', 'Train Epoch: 1 [24320/60000 (41%)]\tLoss: -36435385542015367558754992128.000000\n', 'Train Epoch: 1 [25600/60000 (43%)]\tLoss: -39180818299428327457351008256.000000\n', 'Train Epoch: 1 [26880/60000 (45%)]\tLoss: -42310448626788113081597689856.000000\n', 'Train Epoch: 1 [28160/60000 (47%)]\tLoss: -45151485693646768947544981504.000000\n', 'Train Epoch: 1 [29440/60000 (49%)]\tLoss: -45920017782168423618557509632.000000\n', 'Train Epoch: 1 [30720/60000 (51%)]\tLoss: -48751586504228925845851340800.000000\n', 'Train Epoch: 1 [32000/60000 (53%)]\tLoss: -52400516584243954875667316736.000000\n', 'Train Epoch: 1 [33280/60000 (55%)]\tLoss: -52673785765508172635248263168.000000\n', 'Train Epoch: 1 [34560/60000 (58%)]\tLoss: -54940592512782845382500548608.000000\n', 'Train Epoch: 1 [35840/60000 (60%)]\tLoss: -58377280553591781077832171520.000000\n', 'Train Epoch: 1 [37120/60000 (62%)]\tLoss: -57949523875206965744730374144.000000\n', 'Train Epoch: 1 [38400/60000 (64%)]\tLoss: -62310709602367291883547262976.000000\n', 'Train Epoch: 1 [39680/60000 (66%)]\tLoss: -63381322030065152019589496832.000000\n', 'Train Epoch: 1 [40960/60000 (68%)]\tLoss: -65163047292219454810490929152.000000\n', 'Train Epoch: 1 [42240/60000 (70%)]\tLoss: -67489615587334842917922537472.000000\n', 'Train Epoch: 1 [43520/60000 (72%)]\tLoss: -67839783784406109980163309568.000000\n', 'Train Epoch: 1 [44800/60000 (75%)]\tLoss: -70153346682227675084676399104.000000\n', 'Train Epoch: 1 [46080/60000 (77%)]\tLoss: -75930737061035227735564222464.000000\n', 'Train Epoch: 1 [47360/60000 (79%)]\tLoss: -75987410181196146347773788160.000000\n', 'Train Epoch: 1 [48640/60000 (81%)]\tLoss: -79972473585095353854255431680.000000\n', 'Train Epoch: 1 [49920/60000 (83%)]\tLoss: -82205406797588402636389875712.000000\n', 'Train Epoch: 1 [51200/60000 (85%)]\tLoss: -81573176372861814535180255232.000000\n', 'Train Epoch: 1 [52480/60000 (87%)]\tLoss: -84950518434080527399111360512.000000\n', 'Train Epoch: 1 [53760/60000 (90%)]\tLoss: -86005353435359120050494636032.000000\n', 'Train Epoch: 1 [55040/60000 (92%)]\tLoss: -86391973579311657904139927552.000000\n', 'Train Epoch: 1 [56320/60000 (94%)]\tLoss: -89176101407685251675616968704.000000\n', 'Train Epoch: 1 [57600/60000 (96%)]\tLoss: -94202814965642879784045248512.000000\n', 'Train Epoch: 1 [58880/60000 (98%)]\tLoss: -93616145932743018019857367040.000000\n', 'Train Epoch: 1 [0/60000 (0%)]\tLoss: -0.008910\n', 'Train Epoch: 1 [1280/60000 (2%)]\tLoss: -662935584112640.000000\n', 'Train Epoch: 1 [2560/60000 (4%)]\tLoss: -19676286435669560428331008.000000\n', 'Train Epoch: 1 [3840/60000 (6%)]\tLoss: -1095244291272508205476872192.000000\n', 'Train Epoch: 1 [5120/60000 (9%)]\tLoss: -3474372525342235464136916992.000000\n', 'Train Epoch: 1 [6400/60000 (11%)]\tLoss: -5751184196306677913480069120.000000\n', 'Train Epoch: 1 [7680/60000 (13%)]\tLoss: -8305369965600572561506172928.000000\n', 'Train Epoch: 1 [8960/60000 (15%)]\tLoss: -9977908211712825568010436608.000000\n', 'Train Epoch: 1 [10240/60000 (17%)]\tLoss: -12935364598882046079999672320.000000\n', 'Train Epoch: 1 [11520/60000 (19%)]\tLoss: -15150364624656397384435105792.000000\n', 'Train Epoch: 1 [12800/60000 (21%)]\tLoss: -17320961418983946132337459200.000000\n', 'Train Epoch: 1 [14080/60000 (23%)]\tLoss: -19430355163101883560859009024.000000\n', 'Train Epoch: 1 [15360/60000 (26%)]\tLoss: -21792365999262829073030709248.000000\n', 'Train Epoch: 1 [16640/60000 (28%)]\tLoss: -23534857840677450851496755200.000000\n', 'Train Epoch: 1 [17920/60000 (30%)]\tLoss: -26154765374609252710667517952.000000\n', 'Train Epoch: 1 [19200/60000 (32%)]\tLoss: -28041997748723829114933346304.000000\n', 'Train Epoch: 1 [20480/60000 (34%)]\tLoss: -30114242996904272479381356544.000000\n', 'Train Epoch: 1 [21760/60000 (36%)]\tLoss: -32162323895791871869270884352.000000\n', 'Train Epoch: 1 [23040/60000 (38%)]\tLoss: -34853914591750393507962945536.000000\n', 'Train Epoch: 1 [24320/60000 (41%)]\tLoss: -35723812276826845113487458304.000000\n', 'Train Epoch: 1 [25600/60000 (43%)]\tLoss: -39190144973231995006648057856.000000\n', 'Train Epoch: 1 [26880/60000 (45%)]\tLoss: -41216630490193431508975353856.000000\n', 'Train Epoch: 1 [28160/60000 (47%)]\tLoss: -42986927625459189758459641856.000000\n', 'Train Epoch: 1 [29440/60000 (49%)]\tLoss: -45920239733393118491882553344.000000\n', 'Train Epoch: 1 [30720/60000 (51%)]\tLoss: -47810277193198519465405317120.000000\n', 'Train Epoch: 1 [32000/60000 (53%)]\tLoss: -50814438965474941485969309696.000000\n', 'Train Epoch: 1 [33280/60000 (55%)]\tLoss: -51835523213500464783010299904.000000\n', 'Train Epoch: 1 [34560/60000 (58%)]\tLoss: -53928773547796712329368829952.000000\n', 'Train Epoch: 1 [35840/60000 (60%)]\tLoss: -57724862012150925243334000640.000000\n', 'Train Epoch: 1 [37120/60000 (62%)]\tLoss: -58913302205962865897103163392.000000\n', 'Train Epoch: 1 [38400/60000 (64%)]\tLoss: -59797976175764216622501330944.000000\n', 'Train Epoch: 1 [39680/60000 (66%)]\tLoss: -64172360917244163419690500096.000000\n', 'Train Epoch: 1 [40960/60000 (68%)]\tLoss: -65012517138211501999659155456.000000\n', 'Train Epoch: 1 [42240/60000 (70%)]\tLoss: -67307516413388906528837206016.000000\n', 'Train Epoch: 1 [43520/60000 (72%)]\tLoss: -69856224827858482747121074176.000000\n', 'Train Epoch: 1 [44800/60000 (75%)]\tLoss: -71051795795059556565162917888.000000\n', 'Train Epoch: 1 [46080/60000 (77%)]\tLoss: -72127508378558915918035943424.000000\n', 'Train Epoch: 1 [47360/60000 (79%)]\tLoss: -75335369429073920084892712960.000000\n', 'Train Epoch: 1 [48640/60000 (81%)]\tLoss: -78914450986440824192352911360.000000\n', 'Train Epoch: 1 [49920/60000 (83%)]\tLoss: -80551105150241371482289602560.000000\n', 'Train Epoch: 1 [51200/60000 (85%)]\tLoss: -81949879547200326133876785152.000000\n', 'Train Epoch: 1 [52480/60000 (87%)]\tLoss: -83234325451609006674840387584.000000\n', 'Train Epoch: 1 [53760/60000 (90%)]\tLoss: -86270533202838182107824521216.000000\n', 'Train Epoch: 1 [55040/60000 (92%)]\tLoss: -90498505693883238424808259584.000000\n', 'Train Epoch: 1 [56320/60000 (94%)]\tLoss: -88159442017054177236141211648.000000\n', 'Train Epoch: 1 [57600/60000 (96%)]\tLoss: -93945719889582490559321210880.000000\n', 'Train Epoch: 1 [58880/60000 (98%)]\tLoss: -95808070114698826802956075008.000000\n', '\n', 'Test set: Average loss: -97985828451466562502119129088.0000, Accuracy: 1135/10000 (11%)\n', '\n', '\n', 'Test set: Average loss: -97985823615763283058440011776.0000, Accuracy: 1135/10000 (11%)\n', '\n', '{"accuracy": 11.35, "runtime": 67.05662207491696, "mem_params": 244341408, "mem_bufs": 0, "mem_peak": 3343928832}\n']
[2021-12-11 15:45:19,645 DEBUG] Received error from gpu3: []
[2021-12-11 15:45:19,645 DEBUG] SSH connection with gpu3 has been closed
[2021-12-11 15:45:19,645 INFO] {'batch-size': 128, 'lr': 0.5, 'gamma': 0.5} => {"accuracy": 11.35, "runtime": 67.05662207491696, "mem_params": 244341408, "mem_bufs": 0, "mem_peak": 3343928832}
[2021-12-11 15:45:19,646 DEBUG] gpu3 finished training {'batch-size': 128, 'lr': 0.5, 'gamma': 0.5}
[2021-12-11 15:45:19,646 DEBUG] gpu3 now training {'batch-size': 128, 'lr': 0.9, 'gamma': 0.5}...
[2021-12-11 15:45:19,646 DEBUG] Attempting to establish SSH connection with gpu3...
[2021-12-11 15:45:19,740 DEBUG] SSH connection with gpu3 established successfully!
[2021-12-11 15:45:19,740 DEBUG] Running cmd on gpu3: source /u5/p3basta/CS848/CS848-Project/venv/bin/activate && python /u5/p3basta/CS848/CS848-Project/models/MNIST/train.py --arch "alexnet" --parallelism "dp" --epochs "1" --batch-size "128" --lr "0.9" --gamma "0.5"
[2021-12-11 15:45:19,740 INFO] Training {'batch-size': 128, 'lr': 0.9, 'gamma': 0.5} on gpu3...
[2021-12-11 15:45:20,984 DEBUG] Received output from gpu1: ['Train Epoch: 1 [0/60000 (0%)]\tLoss: 0.000884\n', 'Train Epoch: 1 [1280/60000 (2%)]\tLoss: -325978052100096.000000\n', 'Train Epoch: 1 [2560/60000 (4%)]\tLoss: -19166170551348737949564928.000000\n', 'Train Epoch: 1 [3840/60000 (6%)]\tLoss: -1072281120166767902081417216.000000\n', 'Train Epoch: 1 [5120/60000 (9%)]\tLoss: -3133991137658810562248704000.000000\n', 'Train Epoch: 1 [6400/60000 (11%)]\tLoss: -5279670660387402806533816320.000000\n', 'Train Epoch: 1 [7680/60000 (13%)]\tLoss: -7263216879511726342344278016.000000\n', 'Train Epoch: 1 [8960/60000 (15%)]\tLoss: -9036477299745485294200160256.000000\n', 'Train Epoch: 1 [10240/60000 (17%)]\tLoss: -11214861276403286087059898368.000000\n', 'Train Epoch: 1 [11520/60000 (19%)]\tLoss: -13290908029602439515904933888.000000\n', 'Train Epoch: 1 [12800/60000 (21%)]\tLoss: -15135901196710988378556858368.000000\n', 'Train Epoch: 1 [14080/60000 (23%)]\tLoss: -17792330332429683356399042560.000000\n', 'Train Epoch: 1 [15360/60000 (26%)]\tLoss: -19152907868091946882675245056.000000\n', 'Train Epoch: 1 [16640/60000 (28%)]\tLoss: -21522924296032977160895463424.000000\n', 'Train Epoch: 1 [17920/60000 (30%)]\tLoss: -22954360940770699713603174400.000000\n', 'Train Epoch: 1 [19200/60000 (32%)]\tLoss: -24880269496379978512169172992.000000\n', 'Train Epoch: 1 [20480/60000 (34%)]\tLoss: -27415653753818138026482597888.000000\n', 'Train Epoch: 1 [21760/60000 (36%)]\tLoss: -28610759567920649184470892544.000000\n', 'Train Epoch: 1 [23040/60000 (38%)]\tLoss: -30687901910143828371005505536.000000\n', 'Train Epoch: 1 [24320/60000 (41%)]\tLoss: -33066229703094709224801828864.000000\n', 'Train Epoch: 1 [25600/60000 (43%)]\tLoss: -35122447239432293013394554880.000000\n', 'Train Epoch: 1 [26880/60000 (45%)]\tLoss: -35365597167268768175802548224.000000\n', 'Train Epoch: 1 [28160/60000 (47%)]\tLoss: -37282188493807345164361924608.000000\n', 'Train Epoch: 1 [29440/60000 (49%)]\tLoss: -40928311126948308190098358272.000000\n', 'Train Epoch: 1 [30720/60000 (51%)]\tLoss: -42222725947002326552108072960.000000\n', 'Train Epoch: 1 [32000/60000 (53%)]\tLoss: -46209432734437572695124082688.000000\n', 'Train Epoch: 1 [33280/60000 (55%)]\tLoss: -47212312259671633509866274816.000000\n', 'Train Epoch: 1 [34560/60000 (58%)]\tLoss: -47016258492768817319174471680.000000\n', 'Train Epoch: 1 [35840/60000 (60%)]\tLoss: -49739836138099056499721502720.000000\n', 'Train Epoch: 1 [37120/60000 (62%)]\tLoss: -53193959155962746925182091264.000000\n', 'Train Epoch: 1 [38400/60000 (64%)]\tLoss: -54937933820452989772245237760.000000\n', 'Train Epoch: 1 [39680/60000 (66%)]\tLoss: -56648148286957197525675671552.000000\n', 'Train Epoch: 1 [40960/60000 (68%)]\tLoss: -58887773092756472595077922816.000000\n', 'Train Epoch: 1 [42240/60000 (70%)]\tLoss: -59950045821245584937672769536.000000\n', 'Train Epoch: 1 [43520/60000 (72%)]\tLoss: -61800783747180544723727155200.000000\n', 'Train Epoch: 1 [44800/60000 (75%)]\tLoss: -62224743642913132862077140992.000000\n', 'Train Epoch: 1 [46080/60000 (77%)]\tLoss: -65096291919617609505750122496.000000\n', 'Train Epoch: 1 [47360/60000 (79%)]\tLoss: -68767544625997163348491239424.000000\n', 'Train Epoch: 1 [48640/60000 (81%)]\tLoss: -69638495398799294884898406400.000000\n', 'Train Epoch: 1 [49920/60000 (83%)]\tLoss: -70372086697714197050974797824.000000\n', 'Train Epoch: 1 [51200/60000 (85%)]\tLoss: -72217601686319103009422835712.000000\n', 'Train Epoch: 1 [52480/60000 (87%)]\tLoss: -78303324817526180535603298304.000000\n', 'Train Epoch: 1 [53760/60000 (90%)]\tLoss: -80005549039941372849332158464.000000\n', 'Train Epoch: 1 [55040/60000 (92%)]\tLoss: -79886894859692790143692832768.000000\n', 'Train Epoch: 1 [56320/60000 (94%)]\tLoss: -79085674550376711788511100928.000000\n', 'Train Epoch: 1 [57600/60000 (96%)]\tLoss: -84240180067727275366067208192.000000\n', 'Train Epoch: 1 [58880/60000 (98%)]\tLoss: -84696370114705448833000669184.000000\n', 'Train Epoch: 1 [0/60000 (0%)]\tLoss: 0.001500\n', 'Train Epoch: 1 [1280/60000 (2%)]\tLoss: -318999837540352.000000\n', 'Train Epoch: 1 [2560/60000 (4%)]\tLoss: -19249178593837421718142976.000000\n', 'Train Epoch: 1 [3840/60000 (6%)]\tLoss: -1088760629665480772274880512.000000\n', 'Train Epoch: 1 [5120/60000 (9%)]\tLoss: -3230955193503667808068698112.000000\n', 'Train Epoch: 1 [6400/60000 (11%)]\tLoss: -5126668347525667736432672768.000000\n', 'Train Epoch: 1 [7680/60000 (13%)]\tLoss: -7198274895639302981365530624.000000\n', 'Train Epoch: 1 [8960/60000 (15%)]\tLoss: -9192033822578642483656261632.000000\n', 'Train Epoch: 1 [10240/60000 (17%)]\tLoss: -11448774255399268223429902336.000000\n', 'Train Epoch: 1 [11520/60000 (19%)]\tLoss: -13383153555887194448097968128.000000\n', 'Train Epoch: 1 [12800/60000 (21%)]\tLoss: -15119102558539800333120438272.000000\n', 'Train Epoch: 1 [14080/60000 (23%)]\tLoss: -17207951647274013370139803648.000000\n', 'Train Epoch: 1 [15360/60000 (26%)]\tLoss: -18852031732368873177175031808.000000\n', 'Train Epoch: 1 [16640/60000 (28%)]\tLoss: -20729583255193566808752783360.000000\n', 'Train Epoch: 1 [17920/60000 (30%)]\tLoss: -22828649183813468323191980032.000000\n', 'Train Epoch: 1 [19200/60000 (32%)]\tLoss: -24935218952774649703875739648.000000\n', 'Train Epoch: 1 [20480/60000 (34%)]\tLoss: -27637090240566378560198017024.000000\n', 'Train Epoch: 1 [21760/60000 (36%)]\tLoss: -28447991401172339688067825664.000000\n', 'Train Epoch: 1 [23040/60000 (38%)]\tLoss: -30706472616337713250808365056.000000\n', 'Train Epoch: 1 [24320/60000 (41%)]\tLoss: -33666215809476263388492333056.000000\n', 'Train Epoch: 1 [25600/60000 (43%)]\tLoss: -34875344690849655957942697984.000000\n', 'Train Epoch: 1 [26880/60000 (45%)]\tLoss: -37624009908120140128687489024.000000\n', 'Train Epoch: 1 [28160/60000 (47%)]\tLoss: -40408671363906298170073677824.000000\n', 'Train Epoch: 1 [29440/60000 (49%)]\tLoss: -41404769570870958174289002496.000000\n', 'Train Epoch: 1 [30720/60000 (51%)]\tLoss: -42935836342481023066892664832.000000\n', 'Train Epoch: 1 [32000/60000 (53%)]\tLoss: -45256808633314210644746043392.000000\n', 'Train Epoch: 1 [33280/60000 (55%)]\tLoss: -47656313878757520422503186432.000000\n', 'Train Epoch: 1 [34560/60000 (58%)]\tLoss: -48175505016983657826232565760.000000\n', 'Train Epoch: 1 [35840/60000 (60%)]\tLoss: -51148390556044034186546249728.000000\n', 'Train Epoch: 1 [37120/60000 (62%)]\tLoss: -51639058600713638933184905216.000000\n', 'Train Epoch: 1 [38400/60000 (64%)]\tLoss: -54787120324456064782700642304.000000\n', 'Train Epoch: 1 [39680/60000 (66%)]\tLoss: -58301585741237863534701838336.000000\n', 'Train Epoch: 1 [40960/60000 (68%)]\tLoss: -57026896245982791680749731840.000000\n', 'Train Epoch: 1 [42240/60000 (70%)]\tLoss: -58653378432379237754896121856.000000\n', 'Train Epoch: 1 [43520/60000 (72%)]\tLoss: -60007554800273971477085159424.000000\n', 'Train Epoch: 1 [44800/60000 (75%)]\tLoss: -63784786855262085897712041984.000000\n', 'Train Epoch: 1 [46080/60000 (77%)]\tLoss: -63722938021435942154348265472.000000\n', 'Train Epoch: 1 [47360/60000 (79%)]\tLoss: -67120959325483141194670145536.000000\n', 'Train Epoch: 1 [48640/60000 (81%)]\tLoss: -68593048462088647088199958528.000000\n', 'Train Epoch: 1 [49920/60000 (83%)]\tLoss: -71724610237339926397339041792.000000\n', 'Train Epoch: 1 [51200/60000 (85%)]\tLoss: -74785312903515746680046616576.000000\n', 'Train Epoch: 1 [52480/60000 (87%)]\tLoss: -75499353605191568514938306560.000000\n', 'Train Epoch: 1 [53760/60000 (90%)]\tLoss: -77315844929392757633902968832.000000\n', 'Train Epoch: 1 [55040/60000 (92%)]\tLoss: -79987726828835022808295669760.000000\n', 'Train Epoch: 1 [56320/60000 (94%)]\tLoss: -80857888966434515113952149504.000000\n', 'Train Epoch: 1 [57600/60000 (96%)]\tLoss: -83318185235611805834545201152.000000\n', 'Train Epoch: 1 [58880/60000 (98%)]\tLoss: -82291070525587658000566321152.000000\n', '\n', 'Test set: Average loss: -87014171884239903286559244288.0000, Accuracy: 892/10000 (9%)\n', '\n', '\n', 'Test set: Average loss: -87014168982817939138788982784.0000, Accuracy: 892/10000 (9%)\n', '\n', '{"accuracy": 8.92, "runtime": 66.27351069729775, "mem_params": 244341408, "mem_bufs": 0, "mem_peak": 3343928832}\n']
[2021-12-11 15:45:20,984 DEBUG] Received error from gpu1: []
[2021-12-11 15:45:20,985 DEBUG] SSH connection with gpu1 has been closed
[2021-12-11 15:45:20,985 INFO] {'batch-size': 128, 'lr': 0.5, 'gamma': 0.7} => {"accuracy": 8.92, "runtime": 66.27351069729775, "mem_params": 244341408, "mem_bufs": 0, "mem_peak": 3343928832}
[2021-12-11 15:45:20,985 DEBUG] gpu1 finished training {'batch-size': 128, 'lr': 0.5, 'gamma': 0.7}
[2021-12-11 15:45:20,986 DEBUG] gpu1 now training {'batch-size': 128, 'lr': 0.9, 'gamma': 0.7}...
[2021-12-11 15:45:20,986 DEBUG] Attempting to establish SSH connection with gpu1...
[2021-12-11 15:45:21,094 DEBUG] SSH connection with gpu1 established successfully!
[2021-12-11 15:45:21,094 DEBUG] Running cmd on gpu1: source /u5/p3basta/CS848/CS848-Project/venv/bin/activate && python /u5/p3basta/CS848/CS848-Project/models/MNIST/train.py --arch "alexnet" --parallelism "dp" --epochs "1" --batch-size "128" --lr "0.9" --gamma "0.7"
[2021-12-11 15:45:21,094 INFO] Training {'batch-size': 128, 'lr': 0.9, 'gamma': 0.7} on gpu1...
[2021-12-11 15:45:23,897 DEBUG] Received output from gpu2: ['Train Epoch: 1 [0/60000 (0%)]\tLoss: -0.003186\n', 'Train Epoch: 1 [1280/60000 (2%)]\tLoss: -218892471369728.000000\n', 'Train Epoch: 1 [2560/60000 (4%)]\tLoss: -16862085747429569439203328.000000\n', 'Train Epoch: 1 [3840/60000 (6%)]\tLoss: -1055235664559873622844375040.000000\n', 'Train Epoch: 1 [5120/60000 (9%)]\tLoss: -3252435172598905568676020224.000000\n', 'Train Epoch: 1 [6400/60000 (11%)]\tLoss: -5350012080037177248108773376.000000\n', 'Train Epoch: 1 [7680/60000 (13%)]\tLoss: -7930174997057527455749767168.000000\n', 'Train Epoch: 1 [8960/60000 (15%)]\tLoss: -9494416393209751605979643904.000000\n', 'Train Epoch: 1 [10240/60000 (17%)]\tLoss: -12088549841173861300279705600.000000\n', 'Train Epoch: 1 [11520/60000 (19%)]\tLoss: -14657119348478766528921075712.000000\n', 'Train Epoch: 1 [12800/60000 (21%)]\tLoss: -15945522596000091832573755392.000000\n', 'Train Epoch: 1 [14080/60000 (23%)]\tLoss: -18547872371348584350839996416.000000\n', 'Train Epoch: 1 [15360/60000 (26%)]\tLoss: -21360819621775510849644920832.000000\n', 'Train Epoch: 1 [16640/60000 (28%)]\tLoss: -22477335812870105371986886656.000000\n', 'Train Epoch: 1 [17920/60000 (30%)]\tLoss: -23664304989522632131271983104.000000\n', 'Train Epoch: 1 [19200/60000 (32%)]\tLoss: -26592472079173474386234572800.000000\n', 'Train Epoch: 1 [20480/60000 (34%)]\tLoss: -29240352550966554588828663808.000000\n', 'Train Epoch: 1 [21760/60000 (36%)]\tLoss: -30300098813387331671234183168.000000\n', 'Train Epoch: 1 [23040/60000 (38%)]\tLoss: -33404311003153071430118146048.000000\n', 'Train Epoch: 1 [24320/60000 (41%)]\tLoss: -34854608779623375345809358848.000000\n', 'Train Epoch: 1 [25600/60000 (43%)]\tLoss: -37453513588622614457892208640.000000\n', 'Train Epoch: 1 [26880/60000 (45%)]\tLoss: -38706730483480078035057639424.000000\n', 'Train Epoch: 1 [28160/60000 (47%)]\tLoss: -40566799805585188240054288384.000000\n', 'Train Epoch: 1 [29440/60000 (49%)]\tLoss: -43284526438843151930181550080.000000\n', 'Train Epoch: 1 [30720/60000 (51%)]\tLoss: -45335502148384750412587073536.000000\n', 'Train Epoch: 1 [32000/60000 (53%)]\tLoss: -46548309753248298435658907648.000000\n', 'Train Epoch: 1 [33280/60000 (55%)]\tLoss: -50505175906878291290569572352.000000\n', 'Train Epoch: 1 [34560/60000 (58%)]\tLoss: -50488794017549216491323260928.000000\n', 'Train Epoch: 1 [35840/60000 (60%)]\tLoss: -53656382726698308323797630976.000000\n', 'Train Epoch: 1 [37120/60000 (62%)]\tLoss: -56239913871612565305887293440.000000\n', 'Train Epoch: 1 [38400/60000 (64%)]\tLoss: -58190402344765180607790579712.000000\n', 'Train Epoch: 1 [39680/60000 (66%)]\tLoss: -60207887031210267566340571136.000000\n', 'Train Epoch: 1 [40960/60000 (68%)]\tLoss: -63709040096876856788484358144.000000\n', 'Train Epoch: 1 [42240/60000 (70%)]\tLoss: -65451357210731612390077497344.000000\n', 'Train Epoch: 1 [43520/60000 (72%)]\tLoss: -68457280425706144788306198528.000000\n', 'Train Epoch: 1 [44800/60000 (75%)]\tLoss: -67046638721775738718296997888.000000\n', 'Train Epoch: 1 [46080/60000 (77%)]\tLoss: -72129472883015789690444840960.000000\n', 'Train Epoch: 1 [47360/60000 (79%)]\tLoss: -71454231144363224860628877312.000000\n', 'Train Epoch: 1 [48640/60000 (81%)]\tLoss: -73409857552249202336524664832.000000\n', 'Train Epoch: 1 [49920/60000 (83%)]\tLoss: -74121777911374215700715405312.000000\n', 'Train Epoch: 1 [51200/60000 (85%)]\tLoss: -74396369355253636960956186624.000000\n', 'Train Epoch: 1 [52480/60000 (87%)]\tLoss: -80783625031124907073321566208.000000\n', 'Train Epoch: 1 [53760/60000 (90%)]\tLoss: -83570775174047537417735372800.000000\n', 'Train Epoch: 1 [55040/60000 (92%)]\tLoss: -81891265534414948097484390400.000000\n', 'Train Epoch: 1 [56320/60000 (94%)]\tLoss: -87774635261831061326257979392.000000\n', 'Train Epoch: 1 [57600/60000 (96%)]\tLoss: -84040386186570026416366157824.000000\n', 'Train Epoch: 1 [58880/60000 (98%)]\tLoss: -89103093621860086960613228544.000000\n', 'Train Epoch: 1 [0/60000 (0%)]\tLoss: -0.002817\n', 'Train Epoch: 1 [1280/60000 (2%)]\tLoss: -212024701222912.000000\n', 'Train Epoch: 1 [2560/60000 (4%)]\tLoss: -16800546256278169768165376.000000\n', 'Train Epoch: 1 [3840/60000 (6%)]\tLoss: -1079420600419103857262460928.000000\n', 'Train Epoch: 1 [5120/60000 (9%)]\tLoss: -3363308663771150175120130048.000000\n', 'Train Epoch: 1 [6400/60000 (11%)]\tLoss: -5582230910057429899258363904.000000\n', 'Train Epoch: 1 [7680/60000 (13%)]\tLoss: -7439340488969401554117328896.000000\n', 'Train Epoch: 1 [8960/60000 (15%)]\tLoss: -9752561015220958609352425472.000000\n', 'Train Epoch: 1 [10240/60000 (17%)]\tLoss: -11850000678883321889721155584.000000\n', 'Train Epoch: 1 [11520/60000 (19%)]\tLoss: -14447938583345193441946501120.000000\n', 'Train Epoch: 1 [12800/60000 (21%)]\tLoss: -16465816406799979298460532736.000000\n', 'Train Epoch: 1 [14080/60000 (23%)]\tLoss: -18315771600490403440820748288.000000\n', 'Train Epoch: 1 [15360/60000 (26%)]\tLoss: -20408389137677946454720643072.000000\n', 'Train Epoch: 1 [16640/60000 (28%)]\tLoss: -22251509886476037503045337088.000000\n', 'Train Epoch: 1 [17920/60000 (30%)]\tLoss: -24006213767615360184034000896.000000\n', 'Train Epoch: 1 [19200/60000 (32%)]\tLoss: -27099715630197951587573301248.000000\n', 'Train Epoch: 1 [20480/60000 (34%)]\tLoss: -29695482426669323820411650048.000000\n', 'Train Epoch: 1 [21760/60000 (36%)]\tLoss: -30624574975608546428689842176.000000\n', 'Train Epoch: 1 [23040/60000 (38%)]\tLoss: -32765169395078803603138281472.000000\n', 'Train Epoch: 1 [24320/60000 (41%)]\tLoss: -35300999916149594298924400640.000000\n', 'Train Epoch: 1 [25600/60000 (43%)]\tLoss: -37918798913446794861507248128.000000\n', 'Train Epoch: 1 [26880/60000 (45%)]\tLoss: -39290433870228697662051319808.000000\n', 'Train Epoch: 1 [28160/60000 (47%)]\tLoss: -41346386954043240750512078848.000000\n', 'Train Epoch: 1 [29440/60000 (49%)]\tLoss: -42956185019655708368118480896.000000\n', 'Train Epoch: 1 [30720/60000 (51%)]\tLoss: -45319908894258314844091449344.000000\n', 'Train Epoch: 1 [32000/60000 (53%)]\tLoss: -47926593802038081696663863296.000000\n', 'Train Epoch: 1 [33280/60000 (55%)]\tLoss: -50833186760411933977467682816.000000\n', 'Train Epoch: 1 [34560/60000 (58%)]\tLoss: -50892221063814287412284096512.000000\n', 'Train Epoch: 1 [35840/60000 (60%)]\tLoss: -54088998720193996521824321536.000000\n', 'Train Epoch: 1 [37120/60000 (62%)]\tLoss: -55063038753317172413246472192.000000\n', 'Train Epoch: 1 [38400/60000 (64%)]\tLoss: -55947986620374529578067034112.000000\n', 'Train Epoch: 1 [39680/60000 (66%)]\tLoss: -60440789423778915598634844160.000000\n', 'Train Epoch: 1 [40960/60000 (68%)]\tLoss: -61753782033576543144915238912.000000\n', 'Train Epoch: 1 [42240/60000 (70%)]\tLoss: -61894688004692407618801500160.000000\n', 'Train Epoch: 1 [43520/60000 (72%)]\tLoss: -65394957987826700217290326016.000000\n', 'Train Epoch: 1 [44800/60000 (75%)]\tLoss: -66372577574743891299784458240.000000\n', 'Train Epoch: 1 [46080/60000 (77%)]\tLoss: -68764597869311852689877893120.000000\n', 'Train Epoch: 1 [47360/60000 (79%)]\tLoss: -69883586219260229471489228800.000000\n', 'Train Epoch: 1 [48640/60000 (81%)]\tLoss: -74188963019326002143170658304.000000\n', 'Train Epoch: 1 [49920/60000 (83%)]\tLoss: -75096998536118109003440979968.000000\n', 'Train Epoch: 1 [51200/60000 (85%)]\tLoss: -78500733903609580314471432192.000000\n', 'Train Epoch: 1 [52480/60000 (87%)]\tLoss: -77751502126903413883447279616.000000\n', 'Train Epoch: 1 [53760/60000 (90%)]\tLoss: -80200025536438910578522587136.000000\n', 'Train Epoch: 1 [55040/60000 (92%)]\tLoss: -87334463481962781695889375232.000000\n', 'Train Epoch: 1 [56320/60000 (94%)]\tLoss: -88240421157502425912265670656.000000\n', 'Train Epoch: 1 [57600/60000 (96%)]\tLoss: -88957701402585496323773956096.000000\n', 'Train Epoch: 1 [58880/60000 (98%)]\tLoss: -89396494251440778017740161024.000000\n', '\n', 'Test set: Average loss: -91817325076790450391336615936.0000, Accuracy: 1009/10000 (10%)\n', '\n', '\n', 'Test set: Average loss: -91817330879634396279063183360.0000, Accuracy: 1009/10000 (10%)\n', '\n', '{"accuracy": 10.09, "runtime": 67.47841753996909, "mem_params": 244341408, "mem_bufs": 0, "mem_peak": 3343928832}\n']
[2021-12-11 15:45:23,898 DEBUG] Received error from gpu2: []
[2021-12-11 15:45:23,898 DEBUG] SSH connection with gpu2 has been closed
[2021-12-11 15:45:23,898 INFO] {'batch-size': 128, 'lr': 0.5, 'gamma': 0.9} => {"accuracy": 10.09, "runtime": 67.47841753996909, "mem_params": 244341408, "mem_bufs": 0, "mem_peak": 3343928832}
[2021-12-11 15:45:23,899 DEBUG] gpu2 finished training {'batch-size': 128, 'lr': 0.5, 'gamma': 0.9}
[2021-12-11 15:45:23,899 DEBUG] gpu2 now training {'batch-size': 128, 'lr': 0.9, 'gamma': 0.9}...
[2021-12-11 15:45:23,899 DEBUG] Attempting to establish SSH connection with gpu2...
[2021-12-11 15:45:23,999 DEBUG] SSH connection with gpu2 established successfully!
[2021-12-11 15:45:23,999 DEBUG] Running cmd on gpu2: source /u5/p3basta/CS848/CS848-Project/venv/bin/activate && python /u5/p3basta/CS848/CS848-Project/models/MNIST/train.py --arch "alexnet" --parallelism "dp" --epochs "1" --batch-size "128" --lr "0.9" --gamma "0.9"
[2021-12-11 15:45:23,999 INFO] Training {'batch-size': 128, 'lr': 0.9, 'gamma': 0.9} on gpu2...
[2021-12-11 15:46:27,814 DEBUG] Received output from gpu3: ['Train Epoch: 1 [0/60000 (0%)]\tLoss: 0.004627\n', 'Train Epoch: 1 [1280/60000 (2%)]\tLoss: -75441701849661440.000000\n', 'Train Epoch: 1 [2560/60000 (4%)]\tLoss: -65486587097711488071106560.000000\n', 'Train Epoch: 1 [3840/60000 (6%)]\tLoss: -1837336735300291270996393984.000000\n', 'Train Epoch: 1 [5120/60000 (9%)]\tLoss: -4421300271895636004975935488.000000\n', 'Train Epoch: 1 [6400/60000 (11%)]\tLoss: -7032142042771948862747705344.000000\n', 'Train Epoch: 1 [7680/60000 (13%)]\tLoss: -9308157994984027776872349696.000000\n', 'Train Epoch: 1 [8960/60000 (15%)]\tLoss: -12177359845842328565579776000.000000\n', 'Train Epoch: 1 [10240/60000 (17%)]\tLoss: -14439171509969745945607274496.000000\n', 'Train Epoch: 1 [11520/60000 (19%)]\tLoss: -16772898912673164435182845952.000000\n', 'Train Epoch: 1 [12800/60000 (21%)]\tLoss: -19148577458027155418014285824.000000\n', 'Train Epoch: 1 [14080/60000 (23%)]\tLoss: -21373527509980913064914976768.000000\n', 'Train Epoch: 1 [15360/60000 (26%)]\tLoss: -24305680276943297300437925888.000000\n', 'Train Epoch: 1 [16640/60000 (28%)]\tLoss: -26585490060328551615786123264.000000\n', 'Train Epoch: 1 [17920/60000 (30%)]\tLoss: -28843014996281144075370889216.000000\n', 'Train Epoch: 1 [19200/60000 (32%)]\tLoss: -31783845111655801283974004736.000000\n', 'Train Epoch: 1 [20480/60000 (34%)]\tLoss: -33246215618039561447654031360.000000\n', 'Train Epoch: 1 [21760/60000 (36%)]\tLoss: -36708288739877162920831877120.000000\n', 'Train Epoch: 1 [23040/60000 (38%)]\tLoss: -38238283534295616403972030464.000000\n', 'Train Epoch: 1 [24320/60000 (41%)]\tLoss: -40206960201957004144415866880.000000\n', 'Train Epoch: 1 [25600/60000 (43%)]\tLoss: -43925488519196566005391294464.000000\n', 'Train Epoch: 1 [26880/60000 (45%)]\tLoss: -45812635890714450756043276288.000000\n', 'Train Epoch: 1 [28160/60000 (47%)]\tLoss: -46528669431046043581215145984.000000\n', 'Train Epoch: 1 [29440/60000 (49%)]\tLoss: -48600036319060673191653408768.000000\n', 'Train Epoch: 1 [30720/60000 (51%)]\tLoss: -51681961300210509659951333376.000000\n', 'Train Epoch: 1 [32000/60000 (53%)]\tLoss: -55945436542473779969651638272.000000\n', 'Train Epoch: 1 [33280/60000 (55%)]\tLoss: -57601721583743616374741663744.000000\n', 'Train Epoch: 1 [34560/60000 (58%)]\tLoss: -59546836003838726020391763968.000000\n', 'Train Epoch: 1 [35840/60000 (60%)]\tLoss: -62853271732317151161439223808.000000\n', 'Train Epoch: 1 [37120/60000 (62%)]\tLoss: -63477998316702459396404281344.000000\n', 'Train Epoch: 1 [38400/60000 (64%)]\tLoss: -64993717397243197942063431680.000000\n', 'Train Epoch: 1 [39680/60000 (66%)]\tLoss: -67739117098090777753142951936.000000\n', 'Train Epoch: 1 [40960/60000 (68%)]\tLoss: -70924263565823178926521843712.000000\n', 'Train Epoch: 1 [42240/60000 (70%)]\tLoss: -73177828797479885188594925568.000000\n', 'Train Epoch: 1 [43520/60000 (72%)]\tLoss: -74534729970835234696072265728.000000\n', 'Train Epoch: 1 [44800/60000 (75%)]\tLoss: -77817237468344959344821927936.000000\n', 'Train Epoch: 1 [46080/60000 (77%)]\tLoss: -81323646527906982482088558592.000000\n', 'Train Epoch: 1 [47360/60000 (79%)]\tLoss: -83359033705688628265643671552.000000\n', 'Train Epoch: 1 [48640/60000 (81%)]\tLoss: -82920448640958592836066869248.000000\n', 'Train Epoch: 1 [49920/60000 (83%)]\tLoss: -87391245216552806309938855936.000000\n', 'Train Epoch: 1 [51200/60000 (85%)]\tLoss: -89749736709092393219015049216.000000\n', 'Train Epoch: 1 [52480/60000 (87%)]\tLoss: -92515976213228876774422609920.000000\n', 'Train Epoch: 1 [53760/60000 (90%)]\tLoss: -93298406226309616811299045376.000000\n', 'Train Epoch: 1 [55040/60000 (92%)]\tLoss: -92898280114216071772342583296.000000\n', 'Train Epoch: 1 [56320/60000 (94%)]\tLoss: -97462041196392057081891389440.000000\n', 'Train Epoch: 1 [57600/60000 (96%)]\tLoss: -100302100733388758931279446016.000000\n', 'Train Epoch: 1 [58880/60000 (98%)]\tLoss: -101626252295185407449199804416.000000\n', 'Train Epoch: 1 [0/60000 (0%)]\tLoss: 0.006545\n', 'Train Epoch: 1 [1280/60000 (2%)]\tLoss: -79796068543365120.000000\n', 'Train Epoch: 1 [2560/60000 (4%)]\tLoss: -63713075617290885932253184.000000\n', 'Train Epoch: 1 [3840/60000 (6%)]\tLoss: -1871138549140956653377552384.000000\n', 'Train Epoch: 1 [5120/60000 (9%)]\tLoss: -4532080201181938756574248960.000000\n', 'Train Epoch: 1 [6400/60000 (11%)]\tLoss: -6867838516620896372944535552.000000\n', 'Train Epoch: 1 [7680/60000 (13%)]\tLoss: -9320428473993954191254487040.000000\n', 'Train Epoch: 1 [8960/60000 (15%)]\tLoss: -11983609413191532044340953088.000000\n', 'Train Epoch: 1 [10240/60000 (17%)]\tLoss: -13816660896056524291658743808.000000\n', 'Train Epoch: 1 [11520/60000 (19%)]\tLoss: -16667312701074302755261120512.000000\n', 'Train Epoch: 1 [12800/60000 (21%)]\tLoss: -18458596032989933708075073536.000000\n', 'Train Epoch: 1 [14080/60000 (23%)]\tLoss: -21994369947934061016691769344.000000\n', 'Train Epoch: 1 [15360/60000 (26%)]\tLoss: -24839957014898961785802457088.000000\n', 'Train Epoch: 1 [16640/60000 (28%)]\tLoss: -26391398436699367762680610816.000000\n', 'Train Epoch: 1 [17920/60000 (30%)]\tLoss: -29634769321982310226721767424.000000\n', 'Train Epoch: 1 [19200/60000 (32%)]\tLoss: -31604527411568275115919540224.000000\n', 'Train Epoch: 1 [20480/60000 (34%)]\tLoss: -33272488503967006718800429056.000000\n', 'Train Epoch: 1 [21760/60000 (36%)]\tLoss: -35703657216677957467715403776.000000\n', 'Train Epoch: 1 [23040/60000 (38%)]\tLoss: -38555954766415016002674753536.000000\n', 'Train Epoch: 1 [24320/60000 (41%)]\tLoss: -40682847239535226901535653888.000000\n', 'Train Epoch: 1 [25600/60000 (43%)]\tLoss: -42091892783594423031462625280.000000\n', 'Train Epoch: 1 [26880/60000 (45%)]\tLoss: -45698619074352046042003800064.000000\n', 'Train Epoch: 1 [28160/60000 (47%)]\tLoss: -48559900926322764076982206464.000000\n', 'Train Epoch: 1 [29440/60000 (49%)]\tLoss: -50588827906755844185884983296.000000\n', 'Train Epoch: 1 [30720/60000 (51%)]\tLoss: -53297303424073866241038614528.000000\n', 'Train Epoch: 1 [32000/60000 (53%)]\tLoss: -55195671138355049268718338048.000000\n', 'Train Epoch: 1 [33280/60000 (55%)]\tLoss: -58633492547119873678901248000.000000\n', 'Train Epoch: 1 [34560/60000 (58%)]\tLoss: -59291247362686372212490895360.000000\n', 'Train Epoch: 1 [35840/60000 (60%)]\tLoss: -61941198592182190754511192064.000000\n', 'Train Epoch: 1 [37120/60000 (62%)]\tLoss: -64244178666715644984100388864.000000\n', 'Train Epoch: 1 [38400/60000 (64%)]\tLoss: -66544533105484623690950770688.000000\n', 'Train Epoch: 1 [39680/60000 (66%)]\tLoss: -67002290978135109880095178752.000000\n', 'Train Epoch: 1 [40960/60000 (68%)]\tLoss: -70112290428025606389188526080.000000\n', 'Train Epoch: 1 [42240/60000 (70%)]\tLoss: -74181827523570386109252763648.000000\n', 'Train Epoch: 1 [43520/60000 (72%)]\tLoss: -76443014654730443978700750848.000000\n', 'Train Epoch: 1 [44800/60000 (75%)]\tLoss: -78827318602465396368515006464.000000\n', 'Train Epoch: 1 [46080/60000 (77%)]\tLoss: -80097059057646420834283159552.000000\n', 'Train Epoch: 1 [47360/60000 (79%)]\tLoss: -84299105756700522799043706880.000000\n', 'Train Epoch: 1 [48640/60000 (81%)]\tLoss: -83003552846324132852537491456.000000\n', 'Train Epoch: 1 [49920/60000 (83%)]\tLoss: -84423086766341782464484081664.000000\n', 'Train Epoch: 1 [51200/60000 (85%)]\tLoss: -91180594863935964240184082432.000000\n', 'Train Epoch: 1 [52480/60000 (87%)]\tLoss: -90756044672393017396182384640.000000\n', 'Train Epoch: 1 [53760/60000 (90%)]\tLoss: -93920143552711268560843833344.000000\n', 'Train Epoch: 1 [55040/60000 (92%)]\tLoss: -94475389959034115705779781632.000000\n', 'Train Epoch: 1 [56320/60000 (94%)]\tLoss: -97644447324159379997915611136.000000\n', 'Train Epoch: 1 [57600/60000 (96%)]\tLoss: -99952796729383857014112780288.000000\n', 'Train Epoch: 1 [58880/60000 (98%)]\tLoss: -102335759525037674424686346240.000000\n', '\n', 'Test set: Average loss: -105653919196996925005995442176.0000, Accuracy: 982/10000 (10%)\n', '\n', '\n', 'Test set: Average loss: -105653911459871663822360018944.0000, Accuracy: 982/10000 (10%)\n', '\n', '{"accuracy": 9.82, "runtime": 66.58223777450621, "mem_params": 244341408, "mem_bufs": 0, "mem_peak": 3343928832}\n']
[2021-12-11 15:46:27,814 DEBUG] Received error from gpu3: []
[2021-12-11 15:46:27,815 DEBUG] SSH connection with gpu3 has been closed
[2021-12-11 15:46:27,815 INFO] {'batch-size': 128, 'lr': 0.9, 'gamma': 0.5} => {"accuracy": 9.82, "runtime": 66.58223777450621, "mem_params": 244341408, "mem_bufs": 0, "mem_peak": 3343928832}
[2021-12-11 15:46:27,815 DEBUG] gpu3 finished training {'batch-size': 128, 'lr': 0.9, 'gamma': 0.5}
[2021-12-11 15:46:27,816 DEBUG] gpu3 now training {'batch-size': 128, 'lr': 0.99, 'gamma': 0.5}...
[2021-12-11 15:46:27,816 DEBUG] Attempting to establish SSH connection with gpu3...
[2021-12-11 15:46:27,909 DEBUG] SSH connection with gpu3 established successfully!
[2021-12-11 15:46:27,910 DEBUG] Running cmd on gpu3: source /u5/p3basta/CS848/CS848-Project/venv/bin/activate && python /u5/p3basta/CS848/CS848-Project/models/MNIST/train.py --arch "alexnet" --parallelism "dp" --epochs "1" --batch-size "128" --lr "0.99" --gamma "0.5"
[2021-12-11 15:46:27,910 INFO] Training {'batch-size': 128, 'lr': 0.99, 'gamma': 0.5} on gpu3...
[2021-12-11 15:46:31,072 DEBUG] Received output from gpu1: ['Train Epoch: 1 [0/60000 (0%)]\tLoss: 0.002670\n', 'Train Epoch: 1 [1280/60000 (2%)]\tLoss: -218735623459045376.000000\n', 'Train Epoch: 1 [2560/60000 (4%)]\tLoss: -55422163434932035821502464.000000\n', 'Train Epoch: 1 [3840/60000 (6%)]\tLoss: -1594875387526599538731122688.000000\n', 'Train Epoch: 1 [5120/60000 (9%)]\tLoss: -4529373399743538911808323584.000000\n', 'Train Epoch: 1 [6400/60000 (11%)]\tLoss: -7136313905609191083927928832.000000\n', 'Train Epoch: 1 [7680/60000 (13%)]\tLoss: -9734622515839967903302549504.000000\n', 'Train Epoch: 1 [8960/60000 (15%)]\tLoss: -13158801007835781908463091712.000000\n', 'Train Epoch: 1 [10240/60000 (17%)]\tLoss: -15565693215049920528745758720.000000\n', 'Train Epoch: 1 [11520/60000 (19%)]\tLoss: -18873073416824919598835957760.000000\n', 'Train Epoch: 1 [12800/60000 (21%)]\tLoss: -21450546946133275543527751680.000000\n', 'Train Epoch: 1 [14080/60000 (23%)]\tLoss: -24077342051580342780242690048.000000\n', 'Train Epoch: 1 [15360/60000 (26%)]\tLoss: -26670086533502678440144273408.000000\n', 'Train Epoch: 1 [16640/60000 (28%)]\tLoss: -30451585246608065585221730304.000000\n', 'Train Epoch: 1 [17920/60000 (30%)]\tLoss: -32229168993356891697270751232.000000\n', 'Train Epoch: 1 [19200/60000 (32%)]\tLoss: -33804673233570759951335292928.000000\n', 'Train Epoch: 1 [20480/60000 (34%)]\tLoss: -36735260536044072899469901824.000000\n', 'Train Epoch: 1 [21760/60000 (36%)]\tLoss: -40369097932779850543182905344.000000\n', 'Train Epoch: 1 [23040/60000 (38%)]\tLoss: -42702773389451957466661126144.000000\n', 'Train Epoch: 1 [24320/60000 (41%)]\tLoss: -46404688421404783915774771200.000000\n', 'Train Epoch: 1 [25600/60000 (43%)]\tLoss: -48817713802088549487778725888.000000\n', 'Train Epoch: 1 [26880/60000 (45%)]\tLoss: -50563294071182968014214529024.000000\n', 'Train Epoch: 1 [28160/60000 (47%)]\tLoss: -53097457596885305725240213504.000000\n', 'Train Epoch: 1 [29440/60000 (49%)]\tLoss: -55922920299083457501272735744.000000\n', 'Train Epoch: 1 [30720/60000 (51%)]\tLoss: -58478362808157605833631334400.000000\n', 'Train Epoch: 1 [32000/60000 (53%)]\tLoss: -61884837148209141538885730304.000000\n', 'Train Epoch: 1 [33280/60000 (55%)]\tLoss: -66340144361739542576456794112.000000\n', 'Train Epoch: 1 [34560/60000 (58%)]\tLoss: -67043677797990979450748010496.000000\n', 'Train Epoch: 1 [35840/60000 (60%)]\tLoss: -70891962579080350553260163072.000000\n', 'Train Epoch: 1 [37120/60000 (62%)]\tLoss: -71525128032370546844222095360.000000\n', 'Train Epoch: 1 [38400/60000 (64%)]\tLoss: -75565995640997824948193984512.000000\n', 'Train Epoch: 1 [39680/60000 (66%)]\tLoss: -77085624840986379560090075136.000000\n', 'Train Epoch: 1 [40960/60000 (68%)]\tLoss: -80148277844519625006270906368.000000\n', 'Train Epoch: 1 [42240/60000 (70%)]\tLoss: -82699432444827327700775469056.000000\n', 'Train Epoch: 1 [43520/60000 (72%)]\tLoss: -83670492664699812846067777536.000000\n', 'Train Epoch: 1 [44800/60000 (75%)]\tLoss: -87966353896302603182643609600.000000\n', 'Train Epoch: 1 [46080/60000 (77%)]\tLoss: -89428445783063874037256028160.000000\n', 'Train Epoch: 1 [47360/60000 (79%)]\tLoss: -91534640123889667281145298944.000000\n', 'Train Epoch: 1 [48640/60000 (81%)]\tLoss: -96863103455369699979438325760.000000\n', 'Train Epoch: 1 [49920/60000 (83%)]\tLoss: -96662176206256562314885988352.000000\n', 'Train Epoch: 1 [51200/60000 (85%)]\tLoss: -100418044275276174460566110208.000000\n', 'Train Epoch: 1 [52480/60000 (87%)]\tLoss: -106216373627068771118331461632.000000\n', 'Train Epoch: 1 [53760/60000 (90%)]\tLoss: -107003261554109340100289626112.000000\n', 'Train Epoch: 1 [55040/60000 (92%)]\tLoss: -110067369046519309397196275712.000000\n', 'Train Epoch: 1 [56320/60000 (94%)]\tLoss: -110290047515652544647602896896.000000\n', 'Train Epoch: 1 [57600/60000 (96%)]\tLoss: -116110411429454211069935353856.000000\n', 'Train Epoch: 1 [58880/60000 (98%)]\tLoss: -112395070709590586219479171072.000000\n', 'Train Epoch: 1 [0/60000 (0%)]\tLoss: 0.000510\n', 'Train Epoch: 1 [1280/60000 (2%)]\tLoss: -205357006490435584.000000\n', 'Train Epoch: 1 [2560/60000 (4%)]\tLoss: -57113324038121580094554112.000000\n', 'Train Epoch: 1 [3840/60000 (6%)]\tLoss: -1504654133149517197894221824.000000\n', 'Train Epoch: 1 [5120/60000 (9%)]\tLoss: -4486782671582442760978825216.000000\n', 'Train Epoch: 1 [6400/60000 (11%)]\tLoss: -7224622158838853449424044032.000000\n', 'Train Epoch: 1 [7680/60000 (13%)]\tLoss: -10219832685446996057485475840.000000\n', 'Train Epoch: 1 [8960/60000 (15%)]\tLoss: -12748840567541660833349107712.000000\n', 'Train Epoch: 1 [10240/60000 (17%)]\tLoss: -15395487321091091341131120640.000000\n', 'Train Epoch: 1 [11520/60000 (19%)]\tLoss: -17682665176781243020423987200.000000\n', 'Train Epoch: 1 [12800/60000 (21%)]\tLoss: -20708070514680854139981791232.000000\n', 'Train Epoch: 1 [14080/60000 (23%)]\tLoss: -23114019429190039548633022464.000000\n', 'Train Epoch: 1 [15360/60000 (26%)]\tLoss: -26388978223876897069508591616.000000\n', 'Train Epoch: 1 [16640/60000 (28%)]\tLoss: -28680211411784213056628719616.000000\n', 'Train Epoch: 1 [17920/60000 (30%)]\tLoss: -32248759730711076420439769088.000000\n', 'Train Epoch: 1 [19200/60000 (32%)]\tLoss: -33662015264489750839074750464.000000\n', 'Train Epoch: 1 [20480/60000 (34%)]\tLoss: -37602504251157151764384317440.000000\n', 'Train Epoch: 1 [21760/60000 (36%)]\tLoss: -39350386673911969242861797376.000000\n', 'Train Epoch: 1 [23040/60000 (38%)]\tLoss: -44541233162531456175159902208.000000\n', 'Train Epoch: 1 [24320/60000 (41%)]\tLoss: -46288527650659156382808276992.000000\n', 'Train Epoch: 1 [25600/60000 (43%)]\tLoss: -48202729459757401330889523200.000000\n', 'Train Epoch: 1 [26880/60000 (45%)]\tLoss: -51582361868720305972749271040.000000\n', 'Train Epoch: 1 [28160/60000 (47%)]\tLoss: -54315025347163586350687453184.000000\n', 'Train Epoch: 1 [29440/60000 (49%)]\tLoss: -56628541021320322758748405760.000000\n', 'Train Epoch: 1 [30720/60000 (51%)]\tLoss: -58325962597022436643294937088.000000\n', 'Train Epoch: 1 [32000/60000 (53%)]\tLoss: -60657385484882214746006224896.000000\n', 'Train Epoch: 1 [33280/60000 (55%)]\tLoss: -64233260555407250364366323712.000000\n', 'Train Epoch: 1 [34560/60000 (58%)]\tLoss: -65857565730855093532069199872.000000\n', 'Train Epoch: 1 [35840/60000 (60%)]\tLoss: -69747794571045312823369400320.000000\n', 'Train Epoch: 1 [37120/60000 (62%)]\tLoss: -71601342305037580048325935104.000000\n', 'Train Epoch: 1 [38400/60000 (64%)]\tLoss: -75061297445507614485625438208.000000\n', 'Train Epoch: 1 [39680/60000 (66%)]\tLoss: -77654896675763349551310700544.000000\n', 'Train Epoch: 1 [40960/60000 (68%)]\tLoss: -80598546043928279938106392576.000000\n', 'Train Epoch: 1 [42240/60000 (70%)]\tLoss: -83188424049395513723363262464.000000\n', 'Train Epoch: 1 [43520/60000 (72%)]\tLoss: -86655840528908482200100405248.000000\n', 'Train Epoch: 1 [44800/60000 (75%)]\tLoss: -86698011261600508131858710528.000000\n', 'Train Epoch: 1 [46080/60000 (77%)]\tLoss: -90647430243287015556267376640.000000\n', 'Train Epoch: 1 [47360/60000 (79%)]\tLoss: -93564719361744567583480217600.000000\n', 'Train Epoch: 1 [48640/60000 (81%)]\tLoss: -96577674180412092883432112128.000000\n', 'Train Epoch: 1 [49920/60000 (83%)]\tLoss: -96478853939391562687690309632.000000\n', 'Train Epoch: 1 [51200/60000 (85%)]\tLoss: -104214071348866110069143502848.000000\n', 'Train Epoch: 1 [52480/60000 (87%)]\tLoss: -102211967410055729545054519296.000000\n', 'Train Epoch: 1 [53760/60000 (90%)]\tLoss: -109365578163500051421988913152.000000\n', 'Train Epoch: 1 [55040/60000 (92%)]\tLoss: -110657447628019803045228445696.000000\n', 'Train Epoch: 1 [56320/60000 (94%)]\tLoss: -107908813106131457527177543680.000000\n', 'Train Epoch: 1 [57600/60000 (96%)]\tLoss: -113089957492811888773384110080.000000\n', 'Train Epoch: 1 [58880/60000 (98%)]\tLoss: -115282693921802751135459573760.000000\n', '\n', 'Test set: Average loss: -119740074291998070002686099456.0000, Accuracy: 980/10000 (10%)\n', '\n', '\n', 'Test set: Average loss: -119740077193420034150456360960.0000, Accuracy: 980/10000 (10%)\n', '\n', '{"accuracy": 9.8, "runtime": 67.28138215094805, "mem_params": 244341408, "mem_bufs": 0, "mem_peak": 3343928832}\n']
[2021-12-11 15:46:31,072 DEBUG] Received error from gpu1: []
[2021-12-11 15:46:31,073 DEBUG] SSH connection with gpu1 has been closed
[2021-12-11 15:46:31,073 INFO] {'batch-size': 128, 'lr': 0.9, 'gamma': 0.7} => {"accuracy": 9.8, "runtime": 67.28138215094805, "mem_params": 244341408, "mem_bufs": 0, "mem_peak": 3343928832}
[2021-12-11 15:46:31,073 DEBUG] gpu1 finished training {'batch-size': 128, 'lr': 0.9, 'gamma': 0.7}
[2021-12-11 15:46:31,074 DEBUG] gpu1 now training {'batch-size': 128, 'lr': 0.99, 'gamma': 0.7}...
[2021-12-11 15:46:31,074 DEBUG] Attempting to establish SSH connection with gpu1...
[2021-12-11 15:46:31,178 DEBUG] SSH connection with gpu1 established successfully!
[2021-12-11 15:46:31,178 DEBUG] Running cmd on gpu1: source /u5/p3basta/CS848/CS848-Project/venv/bin/activate && python /u5/p3basta/CS848/CS848-Project/models/MNIST/train.py --arch "alexnet" --parallelism "dp" --epochs "1" --batch-size "128" --lr "0.99" --gamma "0.7"
[2021-12-11 15:46:31,178 INFO] Training {'batch-size': 128, 'lr': 0.99, 'gamma': 0.7} on gpu1...
[2021-12-11 15:46:33,410 DEBUG] Received output from gpu2: ['Train Epoch: 1 [0/60000 (0%)]\tLoss: 0.000458\n', 'Train Epoch: 1 [1280/60000 (2%)]\tLoss: -182218437118918656.000000\n', 'Train Epoch: 1 [2560/60000 (4%)]\tLoss: -56390188612002073534267392.000000\n', 'Train Epoch: 1 [3840/60000 (6%)]\tLoss: -1681988882036095883988172800.000000\n', 'Train Epoch: 1 [5120/60000 (9%)]\tLoss: -4791833084128468053495119872.000000\n', 'Train Epoch: 1 [6400/60000 (11%)]\tLoss: -7808442424157924100136763392.000000\n', 'Train Epoch: 1 [7680/60000 (13%)]\tLoss: -10664025560375439190753542144.000000\n', 'Train Epoch: 1 [8960/60000 (15%)]\tLoss: -13287221041970939040404340736.000000\n', 'Train Epoch: 1 [10240/60000 (17%)]\tLoss: -16718428776476504512465469440.000000\n', 'Train Epoch: 1 [11520/60000 (19%)]\tLoss: -18901741723150800497517002752.000000\n', 'Train Epoch: 1 [12800/60000 (21%)]\tLoss: -22739457848051509334040903680.000000\n', 'Train Epoch: 1 [14080/60000 (23%)]\tLoss: -25313874825653827900868132864.000000\n', 'Train Epoch: 1 [15360/60000 (26%)]\tLoss: -28003543518453821593958219776.000000\n', 'Train Epoch: 1 [16640/60000 (28%)]\tLoss: -31437556338650211635276283904.000000\n', 'Train Epoch: 1 [17920/60000 (30%)]\tLoss: -33150675060541384220513140736.000000\n', 'Train Epoch: 1 [19200/60000 (32%)]\tLoss: -35919429224829995861996994560.000000\n', 'Train Epoch: 1 [20480/60000 (34%)]\tLoss: -38742681859514164644069507072.000000\n', 'Train Epoch: 1 [21760/60000 (36%)]\tLoss: -42648664514291237071802597376.000000\n', 'Train Epoch: 1 [23040/60000 (38%)]\tLoss: -44156827808459384185119834112.000000\n', 'Train Epoch: 1 [24320/60000 (41%)]\tLoss: -47493694466553421319924350976.000000\n', 'Train Epoch: 1 [25600/60000 (43%)]\tLoss: -50443770975501537293855883264.000000\n', 'Train Epoch: 1 [26880/60000 (45%)]\tLoss: -53189609856432023981940277248.000000\n', 'Train Epoch: 1 [28160/60000 (47%)]\tLoss: -56134534263547329172943667200.000000\n', 'Train Epoch: 1 [29440/60000 (49%)]\tLoss: -60195637212553703706656243712.000000\n', 'Train Epoch: 1 [30720/60000 (51%)]\tLoss: -60823645841644606345044819968.000000\n', 'Train Epoch: 1 [32000/60000 (53%)]\tLoss: -65819267338679020709386125312.000000\n', 'Train Epoch: 1 [33280/60000 (55%)]\tLoss: -67214438570011545821675257856.000000\n', 'Train Epoch: 1 [34560/60000 (58%)]\tLoss: -69457024299595580158626496512.000000\n', 'Train Epoch: 1 [35840/60000 (60%)]\tLoss: -70918762008870635789847887872.000000\n', 'Train Epoch: 1 [37120/60000 (62%)]\tLoss: -77280290232143232075089051648.000000\n', 'Train Epoch: 1 [38400/60000 (64%)]\tLoss: -79475189504983248734672388096.000000\n', 'Train Epoch: 1 [39680/60000 (66%)]\tLoss: -80321277018253071589029445632.000000\n', 'Train Epoch: 1 [40960/60000 (68%)]\tLoss: -84105687070295147870381146112.000000\n', 'Train Epoch: 1 [42240/60000 (70%)]\tLoss: -85360353731662852428627181568.000000\n', 'Train Epoch: 1 [43520/60000 (72%)]\tLoss: -90497419549592178406409109504.000000\n', 'Train Epoch: 1 [44800/60000 (75%)]\tLoss: -91551328967040128607330500608.000000\n', 'Train Epoch: 1 [46080/60000 (77%)]\tLoss: -94617419853372903155226902528.000000\n', 'Train Epoch: 1 [47360/60000 (79%)]\tLoss: -98243715630835537975533633536.000000\n', 'Train Epoch: 1 [48640/60000 (81%)]\tLoss: -95921095234099828891500675072.000000\n', 'Train Epoch: 1 [49920/60000 (83%)]\tLoss: -102641485531138655255821025280.000000\n', 'Train Epoch: 1 [51200/60000 (85%)]\tLoss: -106737911781436894735732047872.000000\n', 'Train Epoch: 1 [52480/60000 (87%)]\tLoss: -109431001828753727486779457536.000000\n', 'Train Epoch: 1 [53760/60000 (90%)]\tLoss: -110191378390359466280507932672.000000\n', 'Train Epoch: 1 [55040/60000 (92%)]\tLoss: -110758600718082870845705814016.000000\n', 'Train Epoch: 1 [56320/60000 (94%)]\tLoss: -115149428739656169747529072640.000000\n', 'Train Epoch: 1 [57600/60000 (96%)]\tLoss: -118399200792706642015657394176.000000\n', 'Train Epoch: 1 [58880/60000 (98%)]\tLoss: -122526756882859958196817100800.000000\n', 'Train Epoch: 1 [0/60000 (0%)]\tLoss: -0.002488\n', 'Train Epoch: 1 [1280/60000 (2%)]\tLoss: -186352618019225600.000000\n', 'Train Epoch: 1 [2560/60000 (4%)]\tLoss: -57708844888739163976761344.000000\n', 'Train Epoch: 1 [3840/60000 (6%)]\tLoss: -1671966249472015420727754752.000000\n', 'Train Epoch: 1 [5120/60000 (9%)]\tLoss: -4719193938036872350170873856.000000\n', 'Train Epoch: 1 [6400/60000 (11%)]\tLoss: -7664260311294568809883500544.000000\n', 'Train Epoch: 1 [7680/60000 (13%)]\tLoss: -10516230837152688621911801856.000000\n', 'Train Epoch: 1 [8960/60000 (15%)]\tLoss: -13385926765604259647249711104.000000\n', 'Train Epoch: 1 [10240/60000 (17%)]\tLoss: -16603841734361293288766439424.000000\n', 'Train Epoch: 1 [11520/60000 (19%)]\tLoss: -19403168499260003013363761152.000000\n', 'Train Epoch: 1 [12800/60000 (21%)]\tLoss: -21900793894892757561959776256.000000\n', 'Train Epoch: 1 [14080/60000 (23%)]\tLoss: -24017417582095968417303494656.000000\n', 'Train Epoch: 1 [15360/60000 (26%)]\tLoss: -28277478553392123973514297344.000000\n', 'Train Epoch: 1 [16640/60000 (28%)]\tLoss: -31027770625915956737035206656.000000\n', 'Train Epoch: 1 [17920/60000 (30%)]\tLoss: -32681519756384492142645477376.000000\n', 'Train Epoch: 1 [19200/60000 (32%)]\tLoss: -35718114741665262886537134080.000000\n', 'Train Epoch: 1 [20480/60000 (34%)]\tLoss: -40045053867091818358264299520.000000\n', 'Train Epoch: 1 [21760/60000 (36%)]\tLoss: -41343076575138749129217277952.000000\n', 'Train Epoch: 1 [23040/60000 (38%)]\tLoss: -46080786026711237820212576256.000000\n', 'Train Epoch: 1 [24320/60000 (41%)]\tLoss: -48339985041582007569025597440.000000\n', 'Train Epoch: 1 [25600/60000 (43%)]\tLoss: -49865488865475252019567525888.000000\n', 'Train Epoch: 1 [26880/60000 (45%)]\tLoss: -53691857143717625098642915328.000000\n', 'Train Epoch: 1 [28160/60000 (47%)]\tLoss: -55897495077939687331442196480.000000\n', 'Train Epoch: 1 [29440/60000 (49%)]\tLoss: -59231032467663301366371057664.000000\n', 'Train Epoch: 1 [30720/60000 (51%)]\tLoss: -62696498609818844679634944000.000000\n', 'Train Epoch: 1 [32000/60000 (53%)]\tLoss: -64594734097838507357248684032.000000\n', 'Train Epoch: 1 [33280/60000 (55%)]\tLoss: -66988567781135890691104178176.000000\n', 'Train Epoch: 1 [34560/60000 (58%)]\tLoss: -71546709247197261122848686080.000000\n', 'Train Epoch: 1 [35840/60000 (60%)]\tLoss: -70731987692106658452000997376.000000\n', 'Train Epoch: 1 [37120/60000 (62%)]\tLoss: -74662758048552313647460777984.000000\n', 'Train Epoch: 1 [38400/60000 (64%)]\tLoss: -79006182955370567050628956160.000000\n', 'Train Epoch: 1 [39680/60000 (66%)]\tLoss: -81238634486482363128951603200.000000\n', 'Train Epoch: 1 [40960/60000 (68%)]\tLoss: -84654067155751902551176380416.000000\n', 'Train Epoch: 1 [42240/60000 (70%)]\tLoss: -85643336820782333048412700672.000000\n', 'Train Epoch: 1 [43520/60000 (72%)]\tLoss: -88188541239321619989948006400.000000\n', 'Train Epoch: 1 [44800/60000 (75%)]\tLoss: -90136687418698731947825299456.000000\n', 'Train Epoch: 1 [46080/60000 (77%)]\tLoss: -94301370754140369279655084032.000000\n', 'Train Epoch: 1 [47360/60000 (79%)]\tLoss: -95489159261377673922384756736.000000\n', 'Train Epoch: 1 [48640/60000 (81%)]\tLoss: -101328780985696482757898665984.000000\n', 'Train Epoch: 1 [49920/60000 (83%)]\tLoss: -105389959492566583205934661632.000000\n', 'Train Epoch: 1 [51200/60000 (85%)]\tLoss: -104162200875418269886116265984.000000\n', 'Train Epoch: 1 [52480/60000 (87%)]\tLoss: -108496521059657550613312438272.000000\n', 'Train Epoch: 1 [53760/60000 (90%)]\tLoss: -110105062975785574905291997184.000000\n', 'Train Epoch: 1 [55040/60000 (92%)]\tLoss: -112315102155569671647430443008.000000\n', 'Train Epoch: 1 [56320/60000 (94%)]\tLoss: -119242794896473509697341620224.000000\n', 'Train Epoch: 1 [57600/60000 (96%)]\tLoss: -120746283047823615861897297920.000000\n', 'Train Epoch: 1 [58880/60000 (98%)]\tLoss: -124025900457045824287776178176.000000\n', '\n', 'Test set: Average loss: -124386446247135756848887496704.0000, Accuracy: 1010/10000 (10%)\n', '\n', '\n', 'Test set: Average loss: -124386451082839036292566614016.0000, Accuracy: 1010/10000 (10%)\n', '\n', '{"accuracy": 10.1, "runtime": 66.78818869125098, "mem_params": 244341408, "mem_bufs": 0, "mem_peak": 3343928832}\n']
[2021-12-11 15:46:33,411 DEBUG] Received error from gpu2: []
[2021-12-11 15:46:33,411 DEBUG] SSH connection with gpu2 has been closed
[2021-12-11 15:46:33,411 INFO] {'batch-size': 128, 'lr': 0.9, 'gamma': 0.9} => {"accuracy": 10.1, "runtime": 66.78818869125098, "mem_params": 244341408, "mem_bufs": 0, "mem_peak": 3343928832}
[2021-12-11 15:46:33,412 DEBUG] gpu2 finished training {'batch-size': 128, 'lr': 0.9, 'gamma': 0.9}
[2021-12-11 15:46:33,412 DEBUG] gpu2 now training {'batch-size': 128, 'lr': 0.99, 'gamma': 0.9}...
[2021-12-11 15:46:33,412 DEBUG] Attempting to establish SSH connection with gpu2...
[2021-12-11 15:46:33,493 DEBUG] SSH connection with gpu2 established successfully!
[2021-12-11 15:46:33,493 DEBUG] Running cmd on gpu2: source /u5/p3basta/CS848/CS848-Project/venv/bin/activate && python /u5/p3basta/CS848/CS848-Project/models/MNIST/train.py --arch "alexnet" --parallelism "dp" --epochs "1" --batch-size "128" --lr "0.99" --gamma "0.9"
[2021-12-11 15:46:33,493 INFO] Training {'batch-size': 128, 'lr': 0.99, 'gamma': 0.9} on gpu2...
[2021-12-11 15:47:37,619 DEBUG] Received output from gpu3: ['Train Epoch: 1 [0/60000 (0%)]\tLoss: 0.000463\n', 'Train Epoch: 1 [1280/60000 (2%)]\tLoss: -367278527680086016.000000\n', 'Train Epoch: 1 [2560/60000 (4%)]\tLoss: -80442709130585202363465728.000000\n', 'Train Epoch: 1 [3840/60000 (6%)]\tLoss: -1822208929420323541907144704.000000\n', 'Train Epoch: 1 [5120/60000 (9%)]\tLoss: -4384581216160177899264016384.000000\n', 'Train Epoch: 1 [6400/60000 (11%)]\tLoss: -6578225815255277129984638976.000000\n', 'Train Epoch: 1 [7680/60000 (13%)]\tLoss: -9001217750401139088212099072.000000\n', 'Train Epoch: 1 [8960/60000 (15%)]\tLoss: -11638080941189684408522637312.000000\n', 'Train Epoch: 1 [10240/60000 (17%)]\tLoss: -14083597383867213857008123904.000000\n', 'Train Epoch: 1 [11520/60000 (19%)]\tLoss: -16447189032208299982915108864.000000\n', 'Train Epoch: 1 [12800/60000 (21%)]\tLoss: -18316397314049383668811563008.000000\n', 'Train Epoch: 1 [14080/60000 (23%)]\tLoss: -20882325837898744048367173632.000000\n', 'Train Epoch: 1 [15360/60000 (26%)]\tLoss: -23905480968169267781980651520.000000\n', 'Train Epoch: 1 [16640/60000 (28%)]\tLoss: -25518242318749736101958647808.000000\n', 'Train Epoch: 1 [17920/60000 (30%)]\tLoss: -29542657202550696362006020096.000000\n', 'Train Epoch: 1 [19200/60000 (32%)]\tLoss: -30071885730736173196637110272.000000\n', 'Train Epoch: 1 [20480/60000 (34%)]\tLoss: -34412311934837804375094591488.000000\n', 'Train Epoch: 1 [21760/60000 (36%)]\tLoss: -36190766958202719936685539328.000000\n', 'Train Epoch: 1 [23040/60000 (38%)]\tLoss: -38000316403674090677186068480.000000\n', 'Train Epoch: 1 [24320/60000 (41%)]\tLoss: -39787987125230326351411544064.000000\n', 'Train Epoch: 1 [25600/60000 (43%)]\tLoss: -43227041071647179738995228672.000000\n', 'Train Epoch: 1 [26880/60000 (45%)]\tLoss: -44319248881271202762599694336.000000\n', 'Train Epoch: 1 [28160/60000 (47%)]\tLoss: -46857549200012534282832576512.000000\n', 'Train Epoch: 1 [29440/60000 (49%)]\tLoss: -51688147600303068895181275136.000000\n', 'Train Epoch: 1 [30720/60000 (51%)]\tLoss: -51014860921374412098483781632.000000\n', 'Train Epoch: 1 [32000/60000 (53%)]\tLoss: -55302401343234386120193081344.000000\n', 'Train Epoch: 1 [33280/60000 (55%)]\tLoss: -56940443882780897085822599168.000000\n', 'Train Epoch: 1 [34560/60000 (58%)]\tLoss: -57795263051677545914179780608.000000\n', 'Train Epoch: 1 [35840/60000 (60%)]\tLoss: -62301604879788319207575257088.000000\n', 'Train Epoch: 1 [37120/60000 (62%)]\tLoss: -64484292112903634964635975680.000000\n', 'Train Epoch: 1 [38400/60000 (64%)]\tLoss: -64065101807318745167951822848.000000\n', 'Train Epoch: 1 [39680/60000 (66%)]\tLoss: -68772786452793148654678441984.000000\n', 'Train Epoch: 1 [40960/60000 (68%)]\tLoss: -70176594892422842348063424512.000000\n', 'Train Epoch: 1 [42240/60000 (70%)]\tLoss: -73800180031524309992017494016.000000\n', 'Train Epoch: 1 [43520/60000 (72%)]\tLoss: -73145395584475536465267261440.000000\n', 'Train Epoch: 1 [44800/60000 (75%)]\tLoss: -76638378956126761201191354368.000000\n', 'Train Epoch: 1 [46080/60000 (77%)]\tLoss: -81334630752346137276855615488.000000\n', 'Train Epoch: 1 [47360/60000 (79%)]\tLoss: -83982149963103277951590858752.000000\n', 'Train Epoch: 1 [48640/60000 (81%)]\tLoss: -85111655023209005433093095424.000000\n', 'Train Epoch: 1 [49920/60000 (83%)]\tLoss: -86242935693112291901195681792.000000\n', 'Train Epoch: 1 [51200/60000 (85%)]\tLoss: -88733965123360098272839467008.000000\n', 'Train Epoch: 1 [52480/60000 (87%)]\tLoss: -86677383964803333521565286400.000000\n', 'Train Epoch: 1 [53760/60000 (90%)]\tLoss: -96299064002655749555114475520.000000\n', 'Train Epoch: 1 [55040/60000 (92%)]\tLoss: -96243292854493059045140725760.000000\n', 'Train Epoch: 1 [56320/60000 (94%)]\tLoss: -97869468087068118592348225536.000000\n', 'Train Epoch: 1 [57600/60000 (96%)]\tLoss: -100550421652523976355196436480.000000\n', 'Train Epoch: 1 [58880/60000 (98%)]\tLoss: -105725181399719567841074085888.000000\n', 'Train Epoch: 1 [0/60000 (0%)]\tLoss: 0.000262\n', 'Train Epoch: 1 [1280/60000 (2%)]\tLoss: -364564417586659328.000000\n', 'Train Epoch: 1 [2560/60000 (4%)]\tLoss: -77716372590211299182379008.000000\n', 'Train Epoch: 1 [3840/60000 (6%)]\tLoss: -1814888375928160053767438336.000000\n', 'Train Epoch: 1 [5120/60000 (9%)]\tLoss: -4274189996664996355337355264.000000\n', 'Train Epoch: 1 [6400/60000 (11%)]\tLoss: -6786192341906942359433641984.000000\n', 'Train Epoch: 1 [7680/60000 (13%)]\tLoss: -8672862164114246917213388800.000000\n', 'Train Epoch: 1 [8960/60000 (15%)]\tLoss: -11361288874529245893612273664.000000\n', 'Train Epoch: 1 [10240/60000 (17%)]\tLoss: -13732659441059239042597519360.000000\n', 'Train Epoch: 1 [11520/60000 (19%)]\tLoss: -16321224628644235066484981760.000000\n', 'Train Epoch: 1 [12800/60000 (21%)]\tLoss: -18243642174831052479826755584.000000\n', 'Train Epoch: 1 [14080/60000 (23%)]\tLoss: -20879874929694134702501265408.000000\n', 'Train Epoch: 1 [15360/60000 (26%)]\tLoss: -23748542562844060862593892352.000000\n', 'Train Epoch: 1 [16640/60000 (28%)]\tLoss: -25529958509993735691733827584.000000\n', 'Train Epoch: 1 [17920/60000 (30%)]\tLoss: -27823555242325727936283410432.000000\n', 'Train Epoch: 1 [19200/60000 (32%)]\tLoss: -30546037298631941359140864000.000000\n', 'Train Epoch: 1 [20480/60000 (34%)]\tLoss: -33265031887290555549008003072.000000\n', 'Train Epoch: 1 [21760/60000 (36%)]\tLoss: -34579993723911539737342509056.000000\n', 'Train Epoch: 1 [23040/60000 (38%)]\tLoss: -38350911974912057442318680064.000000\n', 'Train Epoch: 1 [24320/60000 (41%)]\tLoss: -41287210979646401226339254272.000000\n', 'Train Epoch: 1 [25600/60000 (43%)]\tLoss: -41922010371739670414545125376.000000\n', 'Train Epoch: 1 [26880/60000 (45%)]\tLoss: -43934956863994719644044754944.000000\n', 'Train Epoch: 1 [28160/60000 (47%)]\tLoss: -46257128635914556111782412288.000000\n', 'Train Epoch: 1 [29440/60000 (49%)]\tLoss: -50439128889248876432610820096.000000\n', 'Train Epoch: 1 [30720/60000 (51%)]\tLoss: -53531792531780758474124689408.000000\n', 'Train Epoch: 1 [32000/60000 (53%)]\tLoss: -53600956311288867297924481024.000000\n', 'Train Epoch: 1 [33280/60000 (55%)]\tLoss: -56360933957469065703778680832.000000\n', 'Train Epoch: 1 [34560/60000 (58%)]\tLoss: -57793633835240955886581055488.000000\n', 'Train Epoch: 1 [35840/60000 (60%)]\tLoss: -60429200736429953489280434176.000000\n', 'Train Epoch: 1 [37120/60000 (62%)]\tLoss: -63287044705601142422543269888.000000\n', 'Train Epoch: 1 [38400/60000 (64%)]\tLoss: -65498292811204853793856421888.000000\n', 'Train Epoch: 1 [39680/60000 (66%)]\tLoss: -67734101944885970189926006784.000000\n', 'Train Epoch: 1 [40960/60000 (68%)]\tLoss: -70577122405667431306863050752.000000\n', 'Train Epoch: 1 [42240/60000 (70%)]\tLoss: -72152291357861015816117420032.000000\n', 'Train Epoch: 1 [43520/60000 (72%)]\tLoss: -75205244620638447011029319680.000000\n', 'Train Epoch: 1 [44800/60000 (75%)]\tLoss: -77443339379697272315382333440.000000\n', 'Train Epoch: 1 [46080/60000 (77%)]\tLoss: -76719074754586037698602991616.000000\n', 'Train Epoch: 1 [47360/60000 (79%)]\tLoss: -83961390440044582991231451136.000000\n', 'Train Epoch: 1 [48640/60000 (81%)]\tLoss: -85890354366768278450250711040.000000\n', 'Train Epoch: 1 [49920/60000 (83%)]\tLoss: -87772000181333620064228737024.000000\n', 'Train Epoch: 1 [51200/60000 (85%)]\tLoss: -88759843691686223928610521088.000000\n', 'Train Epoch: 1 [52480/60000 (87%)]\tLoss: -90220235526513661710946009088.000000\n', 'Train Epoch: 1 [53760/60000 (90%)]\tLoss: -92799478762661473055181635584.000000\n', 'Train Epoch: 1 [55040/60000 (92%)]\tLoss: -94455537130340131717301403648.000000\n', 'Train Epoch: 1 [56320/60000 (94%)]\tLoss: -99850113592580339448586174464.000000\n', 'Train Epoch: 1 [57600/60000 (96%)]\tLoss: -97737742396394952708757389312.000000\n', 'Train Epoch: 1 [58880/60000 (98%)]\tLoss: -100181954285331589417752592384.000000\n', '\n', 'Test set: Average loss: -104991106757150402416083992576.0000, Accuracy: 1010/10000 (10%)\n', '\n', '\n', 'Test set: Average loss: -104991110625713033007901704192.0000, Accuracy: 1010/10000 (10%)\n', '\n', '{"accuracy": 10.1, "runtime": 68.22179368324578, "mem_params": 244341408, "mem_bufs": 0, "mem_peak": 3343928832}\n']
[2021-12-11 15:47:37,619 DEBUG] Received error from gpu3: []
[2021-12-11 15:47:37,620 DEBUG] SSH connection with gpu3 has been closed
[2021-12-11 15:47:37,620 INFO] {'batch-size': 128, 'lr': 0.99, 'gamma': 0.5} => {"accuracy": 10.1, "runtime": 68.22179368324578, "mem_params": 244341408, "mem_bufs": 0, "mem_peak": 3343928832}
[2021-12-11 15:47:37,620 DEBUG] gpu3 finished training {'batch-size': 128, 'lr': 0.99, 'gamma': 0.5}
[2021-12-11 15:47:37,621 DEBUG] gpu3 now training {'batch-size': 256, 'lr': 0.5, 'gamma': 0.5}...
[2021-12-11 15:47:37,621 DEBUG] Attempting to establish SSH connection with gpu3...
[2021-12-11 15:47:37,718 DEBUG] SSH connection with gpu3 established successfully!
[2021-12-11 15:47:37,718 DEBUG] Running cmd on gpu3: source /u5/p3basta/CS848/CS848-Project/venv/bin/activate && python /u5/p3basta/CS848/CS848-Project/models/MNIST/train.py --arch "alexnet" --parallelism "dp" --epochs "1" --batch-size "256" --lr "0.5" --gamma "0.5"
[2021-12-11 15:47:37,719 INFO] Training {'batch-size': 256, 'lr': 0.5, 'gamma': 0.5} on gpu3...
[2021-12-11 15:47:40,253 DEBUG] Received output from gpu1: ['Train Epoch: 1 [0/60000 (0%)]\tLoss: -0.001888\n', 'Train Epoch: 1 [1280/60000 (2%)]\tLoss: -419240553855582208.000000\n', 'Train Epoch: 1 [2560/60000 (4%)]\tLoss: -78193147137540396253446144.000000\n', 'Train Epoch: 1 [3840/60000 (6%)]\tLoss: -1811901183979839823816949760.000000\n', 'Train Epoch: 1 [5120/60000 (9%)]\tLoss: -4186616661719230578377621504.000000\n', 'Train Epoch: 1 [6400/60000 (11%)]\tLoss: -6397496127589372938011279360.000000\n', 'Train Epoch: 1 [7680/60000 (13%)]\tLoss: -8890208491192511979468095488.000000\n', 'Train Epoch: 1 [8960/60000 (15%)]\tLoss: -10945901254554686878736449536.000000\n', 'Train Epoch: 1 [10240/60000 (17%)]\tLoss: -13470363858909589621081899008.000000\n', 'Train Epoch: 1 [11520/60000 (19%)]\tLoss: -15631782733977681213511434240.000000\n', 'Train Epoch: 1 [12800/60000 (21%)]\tLoss: -18146178433582726589672587264.000000\n', 'Train Epoch: 1 [14080/60000 (23%)]\tLoss: -20797424772086472131892740096.000000\n', 'Train Epoch: 1 [15360/60000 (26%)]\tLoss: -22531572191925863247266185216.000000\n', 'Train Epoch: 1 [16640/60000 (28%)]\tLoss: -25429615305782480035410608128.000000\n', 'Train Epoch: 1 [17920/60000 (30%)]\tLoss: -27865584304023267778685304832.000000\n', 'Train Epoch: 1 [19200/60000 (32%)]\tLoss: -29864042575908872936669315072.000000\n', 'Train Epoch: 1 [20480/60000 (34%)]\tLoss: -31744557383701567270618660864.000000\n', 'Train Epoch: 1 [21760/60000 (36%)]\tLoss: -34724295076528587486137417728.000000\n', 'Train Epoch: 1 [23040/60000 (38%)]\tLoss: -36336017506482824484168400896.000000\n', 'Train Epoch: 1 [24320/60000 (41%)]\tLoss: -39393922170517544502086860800.000000\n', 'Train Epoch: 1 [25600/60000 (43%)]\tLoss: -41357342844283498327407853568.000000\n', 'Train Epoch: 1 [26880/60000 (45%)]\tLoss: -42919723628041471837423534080.000000\n', 'Train Epoch: 1 [28160/60000 (47%)]\tLoss: -45833121516517139276980289536.000000\n', 'Train Epoch: 1 [29440/60000 (49%)]\tLoss: -48786078669019805734492176384.000000\n', 'Train Epoch: 1 [30720/60000 (51%)]\tLoss: -50590065166774356032930971648.000000\n', 'Train Epoch: 1 [32000/60000 (53%)]\tLoss: -53010532997035124165791711232.000000\n', 'Train Epoch: 1 [33280/60000 (55%)]\tLoss: -55171445398297927988772077568.000000\n', 'Train Epoch: 1 [34560/60000 (58%)]\tLoss: -58052122009413791656643133440.000000\n', 'Train Epoch: 1 [35840/60000 (60%)]\tLoss: -60118610692851616923575648256.000000\n', 'Train Epoch: 1 [37120/60000 (62%)]\tLoss: -61861116701365687310977335296.000000\n', 'Train Epoch: 1 [38400/60000 (64%)]\tLoss: -62421694659447694285359546368.000000\n', 'Train Epoch: 1 [39680/60000 (66%)]\tLoss: -65912751305573908206036451328.000000\n', 'Train Epoch: 1 [40960/60000 (68%)]\tLoss: -70751297448655112431279800320.000000\n', 'Train Epoch: 1 [42240/60000 (70%)]\tLoss: -69120484852193874892472451072.000000\n', 'Train Epoch: 1 [43520/60000 (72%)]\tLoss: -72258322652500887960100536320.000000\n', 'Train Epoch: 1 [44800/60000 (75%)]\tLoss: -75521817902550579417219858432.000000\n', 'Train Epoch: 1 [46080/60000 (77%)]\tLoss: -77081728888638012102788775936.000000\n', 'Train Epoch: 1 [47360/60000 (79%)]\tLoss: -78122066224814194943366004736.000000\n', 'Train Epoch: 1 [48640/60000 (81%)]\tLoss: -84121166987625994567391641600.000000\n', 'Train Epoch: 1 [49920/60000 (83%)]\tLoss: -83781581613842838380074762240.000000\n', 'Train Epoch: 1 [51200/60000 (85%)]\tLoss: -85969321779094824657514135552.000000\n', 'Train Epoch: 1 [52480/60000 (87%)]\tLoss: -90356381352214793582456864768.000000\n', 'Train Epoch: 1 [53760/60000 (90%)]\tLoss: -89572487405524363955564183552.000000\n', 'Train Epoch: 1 [55040/60000 (92%)]\tLoss: -92435573201491538195014221824.000000\n', 'Train Epoch: 1 [56320/60000 (94%)]\tLoss: -93815996482298061405300981760.000000\n', 'Train Epoch: 1 [57600/60000 (96%)]\tLoss: -98232117498753610126888796160.000000\n', 'Train Epoch: 1 [58880/60000 (98%)]\tLoss: -96378201420175679069605593088.000000\n', 'Train Epoch: 1 [0/60000 (0%)]\tLoss: -0.003702\n', 'Train Epoch: 1 [1280/60000 (2%)]\tLoss: -421592649745563648.000000\n', 'Train Epoch: 1 [2560/60000 (4%)]\tLoss: -77379249118892220271820800.000000\n', 'Train Epoch: 1 [3840/60000 (6%)]\tLoss: -1797691583232885061368938496.000000\n', 'Train Epoch: 1 [5120/60000 (9%)]\tLoss: -4178377017650338585538199552.000000\n', 'Train Epoch: 1 [6400/60000 (11%)]\tLoss: -6595272377666815831794778112.000000\n', 'Train Epoch: 1 [7680/60000 (13%)]\tLoss: -8893988155266238771756007424.000000\n', 'Train Epoch: 1 [8960/60000 (15%)]\tLoss: -11087516761234602516816068608.000000\n', 'Train Epoch: 1 [10240/60000 (17%)]\tLoss: -13518771657133865636756193280.000000\n', 'Train Epoch: 1 [11520/60000 (19%)]\tLoss: -15794474162270644078179778560.000000\n', 'Train Epoch: 1 [12800/60000 (21%)]\tLoss: -17836856345405040523707678720.000000\n', 'Train Epoch: 1 [14080/60000 (23%)]\tLoss: -20211844244660911820926615552.000000\n', 'Train Epoch: 1 [15360/60000 (26%)]\tLoss: -22647416564117138514003361792.000000\n', 'Train Epoch: 1 [16640/60000 (28%)]\tLoss: -25012474507251155664749199360.000000\n', 'Train Epoch: 1 [17920/60000 (30%)]\tLoss: -27263414103143386404083466240.000000\n', 'Train Epoch: 1 [19200/60000 (32%)]\tLoss: -29920248181787987454002724864.000000\n', 'Train Epoch: 1 [20480/60000 (34%)]\tLoss: -32336548523627623124962377728.000000\n', 'Train Epoch: 1 [21760/60000 (36%)]\tLoss: -35274712863122700418842361856.000000\n', 'Train Epoch: 1 [23040/60000 (38%)]\tLoss: -36558627501302058124719423488.000000\n', 'Train Epoch: 1 [24320/60000 (41%)]\tLoss: -38796131964550524723420725248.000000\n', 'Train Epoch: 1 [25600/60000 (43%)]\tLoss: -41972119402489400219907653632.000000\n', 'Train Epoch: 1 [26880/60000 (45%)]\tLoss: -43856022508233553524297826304.000000\n', 'Train Epoch: 1 [28160/60000 (47%)]\tLoss: -45267783413020399700222672896.000000\n', 'Train Epoch: 1 [29440/60000 (49%)]\tLoss: -47874770552255070210088763392.000000\n', 'Train Epoch: 1 [30720/60000 (51%)]\tLoss: -51288994295704995003138834432.000000\n', 'Train Epoch: 1 [32000/60000 (53%)]\tLoss: -52818195732554326385883086848.000000\n', 'Train Epoch: 1 [33280/60000 (55%)]\tLoss: -54300551293893590888107474944.000000\n', 'Train Epoch: 1 [34560/60000 (58%)]\tLoss: -57611695221755437065432989696.000000\n', 'Train Epoch: 1 [35840/60000 (60%)]\tLoss: -59661438393645006570437738496.000000\n', 'Train Epoch: 1 [37120/60000 (62%)]\tLoss: -59211670765083535820994904064.000000\n', 'Train Epoch: 1 [38400/60000 (64%)]\tLoss: -63979721421308461982488199168.000000\n', 'Train Epoch: 1 [39680/60000 (66%)]\tLoss: -66832923304226990054505971712.000000\n', 'Train Epoch: 1 [40960/60000 (68%)]\tLoss: -67685938529127182678391521280.000000\n', 'Train Epoch: 1 [42240/60000 (70%)]\tLoss: -71686854917309383583855542272.000000\n', 'Train Epoch: 1 [43520/60000 (72%)]\tLoss: -71930519583092491537591828480.000000\n', 'Train Epoch: 1 [44800/60000 (75%)]\tLoss: -74465627582091403177660252160.000000\n', 'Train Epoch: 1 [46080/60000 (77%)]\tLoss: -75760302132301979370156720128.000000\n', 'Train Epoch: 1 [47360/60000 (79%)]\tLoss: -80095991802821292294464864256.000000\n', 'Train Epoch: 1 [48640/60000 (81%)]\tLoss: -81292733916910117784519704576.000000\n', 'Train Epoch: 1 [49920/60000 (83%)]\tLoss: -83213405368089894146543714304.000000\n', 'Train Epoch: 1 [51200/60000 (85%)]\tLoss: -85696869567232143346555158528.000000\n', 'Train Epoch: 1 [52480/60000 (87%)]\tLoss: -88499697966877900913078435840.000000\n', 'Train Epoch: 1 [53760/60000 (90%)]\tLoss: -91102628593303786397705961472.000000\n', 'Train Epoch: 1 [55040/60000 (92%)]\tLoss: -91104819771351837913085116416.000000\n', 'Train Epoch: 1 [56320/60000 (94%)]\tLoss: -95455564346218539266334523392.000000\n', 'Train Epoch: 1 [57600/60000 (96%)]\tLoss: -97402293815650790330647707648.000000\n', 'Train Epoch: 1 [58880/60000 (98%)]\tLoss: -99764997659093096963254517760.000000\n', '\n', 'Test set: Average loss: -102004188588971495562317660160.0000, Accuracy: 1028/10000 (10%)\n', '\n', '\n', 'Test set: Average loss: -102004181818986900822729687040.0000, Accuracy: 1028/10000 (10%)\n', '\n', '{"accuracy": 10.28, "runtime": 66.41429883893579, "mem_params": 244341408, "mem_bufs": 0, "mem_peak": 3343928832}\n']
[2021-12-11 15:47:40,253 DEBUG] Received error from gpu1: []
[2021-12-11 15:47:40,253 DEBUG] SSH connection with gpu1 has been closed
[2021-12-11 15:47:40,253 INFO] {'batch-size': 128, 'lr': 0.99, 'gamma': 0.7} => {"accuracy": 10.28, "runtime": 66.41429883893579, "mem_params": 244341408, "mem_bufs": 0, "mem_peak": 3343928832}
[2021-12-11 15:47:40,254 DEBUG] gpu1 finished training {'batch-size': 128, 'lr': 0.99, 'gamma': 0.7}
[2021-12-11 15:47:40,254 DEBUG] gpu1 now training {'batch-size': 256, 'lr': 0.5, 'gamma': 0.7}...
[2021-12-11 15:47:40,254 DEBUG] Attempting to establish SSH connection with gpu1...
[2021-12-11 15:47:40,365 DEBUG] SSH connection with gpu1 established successfully!
[2021-12-11 15:47:40,366 DEBUG] Running cmd on gpu1: source /u5/p3basta/CS848/CS848-Project/venv/bin/activate && python /u5/p3basta/CS848/CS848-Project/models/MNIST/train.py --arch "alexnet" --parallelism "dp" --epochs "1" --batch-size "256" --lr "0.5" --gamma "0.7"
[2021-12-11 15:47:40,366 INFO] Training {'batch-size': 256, 'lr': 0.5, 'gamma': 0.7} on gpu1...
[2021-12-11 15:47:43,387 DEBUG] Received output from gpu2: ['Train Epoch: 1 [0/60000 (0%)]\tLoss: 0.000818\n', 'Train Epoch: 1 [1280/60000 (2%)]\tLoss: -338009974825287680.000000\n', 'Train Epoch: 1 [2560/60000 (4%)]\tLoss: -75812161316342446442938368.000000\n', 'Train Epoch: 1 [3840/60000 (6%)]\tLoss: -1829934573412345691800338432.000000\n', 'Train Epoch: 1 [5120/60000 (9%)]\tLoss: -4345026969647566930306924544.000000\n', 'Train Epoch: 1 [6400/60000 (11%)]\tLoss: -7038650054081153592557830144.000000\n', 'Train Epoch: 1 [7680/60000 (13%)]\tLoss: -9388761707296888316202319872.000000\n', 'Train Epoch: 1 [8960/60000 (15%)]\tLoss: -11806275107026811127276240896.000000\n', 'Train Epoch: 1 [10240/60000 (17%)]\tLoss: -14444549104802113754094370816.000000\n', 'Train Epoch: 1 [11520/60000 (19%)]\tLoss: -16978345466510408350204690432.000000\n', 'Train Epoch: 1 [12800/60000 (21%)]\tLoss: -19617759915791323996341927936.000000\n', 'Train Epoch: 1 [14080/60000 (23%)]\tLoss: -21776439818299351194547519488.000000\n', 'Train Epoch: 1 [15360/60000 (26%)]\tLoss: -24132709437408747935550668800.000000\n', 'Train Epoch: 1 [16640/60000 (28%)]\tLoss: -26823360382437178514845204480.000000\n', 'Train Epoch: 1 [17920/60000 (30%)]\tLoss: -29134722657477726364688711680.000000\n', 'Train Epoch: 1 [19200/60000 (32%)]\tLoss: -32082964527047247481454723072.000000\n', 'Train Epoch: 1 [20480/60000 (34%)]\tLoss: -33721944456340608071659159552.000000\n', 'Train Epoch: 1 [21760/60000 (36%)]\tLoss: -36973477952089190717452189696.000000\n', 'Train Epoch: 1 [23040/60000 (38%)]\tLoss: -39754595271829955090105499648.000000\n', 'Train Epoch: 1 [24320/60000 (41%)]\tLoss: -41689499935589100562803589120.000000\n', 'Train Epoch: 1 [25600/60000 (43%)]\tLoss: -44041762626737782409842917376.000000\n', 'Train Epoch: 1 [26880/60000 (45%)]\tLoss: -47399785486675075555204792320.000000\n', 'Train Epoch: 1 [28160/60000 (47%)]\tLoss: -47956089703090085500668608512.000000\n', 'Train Epoch: 1 [29440/60000 (49%)]\tLoss: -51351150083352525273441501184.000000\n', 'Train Epoch: 1 [30720/60000 (51%)]\tLoss: -52087664527120323749905170432.000000\n', 'Train Epoch: 1 [32000/60000 (53%)]\tLoss: -56150873651578058145383055360.000000\n', 'Train Epoch: 1 [33280/60000 (55%)]\tLoss: -58352677024216030226268815360.000000\n', 'Train Epoch: 1 [34560/60000 (58%)]\tLoss: -60613193579335520606096457728.000000\n', 'Train Epoch: 1 [35840/60000 (60%)]\tLoss: -64325101138766099224482283520.000000\n', 'Train Epoch: 1 [37120/60000 (62%)]\tLoss: -68016442792163780537962463232.000000\n', 'Train Epoch: 1 [38400/60000 (64%)]\tLoss: -68926801713265459263677923328.000000\n', 'Train Epoch: 1 [39680/60000 (66%)]\tLoss: -71467576552043814478002782208.000000\n', 'Train Epoch: 1 [40960/60000 (68%)]\tLoss: -74324990785865062273551171584.000000\n', 'Train Epoch: 1 [42240/60000 (70%)]\tLoss: -76637557264358741882924171264.000000\n', 'Train Epoch: 1 [43520/60000 (72%)]\tLoss: -77547713123701657213895442432.000000\n', 'Train Epoch: 1 [44800/60000 (75%)]\tLoss: -80540092591603319469651263488.000000\n', 'Train Epoch: 1 [46080/60000 (77%)]\tLoss: -82602557818797739798861709312.000000\n', 'Train Epoch: 1 [47360/60000 (79%)]\tLoss: -84137147475804025446794788864.000000\n', 'Train Epoch: 1 [48640/60000 (81%)]\tLoss: -90595153646321648583751761920.000000\n', 'Train Epoch: 1 [49920/60000 (83%)]\tLoss: -88581253236037059685918965760.000000\n', 'Train Epoch: 1 [51200/60000 (85%)]\tLoss: -94359748648601603833786793984.000000\n', 'Train Epoch: 1 [52480/60000 (87%)]\tLoss: -93426391802728349935880634368.000000\n', 'Train Epoch: 1 [53760/60000 (90%)]\tLoss: -96552626748586952285218668544.000000\n', 'Train Epoch: 1 [55040/60000 (92%)]\tLoss: -98170556729282921431883055104.000000\n', 'Train Epoch: 1 [56320/60000 (94%)]\tLoss: -102784837688092646205927981056.000000\n', 'Train Epoch: 1 [57600/60000 (96%)]\tLoss: -103733957793285718979557457920.000000\n', 'Train Epoch: 1 [58880/60000 (98%)]\tLoss: -104324621948230088463596126208.000000\n', 'Train Epoch: 1 [0/60000 (0%)]\tLoss: 0.002961\n', 'Train Epoch: 1 [1280/60000 (2%)]\tLoss: -346615233860599808.000000\n', 'Train Epoch: 1 [2560/60000 (4%)]\tLoss: -75667280588387531624546304.000000\n', 'Train Epoch: 1 [3840/60000 (6%)]\tLoss: -1878700533619556852128808960.000000\n', 'Train Epoch: 1 [5120/60000 (9%)]\tLoss: -4416876004796997506116354048.000000\n', 'Train Epoch: 1 [6400/60000 (11%)]\tLoss: -6668855701907080284808937472.000000\n', 'Train Epoch: 1 [7680/60000 (13%)]\tLoss: -9331811738400911471042101248.000000\n', 'Train Epoch: 1 [8960/60000 (15%)]\tLoss: -11896576198912244483052535808.000000\n', 'Train Epoch: 1 [10240/60000 (17%)]\tLoss: -14435772586693700518464716800.000000\n', 'Train Epoch: 1 [11520/60000 (19%)]\tLoss: -17021727486205290345960308736.000000\n', 'Train Epoch: 1 [12800/60000 (21%)]\tLoss: -19223049177462009723034271744.000000\n', 'Train Epoch: 1 [14080/60000 (23%)]\tLoss: -21580069652842182737626398720.000000\n', 'Train Epoch: 1 [15360/60000 (26%)]\tLoss: -24461948106227936730204340224.000000\n', 'Train Epoch: 1 [16640/60000 (28%)]\tLoss: -26670650856297381362747310080.000000\n', 'Train Epoch: 1 [17920/60000 (30%)]\tLoss: -29363854240409802985279848448.000000\n', 'Train Epoch: 1 [19200/60000 (32%)]\tLoss: -31751950248430499700200701952.000000\n', 'Train Epoch: 1 [20480/60000 (34%)]\tLoss: -33912411663694189472063160320.000000\n', 'Train Epoch: 1 [21760/60000 (36%)]\tLoss: -36923628651496018742576414720.000000\n', 'Train Epoch: 1 [23040/60000 (38%)]\tLoss: -39075778701749857938862768128.000000\n', 'Train Epoch: 1 [24320/60000 (41%)]\tLoss: -41836639430462352968371929088.000000\n', 'Train Epoch: 1 [25600/60000 (43%)]\tLoss: -43771095469405625824774717440.000000\n', 'Train Epoch: 1 [26880/60000 (45%)]\tLoss: -46769647070300398706824839168.000000\n', 'Train Epoch: 1 [28160/60000 (47%)]\tLoss: -49590118231126157267866484736.000000\n', 'Train Epoch: 1 [29440/60000 (49%)]\tLoss: -52134000387050240708741955584.000000\n', 'Train Epoch: 1 [30720/60000 (51%)]\tLoss: -55485737777198834356324401152.000000\n', 'Train Epoch: 1 [32000/60000 (53%)]\tLoss: -55721629427751138874038943744.000000\n', 'Train Epoch: 1 [33280/60000 (55%)]\tLoss: -59379668952711623449472139264.000000\n', 'Train Epoch: 1 [34560/60000 (58%)]\tLoss: -59513637767464152414539481088.000000\n', 'Train Epoch: 1 [35840/60000 (60%)]\tLoss: -62829768514331908937210658816.000000\n', 'Train Epoch: 1 [37120/60000 (62%)]\tLoss: -66991453147056924044329746432.000000\n', 'Train Epoch: 1 [38400/60000 (64%)]\tLoss: -69466450143095387970473033728.000000\n', 'Train Epoch: 1 [39680/60000 (66%)]\tLoss: -68084081247297922466358231040.000000\n', 'Train Epoch: 1 [40960/60000 (68%)]\tLoss: -72868249340328882726965870592.000000\n', 'Train Epoch: 1 [42240/60000 (70%)]\tLoss: -75307804975913409965780369408.000000\n', 'Train Epoch: 1 [43520/60000 (72%)]\tLoss: -77637669482833841085571137536.000000\n', 'Train Epoch: 1 [44800/60000 (75%)]\tLoss: -80312550084992728484674535424.000000\n', 'Train Epoch: 1 [46080/60000 (77%)]\tLoss: -81481968586611670207522930688.000000\n', 'Train Epoch: 1 [47360/60000 (79%)]\tLoss: -85572076310555830102138028032.000000\n', 'Train Epoch: 1 [48640/60000 (81%)]\tLoss: -87429109151012455125262270464.000000\n', 'Train Epoch: 1 [49920/60000 (83%)]\tLoss: -91112196107798080298908909568.000000\n', 'Train Epoch: 1 [51200/60000 (85%)]\tLoss: -93014365327097973390985658368.000000\n', 'Train Epoch: 1 [52480/60000 (87%)]\tLoss: -92553821258222594111165169664.000000\n', 'Train Epoch: 1 [53760/60000 (90%)]\tLoss: -98709765979029943261673291776.000000\n', 'Train Epoch: 1 [55040/60000 (92%)]\tLoss: -101124406409050850252340330496.000000\n', 'Train Epoch: 1 [56320/60000 (94%)]\tLoss: -99067334124379867057963925504.000000\n', 'Train Epoch: 1 [57600/60000 (96%)]\tLoss: -104115383334107100223467683840.000000\n', 'Train Epoch: 1 [58880/60000 (98%)]\tLoss: -104351662218711000052089749504.000000\n', '\n', 'Test set: Average loss: -108775093896717635021566902272.0000, Accuracy: 1032/10000 (10%)\n', '\n', '\n', 'Test set: Average loss: -108775094863858301465614352384.0000, Accuracy: 1032/10000 (10%)\n', '\n', '{"accuracy": 10.32, "runtime": 67.14807305671275, "mem_params": 244341408, "mem_bufs": 0, "mem_peak": 3343928832}\n']
[2021-12-11 15:47:43,387 DEBUG] Received error from gpu2: []
[2021-12-11 15:47:43,388 DEBUG] SSH connection with gpu2 has been closed
[2021-12-11 15:47:43,388 INFO] {'batch-size': 128, 'lr': 0.99, 'gamma': 0.9} => {"accuracy": 10.32, "runtime": 67.14807305671275, "mem_params": 244341408, "mem_bufs": 0, "mem_peak": 3343928832}
[2021-12-11 15:47:43,388 DEBUG] gpu2 finished training {'batch-size': 128, 'lr': 0.99, 'gamma': 0.9}
[2021-12-11 15:47:43,389 DEBUG] gpu2 now training {'batch-size': 256, 'lr': 0.5, 'gamma': 0.9}...
[2021-12-11 15:47:43,389 DEBUG] Attempting to establish SSH connection with gpu2...
[2021-12-11 15:47:43,481 DEBUG] SSH connection with gpu2 established successfully!
[2021-12-11 15:47:43,481 DEBUG] Running cmd on gpu2: source /u5/p3basta/CS848/CS848-Project/venv/bin/activate && python /u5/p3basta/CS848/CS848-Project/models/MNIST/train.py --arch "alexnet" --parallelism "dp" --epochs "1" --batch-size "256" --lr "0.5" --gamma "0.9"
[2021-12-11 15:47:43,481 INFO] Training {'batch-size': 256, 'lr': 0.5, 'gamma': 0.9} on gpu2...
[2021-12-11 15:48:40,882 DEBUG] Received output from gpu3: ['Train Epoch: 1 [0/60000 (0%)]\tLoss: 0.000093\n', 'Train Epoch: 1 [2560/60000 (4%)]\tLoss: -452832394215424.000000\n', 'Train Epoch: 1 [5120/60000 (9%)]\tLoss: -19132756580302222310506496.000000\n', 'Train Epoch: 1 [7680/60000 (13%)]\tLoss: -1169557221134376018676547584.000000\n', 'Train Epoch: 1 [10240/60000 (17%)]\tLoss: -3591433792346565202575097856.000000\n', 'Train Epoch: 1 [12800/60000 (21%)]\tLoss: -5822084035793051690601545728.000000\n', 'Train Epoch: 1 [15360/60000 (26%)]\tLoss: -7883406450298617565670277120.000000\n', 'Train Epoch: 1 [17920/60000 (30%)]\tLoss: -10199027119315093118085234688.000000\n', 'Train Epoch: 1 [20480/60000 (34%)]\tLoss: -12657687088506069506611740672.000000\n', 'Train Epoch: 1 [23040/60000 (38%)]\tLoss: -15194816260359649354831626240.000000\n', 'Train Epoch: 1 [25600/60000 (43%)]\tLoss: -17203480746806356533533736960.000000\n', 'Train Epoch: 1 [28160/60000 (47%)]\tLoss: -19168536539967003973509971968.000000\n', 'Train Epoch: 1 [30720/60000 (51%)]\tLoss: -21422406364261855327699337216.000000\n', 'Train Epoch: 1 [33280/60000 (55%)]\tLoss: -23885108679162168132528766976.000000\n', 'Train Epoch: 1 [35840/60000 (60%)]\tLoss: -25868365653339415902569889792.000000\n', 'Train Epoch: 1 [38400/60000 (64%)]\tLoss: -28806071923285654840864145408.000000\n', 'Train Epoch: 1 [40960/60000 (68%)]\tLoss: -30598141529220683589606178816.000000\n', 'Train Epoch: 1 [43520/60000 (72%)]\tLoss: -33545625458969704128315392000.000000\n', 'Train Epoch: 1 [46080/60000 (77%)]\tLoss: -36187503802963057011842875392.000000\n', 'Train Epoch: 1 [48640/60000 (81%)]\tLoss: -37042875488738201588690059264.000000\n', 'Train Epoch: 1 [51200/60000 (85%)]\tLoss: -39710511980712366952035647488.000000\n', 'Train Epoch: 1 [53760/60000 (89%)]\tLoss: -42172446911059213439517851648.000000\n', 'Train Epoch: 1 [56320/60000 (94%)]\tLoss: -43423250676643930627979083776.000000\n', 'Train Epoch: 1 [58880/60000 (98%)]\tLoss: -47415761252486623564962725888.000000\n', 'Train Epoch: 1 [0/60000 (0%)]\tLoss: 0.001896\n', 'Train Epoch: 1 [2560/60000 (4%)]\tLoss: -452203181506560.000000\n', 'Train Epoch: 1 [5120/60000 (9%)]\tLoss: -18854101217246270430642176.000000\n', 'Train Epoch: 1 [7680/60000 (13%)]\tLoss: -1150216400268901912512823296.000000\n', 'Train Epoch: 1 [10240/60000 (17%)]\tLoss: -3552608856307652414450696192.000000\n', 'Train Epoch: 1 [12800/60000 (21%)]\tLoss: -5908153887309833844266369024.000000\n', 'Train Epoch: 1 [15360/60000 (26%)]\tLoss: -8034620757150776116352385024.000000\n', 'Train Epoch: 1 [17920/60000 (30%)]\tLoss: -10093130412119982758990708736.000000\n', 'Train Epoch: 1 [20480/60000 (34%)]\tLoss: -12436969582054845876380106752.000000\n', 'Train Epoch: 1 [23040/60000 (38%)]\tLoss: -15044232979728764260491198464.000000\n', 'Train Epoch: 1 [25600/60000 (43%)]\tLoss: -17286911976050835272935407616.000000\n', 'Train Epoch: 1 [28160/60000 (47%)]\tLoss: -19531488183107399165344219136.000000\n', 'Train Epoch: 1 [30720/60000 (51%)]\tLoss: -21741867373278262521938051072.000000\n', 'Train Epoch: 1 [33280/60000 (55%)]\tLoss: -24408587726154751174112182272.000000\n', 'Train Epoch: 1 [35840/60000 (60%)]\tLoss: -26013384805661859837437280256.000000\n', 'Train Epoch: 1 [38400/60000 (64%)]\tLoss: -28260402476190067336421572608.000000\n', 'Train Epoch: 1 [40960/60000 (68%)]\tLoss: -30892023840182627350544908288.000000\n', 'Train Epoch: 1 [43520/60000 (72%)]\tLoss: -33335706824073182659276177408.000000\n', 'Train Epoch: 1 [46080/60000 (77%)]\tLoss: -35345427940020431921094852608.000000\n', 'Train Epoch: 1 [48640/60000 (81%)]\tLoss: -37049668612923809573329960960.000000\n', 'Train Epoch: 1 [51200/60000 (85%)]\tLoss: -39338901878625630265702088704.000000\n', 'Train Epoch: 1 [53760/60000 (89%)]\tLoss: -42600161088145682945812725760.000000\n', 'Train Epoch: 1 [56320/60000 (94%)]\tLoss: -44078247630184433288763932672.000000\n', 'Train Epoch: 1 [58880/60000 (98%)]\tLoss: -46712067255774769122734243840.000000\n', '\n', 'Test set: Average loss: -48217253879899356248703762432.0000, Accuracy: 958/10000 (10%)\n', '\n', '\n', 'Test set: Average loss: -48217251462047716526864203776.0000, Accuracy: 958/10000 (10%)\n', '\n', '{"accuracy": 9.58, "runtime": 61.64756123162806, "mem_params": 244341408, "mem_bufs": 0, "mem_peak": 3343360512}\n']
[2021-12-11 15:48:40,883 DEBUG] Received error from gpu3: []
[2021-12-11 15:48:40,883 DEBUG] SSH connection with gpu3 has been closed
[2021-12-11 15:48:40,883 INFO] {'batch-size': 256, 'lr': 0.5, 'gamma': 0.5} => {"accuracy": 9.58, "runtime": 61.64756123162806, "mem_params": 244341408, "mem_bufs": 0, "mem_peak": 3343360512}
[2021-12-11 15:48:40,884 DEBUG] gpu3 finished training {'batch-size': 256, 'lr': 0.5, 'gamma': 0.5}
[2021-12-11 15:48:40,884 DEBUG] gpu3 now training {'batch-size': 256, 'lr': 0.9, 'gamma': 0.5}...
[2021-12-11 15:48:40,884 DEBUG] Attempting to establish SSH connection with gpu3...
[2021-12-11 15:48:40,974 DEBUG] SSH connection with gpu3 established successfully!
[2021-12-11 15:48:40,974 DEBUG] Running cmd on gpu3: source /u5/p3basta/CS848/CS848-Project/venv/bin/activate && python /u5/p3basta/CS848/CS848-Project/models/MNIST/train.py --arch "alexnet" --parallelism "dp" --epochs "1" --batch-size "256" --lr "0.9" --gamma "0.5"
[2021-12-11 15:48:40,975 INFO] Training {'batch-size': 256, 'lr': 0.9, 'gamma': 0.5} on gpu3...
[2021-12-11 15:48:44,145 DEBUG] Received output from gpu1: ['Train Epoch: 1 [0/60000 (0%)]\tLoss: 0.003255\n', 'Train Epoch: 1 [2560/60000 (4%)]\tLoss: -291180998819840.000000\n', 'Train Epoch: 1 [5120/60000 (9%)]\tLoss: -17233479810473086876123136.000000\n', 'Train Epoch: 1 [7680/60000 (13%)]\tLoss: -1080082100661587081783410688.000000\n', 'Train Epoch: 1 [10240/60000 (17%)]\tLoss: -3541831235402123166661738496.000000\n', 'Train Epoch: 1 [12800/60000 (21%)]\tLoss: -5808337226961418153384476672.000000\n', 'Train Epoch: 1 [15360/60000 (26%)]\tLoss: -8187376916659591606196764672.000000\n', 'Train Epoch: 1 [17920/60000 (30%)]\tLoss: -10313628328529752950719905792.000000\n', 'Train Epoch: 1 [20480/60000 (34%)]\tLoss: -12637181392645828789682569216.000000\n', 'Train Epoch: 1 [23040/60000 (38%)]\tLoss: -14875539423636074076756246528.000000\n', 'Train Epoch: 1 [25600/60000 (43%)]\tLoss: -17139524556937232210993348608.000000\n', 'Train Epoch: 1 [28160/60000 (47%)]\tLoss: -19506979101061305706685136896.000000\n', 'Train Epoch: 1 [30720/60000 (51%)]\tLoss: -21237872810393999636506345472.000000\n', 'Train Epoch: 1 [33280/60000 (55%)]\tLoss: -24158930377304881640599715840.000000\n', 'Train Epoch: 1 [35840/60000 (60%)]\tLoss: -26218387457049714005809037312.000000\n', 'Train Epoch: 1 [38400/60000 (64%)]\tLoss: -28725366680093412604162080768.000000\n', 'Train Epoch: 1 [40960/60000 (68%)]\tLoss: -30028140088822110238200037376.000000\n', 'Train Epoch: 1 [43520/60000 (72%)]\tLoss: -33132588396911993479344685056.000000\n', 'Train Epoch: 1 [46080/60000 (77%)]\tLoss: -35648908460858808235930419200.000000\n', 'Train Epoch: 1 [48640/60000 (81%)]\tLoss: -36885972501161616191642402816.000000\n', 'Train Epoch: 1 [51200/60000 (85%)]\tLoss: -40567805669646039474484805632.000000\n', 'Train Epoch: 1 [53760/60000 (89%)]\tLoss: -42344709395621332357623054336.000000\n', 'Train Epoch: 1 [56320/60000 (94%)]\tLoss: -43989962988787185271493885952.000000\n', 'Train Epoch: 1 [58880/60000 (98%)]\tLoss: -46407238499305533524190167040.000000\n', 'Train Epoch: 1 [0/60000 (0%)]\tLoss: 0.003152\n', 'Train Epoch: 1 [2560/60000 (4%)]\tLoss: -284806529155072.000000\n', 'Train Epoch: 1 [5120/60000 (9%)]\tLoss: -17205727836935695462563840.000000\n', 'Train Epoch: 1 [7680/60000 (13%)]\tLoss: -1082922899248938352732274688.000000\n', 'Train Epoch: 1 [10240/60000 (17%)]\tLoss: -3502731516663488401056464896.000000\n', 'Train Epoch: 1 [12800/60000 (21%)]\tLoss: -5700306010116050714653360128.000000\n', 'Train Epoch: 1 [15360/60000 (26%)]\tLoss: -7842474748512534557074915328.000000\n', 'Train Epoch: 1 [17920/60000 (30%)]\tLoss: -10142384694536313158569558016.000000\n', 'Train Epoch: 1 [20480/60000 (34%)]\tLoss: -12582954458323036653693698048.000000\n', 'Train Epoch: 1 [23040/60000 (38%)]\tLoss: -14848357482160676398906212352.000000\n', 'Train Epoch: 1 [25600/60000 (43%)]\tLoss: -17084533779835835909891162112.000000\n', 'Train Epoch: 1 [28160/60000 (47%)]\tLoss: -19653592052071718146812149760.000000\n', 'Train Epoch: 1 [30720/60000 (51%)]\tLoss: -21284444788648060077603815424.000000\n', 'Train Epoch: 1 [33280/60000 (55%)]\tLoss: -23725792562312836346776911872.000000\n', 'Train Epoch: 1 [35840/60000 (60%)]\tLoss: -25928842639702286013999087616.000000\n', 'Train Epoch: 1 [38400/60000 (64%)]\tLoss: -28284729747126570313739927552.000000\n', 'Train Epoch: 1 [40960/60000 (68%)]\tLoss: -30869864135461761540379639808.000000\n', 'Train Epoch: 1 [43520/60000 (72%)]\tLoss: -32687292849409800283919220736.000000\n', 'Train Epoch: 1 [46080/60000 (77%)]\tLoss: -34885360830159822475440947200.000000\n', 'Train Epoch: 1 [48640/60000 (81%)]\tLoss: -37343938157937348645176213504.000000\n', 'Train Epoch: 1 [51200/60000 (85%)]\tLoss: -39848230354452294415402663936.000000\n', 'Train Epoch: 1 [53760/60000 (89%)]\tLoss: -42113148155133819304569470976.000000\n', 'Train Epoch: 1 [56320/60000 (94%)]\tLoss: -44283901968146923468175179776.000000\n', 'Train Epoch: 1 [58880/60000 (98%)]\tLoss: -47194806447119635735059103744.000000\n', '\n', 'Test set: Average loss: -48082051968366606565584666624.0000, Accuracy: 1135/10000 (11%)\n', '\n', '\n', 'Test set: Average loss: -48082051484796282139653963776.0000, Accuracy: 1135/10000 (11%)\n', '\n', '{"accuracy": 11.35, "runtime": 61.129784691147506, "mem_params": 244341408, "mem_bufs": 0, "mem_peak": 3343360512}\n']
[2021-12-11 15:48:44,145 DEBUG] Received error from gpu1: []
[2021-12-11 15:48:44,145 DEBUG] SSH connection with gpu1 has been closed
[2021-12-11 15:48:44,145 INFO] {'batch-size': 256, 'lr': 0.5, 'gamma': 0.7} => {"accuracy": 11.35, "runtime": 61.129784691147506, "mem_params": 244341408, "mem_bufs": 0, "mem_peak": 3343360512}
[2021-12-11 15:48:44,146 DEBUG] gpu1 finished training {'batch-size': 256, 'lr': 0.5, 'gamma': 0.7}
[2021-12-11 15:48:44,146 DEBUG] gpu1 now training {'batch-size': 256, 'lr': 0.9, 'gamma': 0.7}...
[2021-12-11 15:48:44,146 DEBUG] Attempting to establish SSH connection with gpu1...
[2021-12-11 15:48:44,249 DEBUG] SSH connection with gpu1 established successfully!
[2021-12-11 15:48:44,249 DEBUG] Running cmd on gpu1: source /u5/p3basta/CS848/CS848-Project/venv/bin/activate && python /u5/p3basta/CS848/CS848-Project/models/MNIST/train.py --arch "alexnet" --parallelism "dp" --epochs "1" --batch-size "256" --lr "0.9" --gamma "0.7"
[2021-12-11 15:48:44,250 INFO] Training {'batch-size': 256, 'lr': 0.9, 'gamma': 0.7} on gpu1...
[2021-12-11 15:48:48,926 DEBUG] Received output from gpu2: ['Train Epoch: 1 [0/60000 (0%)]\tLoss: 0.003262\n', 'Train Epoch: 1 [2560/60000 (4%)]\tLoss: -175679597445120.000000\n', 'Train Epoch: 1 [5120/60000 (9%)]\tLoss: -15230857462814002892505088.000000\n', 'Train Epoch: 1 [7680/60000 (13%)]\tLoss: -983514576027338296484954112.000000\n', 'Train Epoch: 1 [10240/60000 (17%)]\tLoss: -3454259966491693645171785728.000000\n', 'Train Epoch: 1 [12800/60000 (21%)]\tLoss: -5912679685287854040498044928.000000\n', 'Train Epoch: 1 [15360/60000 (26%)]\tLoss: -8345923878068025998484439040.000000\n', 'Train Epoch: 1 [17920/60000 (30%)]\tLoss: -10516542513340558018495905792.000000\n', 'Train Epoch: 1 [20480/60000 (34%)]\tLoss: -12976260292623697207550279680.000000\n', 'Train Epoch: 1 [23040/60000 (38%)]\tLoss: -15367801266993647328654524416.000000\n', 'Train Epoch: 1 [25600/60000 (43%)]\tLoss: -17451504156853153169802264576.000000\n', 'Train Epoch: 1 [28160/60000 (47%)]\tLoss: -20367989292416996639917473792.000000\n', 'Train Epoch: 1 [30720/60000 (51%)]\tLoss: -22378239313410327302000082944.000000\n', 'Train Epoch: 1 [33280/60000 (55%)]\tLoss: -24434251426805906261026013184.000000\n', 'Train Epoch: 1 [35840/60000 (60%)]\tLoss: -26591402463165104411593670656.000000\n', 'Train Epoch: 1 [38400/60000 (64%)]\tLoss: -29461177491255263503488909312.000000\n', 'Train Epoch: 1 [40960/60000 (68%)]\tLoss: -31897477055149852121928564736.000000\n', 'Train Epoch: 1 [43520/60000 (72%)]\tLoss: -34387082691903073295540420608.000000\n', 'Train Epoch: 1 [46080/60000 (77%)]\tLoss: -36602668291121300435982352384.000000\n', 'Train Epoch: 1 [48640/60000 (81%)]\tLoss: -38586288887517729168704929792.000000\n', 'Train Epoch: 1 [51200/60000 (85%)]\tLoss: -40455488905217467832722259968.000000\n', 'Train Epoch: 1 [53760/60000 (89%)]\tLoss: -43711721155616505775502917632.000000\n', 'Train Epoch: 1 [56320/60000 (94%)]\tLoss: -45242122073552486048131448832.000000\n', 'Train Epoch: 1 [58880/60000 (98%)]\tLoss: -48995425897571899976460533760.000000\n', 'Train Epoch: 1 [0/60000 (0%)]\tLoss: 0.002888\n', 'Train Epoch: 1 [2560/60000 (4%)]\tLoss: -172471206543360.000000\n', 'Train Epoch: 1 [5120/60000 (9%)]\tLoss: -15525156817765965078986752.000000\n', 'Train Epoch: 1 [7680/60000 (13%)]\tLoss: -1001179694661156626979880960.000000\n', 'Train Epoch: 1 [10240/60000 (17%)]\tLoss: -3522963610415627857916067840.000000\n', 'Train Epoch: 1 [12800/60000 (21%)]\tLoss: -5889371855215840547840196608.000000\n', 'Train Epoch: 1 [15360/60000 (26%)]\tLoss: -8133004179271640869911920640.000000\n', 'Train Epoch: 1 [17920/60000 (30%)]\tLoss: -10538205188989101798502432768.000000\n', 'Train Epoch: 1 [20480/60000 (34%)]\tLoss: -13101075980540804082782175232.000000\n', 'Train Epoch: 1 [23040/60000 (38%)]\tLoss: -15674016038025605168068820992.000000\n', 'Train Epoch: 1 [25600/60000 (43%)]\tLoss: -17898410031326004914245599232.000000\n', 'Train Epoch: 1 [28160/60000 (47%)]\tLoss: -20008286637416815763990249472.000000\n', 'Train Epoch: 1 [30720/60000 (51%)]\tLoss: -22372400107254258985693347840.000000\n', 'Train Epoch: 1 [33280/60000 (55%)]\tLoss: -24863764825522349102147305472.000000\n', 'Train Epoch: 1 [35840/60000 (60%)]\tLoss: -27078875826909047843245260800.000000\n', 'Train Epoch: 1 [38400/60000 (64%)]\tLoss: -29367004058853877038637383680.000000\n', 'Train Epoch: 1 [40960/60000 (68%)]\tLoss: -32287851480456271343518744576.000000\n', 'Train Epoch: 1 [43520/60000 (72%)]\tLoss: -34632411991871392799214534656.000000\n', 'Train Epoch: 1 [46080/60000 (77%)]\tLoss: -37290915427067688268716834816.000000\n', 'Train Epoch: 1 [48640/60000 (81%)]\tLoss: -39314562801772920114270699520.000000\n', 'Train Epoch: 1 [51200/60000 (85%)]\tLoss: -41689079644972125164379570176.000000\n', 'Train Epoch: 1 [53760/60000 (89%)]\tLoss: -44546630827421376179639156736.000000\n', 'Train Epoch: 1 [56320/60000 (94%)]\tLoss: -45907966302904140283972157440.000000\n', 'Train Epoch: 1 [58880/60000 (98%)]\tLoss: -48187122038531517153458257920.000000\n', '\n', 'Test set: Average loss: -49943112994988910525594730496.0000, Accuracy: 1010/10000 (10%)\n', '\n', '\n', 'Test set: Average loss: -49943112027848252877640302592.0000, Accuracy: 1010/10000 (10%)\n', '\n', '{"accuracy": 10.1, "runtime": 62.70460104569793, "mem_params": 244341408, "mem_bufs": 0, "mem_peak": 3343360512}\n']
[2021-12-11 15:48:48,926 DEBUG] Received error from gpu2: []
[2021-12-11 15:48:48,926 DEBUG] SSH connection with gpu2 has been closed
[2021-12-11 15:48:48,926 INFO] {'batch-size': 256, 'lr': 0.5, 'gamma': 0.9} => {"accuracy": 10.1, "runtime": 62.70460104569793, "mem_params": 244341408, "mem_bufs": 0, "mem_peak": 3343360512}
[2021-12-11 15:48:48,927 DEBUG] gpu2 finished training {'batch-size': 256, 'lr': 0.5, 'gamma': 0.9}
[2021-12-11 15:48:48,927 DEBUG] gpu2 now training {'batch-size': 256, 'lr': 0.9, 'gamma': 0.9}...
[2021-12-11 15:48:48,927 DEBUG] Attempting to establish SSH connection with gpu2...
[2021-12-11 15:48:49,021 DEBUG] SSH connection with gpu2 established successfully!
[2021-12-11 15:48:49,021 DEBUG] Running cmd on gpu2: source /u5/p3basta/CS848/CS848-Project/venv/bin/activate && python /u5/p3basta/CS848/CS848-Project/models/MNIST/train.py --arch "alexnet" --parallelism "dp" --epochs "1" --batch-size "256" --lr "0.9" --gamma "0.9"
[2021-12-11 15:48:49,021 INFO] Training {'batch-size': 256, 'lr': 0.9, 'gamma': 0.9} on gpu2...
[2021-12-11 15:49:44,094 DEBUG] Received output from gpu3: ['Train Epoch: 1 [0/60000 (0%)]\tLoss: 0.007028\n', 'Train Epoch: 1 [2560/60000 (4%)]\tLoss: -169559175632781312.000000\n', 'Train Epoch: 1 [5120/60000 (9%)]\tLoss: -56261568688948133685624832.000000\n', 'Train Epoch: 1 [7680/60000 (13%)]\tLoss: -1733469760249099321285279744.000000\n', 'Train Epoch: 1 [10240/60000 (17%)]\tLoss: -4992178301572592034274869248.000000\n', 'Train Epoch: 1 [12800/60000 (21%)]\tLoss: -8125662079982399289015926784.000000\n', 'Train Epoch: 1 [15360/60000 (26%)]\tLoss: -11304371371902838777262899200.000000\n', 'Train Epoch: 1 [17920/60000 (30%)]\tLoss: -14585008812285347046507937792.000000\n', 'Train Epoch: 1 [20480/60000 (34%)]\tLoss: -17579690433847408254305435648.000000\n', 'Train Epoch: 1 [23040/60000 (38%)]\tLoss: -20348736204266337096381235200.000000\n', 'Train Epoch: 1 [25600/60000 (43%)]\tLoss: -23941739298024740917931409408.000000\n', 'Train Epoch: 1 [28160/60000 (47%)]\tLoss: -26343981154844873655089889280.000000\n', 'Train Epoch: 1 [30720/60000 (51%)]\tLoss: -29887361621601283244734545920.000000\n', 'Train Epoch: 1 [33280/60000 (55%)]\tLoss: -32993970412357079348564459520.000000\n', 'Train Epoch: 1 [35840/60000 (60%)]\tLoss: -35988057015742298981065031680.000000\n', 'Train Epoch: 1 [38400/60000 (64%)]\tLoss: -38913929035282466588453765120.000000\n', 'Train Epoch: 1 [40960/60000 (68%)]\tLoss: -42095533728152715527922384896.000000\n', 'Train Epoch: 1 [43520/60000 (72%)]\tLoss: -44097387381539503960815042560.000000\n', 'Train Epoch: 1 [46080/60000 (77%)]\tLoss: -49815157883500827340879953920.000000\n', 'Train Epoch: 1 [48640/60000 (81%)]\tLoss: -51397613447177479712699056128.000000\n', 'Train Epoch: 1 [51200/60000 (85%)]\tLoss: -54883126035052804669895081984.000000\n', 'Train Epoch: 1 [53760/60000 (89%)]\tLoss: -57250113064895074070710714368.000000\n', 'Train Epoch: 1 [56320/60000 (94%)]\tLoss: -60401338774181022582519627776.000000\n', 'Train Epoch: 1 [58880/60000 (98%)]\tLoss: -66150173002866662488800231424.000000\n', 'Train Epoch: 1 [0/60000 (0%)]\tLoss: 0.006393\n', 'Train Epoch: 1 [2560/60000 (4%)]\tLoss: -172482021136793600.000000\n', 'Train Epoch: 1 [5120/60000 (9%)]\tLoss: -57423054094491200320962560.000000\n', 'Train Epoch: 1 [7680/60000 (13%)]\tLoss: -1682559845658665342029791232.000000\n', 'Train Epoch: 1 [10240/60000 (17%)]\tLoss: -5108579322713035560441610240.000000\n', 'Train Epoch: 1 [12800/60000 (21%)]\tLoss: -8292005078158241106845761536.000000\n', 'Train Epoch: 1 [15360/60000 (26%)]\tLoss: -11455295843512111203470016512.000000\n', 'Train Epoch: 1 [17920/60000 (30%)]\tLoss: -14496722990296478311826587648.000000\n', 'Train Epoch: 1 [20480/60000 (34%)]\tLoss: -17550028069376883295306907648.000000\n', 'Train Epoch: 1 [23040/60000 (38%)]\tLoss: -20484216176293384347916959744.000000\n', 'Train Epoch: 1 [25600/60000 (43%)]\tLoss: -23644945648126108020718436352.000000\n', 'Train Epoch: 1 [28160/60000 (47%)]\tLoss: -26749913416529106922836590592.000000\n', 'Train Epoch: 1 [30720/60000 (51%)]\tLoss: -29889892810036101374569086976.000000\n', 'Train Epoch: 1 [33280/60000 (55%)]\tLoss: -32564338954478564766312824832.000000\n', 'Train Epoch: 1 [35840/60000 (60%)]\tLoss: -35895035840762732709645647872.000000\n', 'Train Epoch: 1 [38400/60000 (64%)]\tLoss: -40093916193090070577290412032.000000\n', 'Train Epoch: 1 [40960/60000 (68%)]\tLoss: -42227188583328638366835015680.000000\n', 'Train Epoch: 1 [43520/60000 (72%)]\tLoss: -45575950882593024137932832768.000000\n', 'Train Epoch: 1 [46080/60000 (77%)]\tLoss: -48201152189352122869388148736.000000\n', 'Train Epoch: 1 [48640/60000 (81%)]\tLoss: -51825733747781476008482308096.000000\n', 'Train Epoch: 1 [51200/60000 (85%)]\tLoss: -54658638899556630345371615232.000000\n', 'Train Epoch: 1 [53760/60000 (89%)]\tLoss: -58130900527081023078098010112.000000\n', 'Train Epoch: 1 [56320/60000 (94%)]\tLoss: -61345117882881969787412414464.000000\n', 'Train Epoch: 1 [58880/60000 (98%)]\tLoss: -65205572202397695965640261632.000000\n', '\n', 'Test set: Average loss: -66441515149119573343600640000.0000, Accuracy: 958/10000 (10%)\n', '\n', '\n', 'Test set: Average loss: -66441520468393186009303482368.0000, Accuracy: 958/10000 (10%)\n', '\n', '{"accuracy": 9.58, "runtime": 61.56561255082488, "mem_params": 244341408, "mem_bufs": 0, "mem_peak": 3343360512}\n']
[2021-12-11 15:49:44,094 DEBUG] Received error from gpu3: []
[2021-12-11 15:49:44,094 DEBUG] SSH connection with gpu3 has been closed
[2021-12-11 15:49:44,094 INFO] {'batch-size': 256, 'lr': 0.9, 'gamma': 0.5} => {"accuracy": 9.58, "runtime": 61.56561255082488, "mem_params": 244341408, "mem_bufs": 0, "mem_peak": 3343360512}
[2021-12-11 15:49:44,095 DEBUG] gpu3 finished training {'batch-size': 256, 'lr': 0.9, 'gamma': 0.5}
[2021-12-11 15:49:44,095 DEBUG] gpu3 now training {'batch-size': 256, 'lr': 0.99, 'gamma': 0.5}...
[2021-12-11 15:49:44,095 DEBUG] Attempting to establish SSH connection with gpu3...
[2021-12-11 15:49:44,191 DEBUG] SSH connection with gpu3 established successfully!
[2021-12-11 15:49:44,192 DEBUG] Running cmd on gpu3: source /u5/p3basta/CS848/CS848-Project/venv/bin/activate && python /u5/p3basta/CS848/CS848-Project/models/MNIST/train.py --arch "alexnet" --parallelism "dp" --epochs "1" --batch-size "256" --lr "0.99" --gamma "0.5"
[2021-12-11 15:49:44,192 INFO] Training {'batch-size': 256, 'lr': 0.99, 'gamma': 0.5} on gpu3...
[2021-12-11 15:49:51,100 DEBUG] Received output from gpu1: ['Train Epoch: 1 [0/60000 (0%)]\tLoss: 0.006581\n', 'Train Epoch: 1 [2560/60000 (4%)]\tLoss: -130981873869389824.000000\n', 'Train Epoch: 1 [5120/60000 (9%)]\tLoss: -64192884654020108224561152.000000\n', 'Train Epoch: 1 [7680/60000 (13%)]\tLoss: -1939341917365611863082008576.000000\n', 'Train Epoch: 1 [10240/60000 (17%)]\tLoss: -5132098478685157469722771456.000000\n', 'Train Epoch: 1 [12800/60000 (21%)]\tLoss: -8122579555260706128102686720.000000\n', 'Train Epoch: 1 [15360/60000 (26%)]\tLoss: -11086010326326567099992899584.000000\n', 'Train Epoch: 1 [17920/60000 (30%)]\tLoss: -14212912306450874786717368320.000000\n', 'Train Epoch: 1 [20480/60000 (34%)]\tLoss: -17414885746553361223403962368.000000\n', 'Train Epoch: 1 [23040/60000 (38%)]\tLoss: -20311871050317815211020517376.000000\n', 'Train Epoch: 1 [25600/60000 (43%)]\tLoss: -23363582330710251689241214976.000000\n', 'Train Epoch: 1 [28160/60000 (47%)]\tLoss: -25856113473499610608062955520.000000\n', 'Train Epoch: 1 [30720/60000 (51%)]\tLoss: -29000737314442507355863121920.000000\n', 'Train Epoch: 1 [33280/60000 (55%)]\tLoss: -32947769139871924174616264704.000000\n', 'Train Epoch: 1 [35840/60000 (60%)]\tLoss: -35484997481421644285385637888.000000\n', 'Train Epoch: 1 [38400/60000 (64%)]\tLoss: -38810053500942024437510701056.000000\n', 'Train Epoch: 1 [40960/60000 (68%)]\tLoss: -41849781776384179191001645056.000000\n', 'Train Epoch: 1 [43520/60000 (72%)]\tLoss: -44165483906222484244796538880.000000\n', 'Train Epoch: 1 [46080/60000 (77%)]\tLoss: -45363902460412728458902241280.000000\n', 'Train Epoch: 1 [48640/60000 (81%)]\tLoss: -50550723131605569018655670272.000000\n', 'Train Epoch: 1 [51200/60000 (85%)]\tLoss: -53714732286960645660058058752.000000\n', 'Train Epoch: 1 [53760/60000 (89%)]\tLoss: -56929525771472502466088534016.000000\n', 'Train Epoch: 1 [56320/60000 (94%)]\tLoss: -59768069428828203159362994176.000000\n', 'Train Epoch: 1 [58880/60000 (98%)]\tLoss: -62101570157940443905968308224.000000\n', 'Train Epoch: 1 [0/60000 (0%)]\tLoss: 0.007286\n', 'Train Epoch: 1 [2560/60000 (4%)]\tLoss: -135004832296599552.000000\n', 'Train Epoch: 1 [5120/60000 (9%)]\tLoss: -62929121275960358980288512.000000\n', 'Train Epoch: 1 [7680/60000 (13%)]\tLoss: -1921630829445561848384454656.000000\n', 'Train Epoch: 1 [10240/60000 (17%)]\tLoss: -5053999391495648918473015296.000000\n', 'Train Epoch: 1 [12800/60000 (21%)]\tLoss: -8197256107341754903983816704.000000\n', 'Train Epoch: 1 [15360/60000 (26%)]\tLoss: -11132395771104554190104428544.000000\n', 'Train Epoch: 1 [17920/60000 (30%)]\tLoss: -14362163879733590641107533824.000000\n', 'Train Epoch: 1 [20480/60000 (34%)]\tLoss: -17027793365952536405237301248.000000\n', 'Train Epoch: 1 [23040/60000 (38%)]\tLoss: -20209079299085191643653996544.000000\n', 'Train Epoch: 1 [25600/60000 (43%)]\tLoss: -23053063122629158168214634496.000000\n', 'Train Epoch: 1 [28160/60000 (47%)]\tLoss: -26537241641973072450637791232.000000\n', 'Train Epoch: 1 [30720/60000 (51%)]\tLoss: -29130285994167070333010444288.000000\n', 'Train Epoch: 1 [33280/60000 (55%)]\tLoss: -32437713419606898099552780288.000000\n', 'Train Epoch: 1 [35840/60000 (60%)]\tLoss: -35442342706165124214992928768.000000\n', 'Train Epoch: 1 [38400/60000 (64%)]\tLoss: -37724752152299198270031265792.000000\n', 'Train Epoch: 1 [40960/60000 (68%)]\tLoss: -41784428946627746170889306112.000000\n', 'Train Epoch: 1 [43520/60000 (72%)]\tLoss: -43918556085199713366217588736.000000\n', 'Train Epoch: 1 [46080/60000 (77%)]\tLoss: -47254147704343375696814407680.000000\n', 'Train Epoch: 1 [48640/60000 (81%)]\tLoss: -50360680937235445886320902144.000000\n', 'Train Epoch: 1 [51200/60000 (85%)]\tLoss: -52940358631099681237916188672.000000\n', 'Train Epoch: 1 [53760/60000 (89%)]\tLoss: -57390117064012710442361159680.000000\n', 'Train Epoch: 1 [56320/60000 (94%)]\tLoss: -58872014555803136588999819264.000000\n', 'Train Epoch: 1 [58880/60000 (98%)]\tLoss: -62634016978883996403812532224.000000\n', '\n', 'Test set: Average loss: -64491250871260211007144853504.0000, Accuracy: 980/10000 (10%)\n', '\n', '\n', 'Test set: Average loss: -64491251354830535433075556352.0000, Accuracy: 980/10000 (10%)\n', '\n', '{"accuracy": 9.8, "runtime": 64.12551787868142, "mem_params": 244341408, "mem_bufs": 0, "mem_peak": 3343360512}\n']
[2021-12-11 15:49:51,100 DEBUG] Received error from gpu1: []
[2021-12-11 15:49:51,100 DEBUG] SSH connection with gpu1 has been closed
[2021-12-11 15:49:51,100 INFO] {'batch-size': 256, 'lr': 0.9, 'gamma': 0.7} => {"accuracy": 9.8, "runtime": 64.12551787868142, "mem_params": 244341408, "mem_bufs": 0, "mem_peak": 3343360512}
[2021-12-11 15:49:51,101 DEBUG] gpu1 finished training {'batch-size': 256, 'lr': 0.9, 'gamma': 0.7}
[2021-12-11 15:49:51,101 DEBUG] gpu1 now training {'batch-size': 256, 'lr': 0.99, 'gamma': 0.7}...
[2021-12-11 15:49:51,101 DEBUG] Attempting to establish SSH connection with gpu1...
[2021-12-11 15:49:51,193 DEBUG] SSH connection with gpu1 established successfully!
[2021-12-11 15:49:51,193 DEBUG] Running cmd on gpu1: source /u5/p3basta/CS848/CS848-Project/venv/bin/activate && python /u5/p3basta/CS848/CS848-Project/models/MNIST/train.py --arch "alexnet" --parallelism "dp" --epochs "1" --batch-size "256" --lr "0.99" --gamma "0.7"
[2021-12-11 15:49:51,194 INFO] Training {'batch-size': 256, 'lr': 0.99, 'gamma': 0.7} on gpu1...
[2021-12-11 15:49:54,995 DEBUG] Received output from gpu2: ['Train Epoch: 1 [0/60000 (0%)]\tLoss: -0.005266\n', 'Train Epoch: 1 [2560/60000 (4%)]\tLoss: -163887911836581888.000000\n', 'Train Epoch: 1 [5120/60000 (9%)]\tLoss: -55357775074742752631586816.000000\n', 'Train Epoch: 1 [7680/60000 (13%)]\tLoss: -1620682382485719201441906688.000000\n', 'Train Epoch: 1 [10240/60000 (17%)]\tLoss: -5143779252180535537158848512.000000\n', 'Train Epoch: 1 [12800/60000 (21%)]\tLoss: -8602370809328641364402896896.000000\n', 'Train Epoch: 1 [15360/60000 (26%)]\tLoss: -11888224693787289515492114432.000000\n', 'Train Epoch: 1 [17920/60000 (30%)]\tLoss: -14838675450279172908806832128.000000\n', 'Train Epoch: 1 [20480/60000 (34%)]\tLoss: -18262201075108730185516580864.000000\n', 'Train Epoch: 1 [23040/60000 (38%)]\tLoss: -21715658239298335991002038272.000000\n', 'Train Epoch: 1 [25600/60000 (43%)]\tLoss: -24734863110005939266394259456.000000\n', 'Train Epoch: 1 [28160/60000 (47%)]\tLoss: -27989137939497827741233840128.000000\n', 'Train Epoch: 1 [30720/60000 (51%)]\tLoss: -31568441448089426722019082240.000000\n', 'Train Epoch: 1 [33280/60000 (55%)]\tLoss: -34860254368753646006662332416.000000\n', 'Train Epoch: 1 [35840/60000 (60%)]\tLoss: -38652220207168313720355946496.000000\n', 'Train Epoch: 1 [38400/60000 (64%)]\tLoss: -41041884040861323157487747072.000000\n', 'Train Epoch: 1 [40960/60000 (68%)]\tLoss: -44549195072421574396990193664.000000\n', 'Train Epoch: 1 [43520/60000 (72%)]\tLoss: -47389637121103388687640559616.000000\n', 'Train Epoch: 1 [46080/60000 (77%)]\tLoss: -51764777441220594628063920128.000000\n', 'Train Epoch: 1 [48640/60000 (81%)]\tLoss: -54677849486408944062100930560.000000\n', 'Train Epoch: 1 [51200/60000 (85%)]\tLoss: -56961892871346091014383206400.000000\n', 'Train Epoch: 1 [53760/60000 (89%)]\tLoss: -58645624306614365797455233024.000000\n', 'Train Epoch: 1 [56320/60000 (94%)]\tLoss: -63694013526728365577414377472.000000\n', 'Train Epoch: 1 [58880/60000 (98%)]\tLoss: -67459231881384059620617617408.000000\n', 'Train Epoch: 1 [0/60000 (0%)]\tLoss: -0.006719\n', 'Train Epoch: 1 [2560/60000 (4%)]\tLoss: -167028374743547904.000000\n', 'Train Epoch: 1 [5120/60000 (9%)]\tLoss: -53468782364734710272229376.000000\n', 'Train Epoch: 1 [7680/60000 (13%)]\tLoss: -1630375187265761737919430656.000000\n', 'Train Epoch: 1 [10240/60000 (17%)]\tLoss: -5116548906448688445445373952.000000\n', 'Train Epoch: 1 [12800/60000 (21%)]\tLoss: -8453986970887152807320748032.000000\n', 'Train Epoch: 1 [15360/60000 (26%)]\tLoss: -11521040629686622404135092224.000000\n', 'Train Epoch: 1 [17920/60000 (30%)]\tLoss: -15177564275006105823454691328.000000\n', 'Train Epoch: 1 [20480/60000 (34%)]\tLoss: -18379518825642660781560430592.000000\n', 'Train Epoch: 1 [23040/60000 (38%)]\tLoss: -21279283242082283555385245696.000000\n', 'Train Epoch: 1 [25600/60000 (43%)]\tLoss: -24465862948042235666086494208.000000\n', 'Train Epoch: 1 [28160/60000 (47%)]\tLoss: -27739381420951817945171886080.000000\n', 'Train Epoch: 1 [30720/60000 (51%)]\tLoss: -31842898304524086197371273216.000000\n', 'Train Epoch: 1 [33280/60000 (55%)]\tLoss: -34820508571250573637721260032.000000\n', 'Train Epoch: 1 [35840/60000 (60%)]\tLoss: -38348801077094214710908157952.000000\n', 'Train Epoch: 1 [38400/60000 (64%)]\tLoss: -40318398606219762032168665088.000000\n', 'Train Epoch: 1 [40960/60000 (68%)]\tLoss: -44073770826758672865101348864.000000\n', 'Train Epoch: 1 [43520/60000 (72%)]\tLoss: -48176189760123673924788551680.000000\n', 'Train Epoch: 1 [46080/60000 (77%)]\tLoss: -51639068045446604672475332608.000000\n', 'Train Epoch: 1 [48640/60000 (81%)]\tLoss: -54390162920272525275682570240.000000\n', 'Train Epoch: 1 [51200/60000 (85%)]\tLoss: -57996270581020892362700750848.000000\n', 'Train Epoch: 1 [53760/60000 (89%)]\tLoss: -62190742604236471416538529792.000000\n', 'Train Epoch: 1 [56320/60000 (94%)]\tLoss: -64332524698877170306758213632.000000\n', 'Train Epoch: 1 [58880/60000 (98%)]\tLoss: -65654258409034589566329159680.000000\n', '\n', 'Test set: Average loss: -69449039216108660421761695744.0000, Accuracy: 1009/10000 (10%)\n', '\n', '\n', 'Test set: Average loss: -69449043568241606643417088000.0000, Accuracy: 1009/10000 (10%)\n', '\n', '{"accuracy": 10.09, "runtime": 63.238843688741326, "mem_params": 244341408, "mem_bufs": 0, "mem_peak": 3343360512}\n']
[2021-12-11 15:49:54,995 DEBUG] Received error from gpu2: []
[2021-12-11 15:49:54,995 DEBUG] SSH connection with gpu2 has been closed
[2021-12-11 15:49:54,995 INFO] {'batch-size': 256, 'lr': 0.9, 'gamma': 0.9} => {"accuracy": 10.09, "runtime": 63.238843688741326, "mem_params": 244341408, "mem_bufs": 0, "mem_peak": 3343360512}
[2021-12-11 15:49:54,996 DEBUG] gpu2 finished training {'batch-size': 256, 'lr': 0.9, 'gamma': 0.9}
[2021-12-11 15:49:54,996 DEBUG] gpu2 now training {'batch-size': 256, 'lr': 0.99, 'gamma': 0.9}...
[2021-12-11 15:49:54,996 DEBUG] Attempting to establish SSH connection with gpu2...
[2021-12-11 15:49:55,095 DEBUG] SSH connection with gpu2 established successfully!
[2021-12-11 15:49:55,095 DEBUG] Running cmd on gpu2: source /u5/p3basta/CS848/CS848-Project/venv/bin/activate && python /u5/p3basta/CS848/CS848-Project/models/MNIST/train.py --arch "alexnet" --parallelism "dp" --epochs "1" --batch-size "256" --lr "0.99" --gamma "0.9"
[2021-12-11 15:49:55,095 INFO] Training {'batch-size': 256, 'lr': 0.99, 'gamma': 0.9} on gpu2...
[2021-12-11 15:50:45,965 DEBUG] Received output from gpu3: ['Train Epoch: 1 [0/60000 (0%)]\tLoss: 0.003425\n', 'Train Epoch: 1 [2560/60000 (4%)]\tLoss: -262697379692544000.000000\n', 'Train Epoch: 1 [5120/60000 (9%)]\tLoss: -66690200255032888894947328.000000\n', 'Train Epoch: 1 [7680/60000 (13%)]\tLoss: -1829652707162899409851645952.000000\n', 'Train Epoch: 1 [10240/60000 (17%)]\tLoss: -5040508771045711059508789248.000000\n', 'Train Epoch: 1 [12800/60000 (21%)]\tLoss: -7973012173719448366188855296.000000\n', 'Train Epoch: 1 [15360/60000 (26%)]\tLoss: -11038461998802173359747497984.000000\n', 'Train Epoch: 1 [17920/60000 (30%)]\tLoss: -14035909746531575462228918272.000000\n', 'Train Epoch: 1 [20480/60000 (34%)]\tLoss: -17165780914581987438381498368.000000\n', 'Train Epoch: 1 [23040/60000 (38%)]\tLoss: -20029343669563931511998119936.000000\n', 'Train Epoch: 1 [25600/60000 (43%)]\tLoss: -23038593791725645575279869952.000000\n', 'Train Epoch: 1 [28160/60000 (47%)]\tLoss: -26301371242069940846326710272.000000\n', 'Train Epoch: 1 [30720/60000 (51%)]\tLoss: -29299330185971113587902513152.000000\n', 'Train Epoch: 1 [33280/60000 (55%)]\tLoss: -31712367372571086334019502080.000000\n', 'Train Epoch: 1 [35840/60000 (60%)]\tLoss: -35599219720726053828991909888.000000\n', 'Train Epoch: 1 [38400/60000 (64%)]\tLoss: -37714176412560811699575193600.000000\n', 'Train Epoch: 1 [40960/60000 (68%)]\tLoss: -40189841623456601680516218880.000000\n', 'Train Epoch: 1 [43520/60000 (72%)]\tLoss: -43772082444000545580624379904.000000\n', 'Train Epoch: 1 [46080/60000 (77%)]\tLoss: -46933437629392249481416671232.000000\n', 'Train Epoch: 1 [48640/60000 (81%)]\tLoss: -49652788756720320329497444352.000000\n', 'Train Epoch: 1 [51200/60000 (85%)]\tLoss: -52162518758240290496187465728.000000\n', 'Train Epoch: 1 [53760/60000 (89%)]\tLoss: -55011564958653893280417185792.000000\n', 'Train Epoch: 1 [56320/60000 (94%)]\tLoss: -58344417605237491216790061056.000000\n', 'Train Epoch: 1 [58880/60000 (98%)]\tLoss: -61007133391336506409822978048.000000\n', 'Train Epoch: 1 [0/60000 (0%)]\tLoss: 0.002872\n', 'Train Epoch: 1 [2560/60000 (4%)]\tLoss: -263344373566013440.000000\n', 'Train Epoch: 1 [5120/60000 (9%)]\tLoss: -68037204565725252490887168.000000\n', 'Train Epoch: 1 [7680/60000 (13%)]\tLoss: -1878236118390757140457324544.000000\n', 'Train Epoch: 1 [10240/60000 (17%)]\tLoss: -4944201419289877873726324736.000000\n', 'Train Epoch: 1 [12800/60000 (21%)]\tLoss: -7948728584672911933088727040.000000\n', 'Train Epoch: 1 [15360/60000 (26%)]\tLoss: -11079838193333456473698598912.000000\n', 'Train Epoch: 1 [17920/60000 (30%)]\tLoss: -13958426337872271040973897728.000000\n', 'Train Epoch: 1 [20480/60000 (34%)]\tLoss: -16934309399057648908586975232.000000\n', 'Train Epoch: 1 [23040/60000 (38%)]\tLoss: -19646376276085893328925622272.000000\n', 'Train Epoch: 1 [25600/60000 (43%)]\tLoss: -23463373018043011597074432000.000000\n', 'Train Epoch: 1 [28160/60000 (47%)]\tLoss: -26068808859888059428487823360.000000\n', 'Train Epoch: 1 [30720/60000 (51%)]\tLoss: -29360602891086347234550218752.000000\n', 'Train Epoch: 1 [33280/60000 (55%)]\tLoss: -31565681224880189414391676928.000000\n', 'Train Epoch: 1 [35840/60000 (60%)]\tLoss: -35262149007095025727751323648.000000\n', 'Train Epoch: 1 [38400/60000 (64%)]\tLoss: -38205394612925670759881244672.000000\n', 'Train Epoch: 1 [40960/60000 (68%)]\tLoss: -41586949025047103347342966784.000000\n', 'Train Epoch: 1 [43520/60000 (72%)]\tLoss: -43366643669613772190802509824.000000\n', 'Train Epoch: 1 [46080/60000 (77%)]\tLoss: -45779829610757955330743730176.000000\n', 'Train Epoch: 1 [48640/60000 (81%)]\tLoss: -50091189649157523842910912512.000000\n', 'Train Epoch: 1 [51200/60000 (85%)]\tLoss: -51447217184713542466023718912.000000\n', 'Train Epoch: 1 [53760/60000 (89%)]\tLoss: -54522601688284604475700674560.000000\n', 'Train Epoch: 1 [56320/60000 (94%)]\tLoss: -58550700017942203059014729728.000000\n', 'Train Epoch: 1 [58880/60000 (98%)]\tLoss: -62100252617691723274953687040.000000\n', '\n', 'Test set: Average loss: -63660272981342682258618712064.0000, Accuracy: 1009/10000 (10%)\n', '\n', '\n', 'Test set: Average loss: -63660276849905304054343401472.0000, Accuracy: 1009/10000 (10%)\n', '\n', '{"accuracy": 10.09, "runtime": 60.24541654996574, "mem_params": 244341408, "mem_bufs": 0, "mem_peak": 3343360512}\n']
[2021-12-11 15:50:45,966 DEBUG] Received error from gpu3: []
[2021-12-11 15:50:45,966 DEBUG] SSH connection with gpu3 has been closed
[2021-12-11 15:50:45,966 INFO] {'batch-size': 256, 'lr': 0.99, 'gamma': 0.5} => {"accuracy": 10.09, "runtime": 60.24541654996574, "mem_params": 244341408, "mem_bufs": 0, "mem_peak": 3343360512}
[2021-12-11 15:50:45,967 DEBUG] gpu3 finished training {'batch-size': 256, 'lr': 0.99, 'gamma': 0.5}
[2021-12-11 15:50:57,153 DEBUG] Received output from gpu1: ['Train Epoch: 1 [0/60000 (0%)]\tLoss: -0.004578\n', 'Train Epoch: 1 [2560/60000 (4%)]\tLoss: -427733731424337920.000000\n', 'Train Epoch: 1 [5120/60000 (9%)]\tLoss: -77186448361519826465718272.000000\n', 'Train Epoch: 1 [7680/60000 (13%)]\tLoss: -1882470162664507546420641792.000000\n', 'Train Epoch: 1 [10240/60000 (17%)]\tLoss: -4381876480757114309967872000.000000\n', 'Train Epoch: 1 [12800/60000 (21%)]\tLoss: -7026731391374200966744113152.000000\n', 'Train Epoch: 1 [15360/60000 (26%)]\tLoss: -9358579292217437337524633600.000000\n', 'Train Epoch: 1 [17920/60000 (30%)]\tLoss: -11633862687328861097935503360.000000\n', 'Train Epoch: 1 [20480/60000 (34%)]\tLoss: -14461665322119274783171411968.000000\n', 'Train Epoch: 1 [23040/60000 (38%)]\tLoss: -17228862286060160159146049536.000000\n', 'Train Epoch: 1 [25600/60000 (43%)]\tLoss: -19658166844601998115612917760.000000\n', 'Train Epoch: 1 [28160/60000 (47%)]\tLoss: -22187073195817281194104455168.000000\n', 'Train Epoch: 1 [30720/60000 (51%)]\tLoss: -24826868976191688564092698624.000000\n', 'Train Epoch: 1 [33280/60000 (55%)]\tLoss: -26767327142934688739562094592.000000\n', 'Train Epoch: 1 [35840/60000 (60%)]\tLoss: -29456100947286178634884186112.000000\n', 'Train Epoch: 1 [38400/60000 (64%)]\tLoss: -31987334244585895731054772224.000000\n', 'Train Epoch: 1 [40960/60000 (68%)]\tLoss: -34648083165044795716856184832.000000\n', 'Train Epoch: 1 [43520/60000 (72%)]\tLoss: -36545860583515620038884196352.000000\n', 'Train Epoch: 1 [46080/60000 (77%)]\tLoss: -40250155688175812789185544192.000000\n', 'Train Epoch: 1 [48640/60000 (81%)]\tLoss: -43562177976203472720520806400.000000\n', 'Train Epoch: 1 [51200/60000 (85%)]\tLoss: -45486518706140438796875857920.000000\n', 'Train Epoch: 1 [53760/60000 (89%)]\tLoss: -47968948707022939544585502720.000000\n', 'Train Epoch: 1 [56320/60000 (94%)]\tLoss: -49736946049811540276850720768.000000\n', 'Train Epoch: 1 [58880/60000 (98%)]\tLoss: -52151336194408855176321433600.000000\n', 'Train Epoch: 1 [0/60000 (0%)]\tLoss: -0.005226\n', 'Train Epoch: 1 [2560/60000 (4%)]\tLoss: -434236999105249280.000000\n', 'Train Epoch: 1 [5120/60000 (9%)]\tLoss: -77784367288866992589635584.000000\n', 'Train Epoch: 1 [7680/60000 (13%)]\tLoss: -1912288217655014614034808832.000000\n', 'Train Epoch: 1 [10240/60000 (17%)]\tLoss: -4413459077498736138451419136.000000\n', 'Train Epoch: 1 [12800/60000 (21%)]\tLoss: -6995430365734120240856432640.000000\n', 'Train Epoch: 1 [15360/60000 (26%)]\tLoss: -9564327487213774551134502912.000000\n', 'Train Epoch: 1 [17920/60000 (30%)]\tLoss: -11942560242539187653320900608.000000\n', 'Train Epoch: 1 [20480/60000 (34%)]\tLoss: -14525002881979143182188806144.000000\n', 'Train Epoch: 1 [23040/60000 (38%)]\tLoss: -17185643188008937166150303744.000000\n', 'Train Epoch: 1 [25600/60000 (43%)]\tLoss: -19435079890767994640895311872.000000\n', 'Train Epoch: 1 [28160/60000 (47%)]\tLoss: -22000832506465868126166712320.000000\n', 'Train Epoch: 1 [30720/60000 (51%)]\tLoss: -24380747014554993180754837504.000000\n', 'Train Epoch: 1 [33280/60000 (55%)]\tLoss: -27012073230642373842052317184.000000\n', 'Train Epoch: 1 [35840/60000 (60%)]\tLoss: -29636910915182291610826178560.000000\n', 'Train Epoch: 1 [38400/60000 (64%)]\tLoss: -32028765926923352563337134080.000000\n', 'Train Epoch: 1 [40960/60000 (68%)]\tLoss: -34254688786372581357151846400.000000\n', 'Train Epoch: 1 [43520/60000 (72%)]\tLoss: -36690105267734873351936540672.000000\n', 'Train Epoch: 1 [46080/60000 (77%)]\tLoss: -39948108405564987411672334336.000000\n', 'Train Epoch: 1 [48640/60000 (81%)]\tLoss: -41985299527343089399699079168.000000\n', 'Train Epoch: 1 [51200/60000 (85%)]\tLoss: -45965258053074314819704717312.000000\n', 'Train Epoch: 1 [53760/60000 (89%)]\tLoss: -48207702111663863067299545088.000000\n', 'Train Epoch: 1 [56320/60000 (94%)]\tLoss: -50360501487309096839802781696.000000\n', 'Train Epoch: 1 [58880/60000 (98%)]\tLoss: -51589558755240199312054943744.000000\n', '\n', 'Test set: Average loss: -54094193844674415612896739328.0000, Accuracy: 1010/10000 (10%)\n', '\n', '\n', 'Test set: Average loss: -54094195778955722112712572928.0000, Accuracy: 1010/10000 (10%)\n', '\n', '{"accuracy": 10.1, "runtime": 63.29802916524932, "mem_params": 244341408, "mem_bufs": 0, "mem_peak": 3343360512}\n']
[2021-12-11 15:50:57,153 DEBUG] Received error from gpu1: []
[2021-12-11 15:50:57,154 DEBUG] SSH connection with gpu1 has been closed
[2021-12-11 15:50:57,154 INFO] {'batch-size': 256, 'lr': 0.99, 'gamma': 0.7} => {"accuracy": 10.1, "runtime": 63.29802916524932, "mem_params": 244341408, "mem_bufs": 0, "mem_peak": 3343360512}
[2021-12-11 15:50:57,154 DEBUG] gpu1 finished training {'batch-size': 256, 'lr': 0.99, 'gamma': 0.7}
[2021-12-11 15:50:59,801 DEBUG] Received output from gpu2: ['Train Epoch: 1 [0/60000 (0%)]\tLoss: 0.007331\n', 'Train Epoch: 1 [2560/60000 (4%)]\tLoss: -423544042366697472.000000\n', 'Train Epoch: 1 [5120/60000 (9%)]\tLoss: -83054943335491175113031680.000000\n', 'Train Epoch: 1 [7680/60000 (13%)]\tLoss: -1919463558377829860584194048.000000\n', 'Train Epoch: 1 [10240/60000 (17%)]\tLoss: -4475636410943344501510373376.000000\n', 'Train Epoch: 1 [12800/60000 (21%)]\tLoss: -7029718878470426376047427584.000000\n', 'Train Epoch: 1 [15360/60000 (26%)]\tLoss: -9309340947787986622998380544.000000\n', 'Train Epoch: 1 [17920/60000 (30%)]\tLoss: -11933630247520081154221801472.000000\n', 'Train Epoch: 1 [20480/60000 (34%)]\tLoss: -14584649912432648953471696896.000000\n', 'Train Epoch: 1 [23040/60000 (38%)]\tLoss: -16892554234616115505607475200.000000\n', 'Train Epoch: 1 [25600/60000 (43%)]\tLoss: -19459650363578365404942172160.000000\n', 'Train Epoch: 1 [28160/60000 (47%)]\tLoss: -21929997009222823447961272320.000000\n', 'Train Epoch: 1 [30720/60000 (51%)]\tLoss: -23756502111550937649601576960.000000\n', 'Train Epoch: 1 [33280/60000 (55%)]\tLoss: -26494537281868482248970338304.000000\n', 'Train Epoch: 1 [35840/60000 (60%)]\tLoss: -28809762452692017468598648832.000000\n', 'Train Epoch: 1 [38400/60000 (64%)]\tLoss: -32268284354934500968575795200.000000\n', 'Train Epoch: 1 [40960/60000 (68%)]\tLoss: -34095323084675179440125247488.000000\n', 'Train Epoch: 1 [43520/60000 (72%)]\tLoss: -36341341974692260009146843136.000000\n', 'Train Epoch: 1 [46080/60000 (77%)]\tLoss: -39216120350071019490145992704.000000\n', 'Train Epoch: 1 [48640/60000 (81%)]\tLoss: -42296234303674675449504464896.000000\n', 'Train Epoch: 1 [51200/60000 (85%)]\tLoss: -43924322094675297203023511552.000000\n', 'Train Epoch: 1 [53760/60000 (89%)]\tLoss: -47046472193526217309251698688.000000\n', 'Train Epoch: 1 [56320/60000 (94%)]\tLoss: -49161558750439254095078359040.000000\n', 'Train Epoch: 1 [58880/60000 (98%)]\tLoss: -51864353260878383967039913984.000000\n', 'Train Epoch: 1 [0/60000 (0%)]\tLoss: 0.006352\n', 'Train Epoch: 1 [2560/60000 (4%)]\tLoss: -429911039325241344.000000\n', 'Train Epoch: 1 [5120/60000 (9%)]\tLoss: -82761483307394566711148544.000000\n', 'Train Epoch: 1 [7680/60000 (13%)]\tLoss: -1918133917064996876103712768.000000\n', 'Train Epoch: 1 [10240/60000 (17%)]\tLoss: -4462593529865563720782970880.000000\n', 'Train Epoch: 1 [12800/60000 (21%)]\tLoss: -6847269068813136915804979200.000000\n', 'Train Epoch: 1 [15360/60000 (26%)]\tLoss: -9381286201154505667829039104.000000\n', 'Train Epoch: 1 [17920/60000 (30%)]\tLoss: -11930119168040067573005418496.000000\n', 'Train Epoch: 1 [20480/60000 (34%)]\tLoss: -14346088944225902368800112640.000000\n', 'Train Epoch: 1 [23040/60000 (38%)]\tLoss: -16576849868136831114136256512.000000\n', 'Train Epoch: 1 [25600/60000 (43%)]\tLoss: -19379561389212137656940494848.000000\n', 'Train Epoch: 1 [28160/60000 (47%)]\tLoss: -21340414276203031112676540416.000000\n', 'Train Epoch: 1 [30720/60000 (51%)]\tLoss: -24316409493592377134363443200.000000\n', 'Train Epoch: 1 [33280/60000 (55%)]\tLoss: -27364371214997415114284466176.000000\n', 'Train Epoch: 1 [35840/60000 (60%)]\tLoss: -29440675337169884938793648128.000000\n', 'Train Epoch: 1 [38400/60000 (64%)]\tLoss: -31390627821726694535965179904.000000\n', 'Train Epoch: 1 [40960/60000 (68%)]\tLoss: -34408323896343020959711625216.000000\n', 'Train Epoch: 1 [43520/60000 (72%)]\tLoss: -37147331874156036705994407936.000000\n', 'Train Epoch: 1 [46080/60000 (77%)]\tLoss: -39187460307886483613344071680.000000\n', 'Train Epoch: 1 [48640/60000 (81%)]\tLoss: -42830825079001450766275706880.000000\n', 'Train Epoch: 1 [51200/60000 (85%)]\tLoss: -44198823813591543940005232640.000000\n', 'Train Epoch: 1 [53760/60000 (89%)]\tLoss: -46506110686357375286029320192.000000\n', 'Train Epoch: 1 [56320/60000 (94%)]\tLoss: -49308896584704787025745674240.000000\n', 'Train Epoch: 1 [58880/60000 (98%)]\tLoss: -51129203581024134818043002880.000000\n', '\n', 'Test set: Average loss: -53217026767752034734860926976.0000, Accuracy: 980/10000 (10%)\n', '\n', '\n', 'Test set: Average loss: -53217029669174007678724210688.0000, Accuracy: 980/10000 (10%)\n', '\n', '{"accuracy": 9.8, "runtime": 62.061782258562744, "mem_params": 244341408, "mem_bufs": 0, "mem_peak": 3343360512}\n']
[2021-12-11 15:50:59,801 DEBUG] Received error from gpu2: []
[2021-12-11 15:50:59,802 DEBUG] SSH connection with gpu2 has been closed
[2021-12-11 15:50:59,802 INFO] {'batch-size': 256, 'lr': 0.99, 'gamma': 0.9} => {"accuracy": 9.8, "runtime": 62.061782258562744, "mem_params": 244341408, "mem_bufs": 0, "mem_peak": 3343360512}
[2021-12-11 15:50:59,802 DEBUG] gpu2 finished training {'batch-size': 256, 'lr': 0.99, 'gamma': 0.9}
[2021-12-11 15:51:00,284 DEBUG] All trials have now been executed!
All Trial Results:
{'batch-size': 64, 'lr': 0.5, 'gamma': 0.5}: 10.1, runtime: 98.86405460909009, mem_params: 244341408, mem_bufs: 0, mem_peak: 3344906752
{'batch-size': 64, 'lr': 0.5, 'gamma': 0.7}: 10.09, runtime: 98.56036841403693, mem_params: 244341408, mem_bufs: 0, mem_peak: 3344906752
{'batch-size': 64, 'lr': 0.5, 'gamma': 0.9}: 11.35, runtime: 99.16920200129971, mem_params: 244341408, mem_bufs: 0, mem_peak: 3344906752
{'batch-size': 64, 'lr': 0.9, 'gamma': 0.5}: 10.09, runtime: 99.85920097492635, mem_params: 244341408, mem_bufs: 0, mem_peak: 3344906752
{'batch-size': 64, 'lr': 0.9, 'gamma': 0.9}: 10.28, runtime: 97.7788297929801, mem_params: 244341408, mem_bufs: 0, mem_peak: 3344906752
{'batch-size': 64, 'lr': 0.9, 'gamma': 0.7}: 10.28, runtime: 98.76292283693328, mem_params: 244341408, mem_bufs: 0, mem_peak: 3344906752
{'batch-size': 64, 'lr': 0.99, 'gamma': 0.5}: 9.58, runtime: 99.04266539029777, mem_params: 244341408, mem_bufs: 0, mem_peak: 3344906752
{'batch-size': 64, 'lr': 0.99, 'gamma': 0.7}: 9.82, runtime: 98.22968475613743, mem_params: 244341408, mem_bufs: 0, mem_peak: 3344906752
{'batch-size': 64, 'lr': 0.99, 'gamma': 0.9}: 10.28, runtime: 98.22733215102926, mem_params: 244341408, mem_bufs: 0, mem_peak: 3344906752
{'batch-size': 128, 'lr': 0.5, 'gamma': 0.5}: 11.35, runtime: 67.05662207491696, mem_params: 244341408, mem_bufs: 0, mem_peak: 3343928832
{'batch-size': 128, 'lr': 0.5, 'gamma': 0.7}: 8.92, runtime: 66.27351069729775, mem_params: 244341408, mem_bufs: 0, mem_peak: 3343928832
{'batch-size': 128, 'lr': 0.5, 'gamma': 0.9}: 10.09, runtime: 67.47841753996909, mem_params: 244341408, mem_bufs: 0, mem_peak: 3343928832
{'batch-size': 128, 'lr': 0.9, 'gamma': 0.5}: 9.82, runtime: 66.58223777450621, mem_params: 244341408, mem_bufs: 0, mem_peak: 3343928832
{'batch-size': 128, 'lr': 0.9, 'gamma': 0.7}: 9.8, runtime: 67.28138215094805, mem_params: 244341408, mem_bufs: 0, mem_peak: 3343928832
{'batch-size': 128, 'lr': 0.9, 'gamma': 0.9}: 10.1, runtime: 66.78818869125098, mem_params: 244341408, mem_bufs: 0, mem_peak: 3343928832
{'batch-size': 128, 'lr': 0.99, 'gamma': 0.5}: 10.1, runtime: 68.22179368324578, mem_params: 244341408, mem_bufs: 0, mem_peak: 3343928832
{'batch-size': 128, 'lr': 0.99, 'gamma': 0.7}: 10.28, runtime: 66.41429883893579, mem_params: 244341408, mem_bufs: 0, mem_peak: 3343928832
{'batch-size': 128, 'lr': 0.99, 'gamma': 0.9}: 10.32, runtime: 67.14807305671275, mem_params: 244341408, mem_bufs: 0, mem_peak: 3343928832
{'batch-size': 256, 'lr': 0.5, 'gamma': 0.5}: 9.58, runtime: 61.64756123162806, mem_params: 244341408, mem_bufs: 0, mem_peak: 3343360512
{'batch-size': 256, 'lr': 0.5, 'gamma': 0.7}: 11.35, runtime: 61.129784691147506, mem_params: 244341408, mem_bufs: 0, mem_peak: 3343360512
{'batch-size': 256, 'lr': 0.5, 'gamma': 0.9}: 10.1, runtime: 62.70460104569793, mem_params: 244341408, mem_bufs: 0, mem_peak: 3343360512
{'batch-size': 256, 'lr': 0.9, 'gamma': 0.5}: 9.58, runtime: 61.56561255082488, mem_params: 244341408, mem_bufs: 0, mem_peak: 3343360512
{'batch-size': 256, 'lr': 0.9, 'gamma': 0.7}: 9.8, runtime: 64.12551787868142, mem_params: 244341408, mem_bufs: 0, mem_peak: 3343360512
{'batch-size': 256, 'lr': 0.9, 'gamma': 0.9}: 10.09, runtime: 63.238843688741326, mem_params: 244341408, mem_bufs: 0, mem_peak: 3343360512
{'batch-size': 256, 'lr': 0.99, 'gamma': 0.5}: 10.09, runtime: 60.24541654996574, mem_params: 244341408, mem_bufs: 0, mem_peak: 3343360512
{'batch-size': 256, 'lr': 0.99, 'gamma': 0.7}: 10.1, runtime: 63.29802916524932, mem_params: 244341408, mem_bufs: 0, mem_peak: 3343360512
{'batch-size': 256, 'lr': 0.99, 'gamma': 0.9}: 9.8, runtime: 62.061782258562744, mem_params: 244341408, mem_bufs: 0, mem_peak: 3343360512
Best Trial Result:
{'batch-size': 64, 'lr': 0.5, 'gamma': 0.9}: 11.35, runtime: 99.16920200129971, mem_params: 244341408, mem_bufs: 0, mem_peak: 3344906752
